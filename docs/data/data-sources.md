# æ•¸æ“šæºé›†æˆ (v0.1.6)

## æ¦‚è¿°

TradingAgents ä¸­æ–‡å¢å¼ºç‰ˆé›†æˆäº†å¤šç¨®é‡‘èæ•¸æ“šæºï¼Œç‰¹åˆ¥åŠ å¼ºäº†å°ä¸­åœ‹Aè‚¡å¸‚å ´çš„æ”¯æŒã€‚ç‚ºæ™ºèƒ½é«”æä¾›å…¨é¢ã€æº–ç¢ºã€å¯¦æ™‚çš„å¸‚å ´ä¿¡æ¯ã€‚æœ¬æ–‡æ¡£è©³ç´°ä»‹ç´¹äº†æ”¯æŒçš„æ•¸æ“šæºã€APIé›†æˆæ–¹æ³•ã€æ•¸æ“šæ ¼å¼å’Œä½¿ç”¨æŒ‡å—ã€‚

## ğŸ”„ v0.1.6 é‡å¤§æ›´æ–°

### æ•¸æ“šæºè¿ç§»å®Œæˆ
- âœ… **ä¸»æ•¸æ“šæº**: å¾é€šé”ä¿¡å®Œå…¨è¿ç§»åˆ°Tushare
- âœ… **æ··åˆç­–ç•¥**: Tushare(æ­·å²æ•¸æ“š) + AKShare(å¯¦æ™‚æ•¸æ“š)
- âœ… **çµ±ä¸€æ¥å£**: é€æ˜çš„æ•¸æ“šæºåˆ‡æ›ï¼Œç”¨æˆ¶ç„¡æ„ŸçŸ¥
- âœ… **å‘å¾Œå…¼å®¹**: ä¿æŒæ‰€æœ‰APIæ¥å£ä¸è®Š
- âœ… **ç”¨æˆ¶ç•Œé¢**: æ‰€æœ‰æç¤ºä¿¡æ¯å·²æ›´æ–°ç‚ºæ­£ç¢ºçš„æ•¸æ“šæºæ¨™è¯†

## ğŸ¯ v0.1.6 æ•¸æ“šæºç‹€æ…‹

| æ•¸æ“šæº | å¸‚å ´ | ç‹€æ…‹ | èªªæ˜ |
|--------|------|------|------|
| ğŸ‡¨ğŸ‡³ **Tushareæ•¸æ“šæ¥å£** | Aè‚¡ | âœ… å®Œæ•´æ”¯æŒ | å¯¦æ™‚è¡Œæƒ…ã€æ­·å²æ•¸æ“šã€æŠ€è¡“æŒ‡æ¨™ |
| **FinnHub** | ç¾è‚¡ | âœ… å®Œæ•´æ”¯æŒ | å¯¦æ™‚æ•¸æ“šã€åŸºæœ¬é¢ã€æ–°è |
| **Google News** | å…¨çƒ | âœ… å®Œæ•´æ”¯æŒ | è²¡ç¶“æ–°èã€å¸‚å ´è³‡è®¯ |
| **Reddit** | å…¨çƒ | âœ… å®Œæ•´æ”¯æŒ | ç¤¾äº¤åª’é«”æƒ…ç»ªåˆ†æ |
| **MongoDB** | ç·©å­˜ | âœ… å®Œæ•´æ”¯æŒ | æ•¸æ“šæŒä¹…åŒ–å­˜å‚¨ |
| **Redis** | ç·©å­˜ | âœ… å®Œæ•´æ”¯æŒ | é«˜é€Ÿæ•¸æ“šç·©å­˜ |

## æ”¯æŒçš„æ•¸æ“šæº

### ğŸ‡¨ğŸ‡³ 1. Tushareæ•¸æ“šæ¥å£ (æ–°å¢ v0.1.3)

#### ç°¡ä»‹
Tushareæ•¸æ“šæ¥å£æ˜¯ä¸­åœ‹é ˜å…ˆçš„è‚¡ç¥¨æ•¸æ“šæä¾›å•†ï¼Œç‚ºAè‚¡å¸‚å ´æä¾›å¯¦æ™‚è¡Œæƒ…å’Œæ­·å²æ•¸æ“šã€‚

#### æ•¸æ“šé¡å‹
```python
tdx_data_types = {
    "å¯¦æ™‚æ•¸æ“š": [
        "Aè‚¡å¯¦æ™‚è¡Œæƒ…",
        "æˆäº¤é‡",
        "æ¶¨è·Œå¹…",
        "æ›æ‰‹ç‡"
    ],
    "æ­·å²æ•¸æ“š": [
        "æ—¥Kç·šæ•¸æ“š",
        "åˆ†é˜ç´šæ•¸æ“š",
        "è¤‡æ¬Šæ•¸æ“š",
        "é™¤æ¬Šé™¤æ¯"
    ],
    "æŠ€è¡“æŒ‡æ¨™": [
        "MAç§»å‹•å¹³å‡",
        "MACD",
        "RSI",
        "KDJ"
    ],
    "å¸‚å ´æ•¸æ“š": [
        "æ¿å¡Šåˆ†é¡",
        "æ¦‚å¿µè‚¡",
        "é¾™è™æ¦œ",
        "è³‡é‡‘æµå‘"
    ]
}
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
from tradingagents.dataflows.tdx_utils import get_stock_data

# ç²å–Aè‚¡æ•¸æ“š
data = get_stock_data(
    stock_code="000001",  # å¹³å®‰éŠ€è¡Œ
    start_date="2024-01-01",
    end_date="2024-12-31"
)
```

### 1. FinnHub API

#### ç°¡ä»‹
FinnHub æ˜¯é ˜å…ˆçš„é‡‘èæ•¸æ“šæä¾›å•†ï¼Œæä¾›å¯¦æ™‚è‚¡ç¥¨åƒ¹æ ¼ã€å…¬å¸åŸºæœ¬é¢æ•¸æ“šã€æ–°èå’Œå¸‚å ´æŒ‡æ¨™ã€‚

#### æ•¸æ“šé¡å‹
```python
finnhub_data_types = {
    "å¯¦æ™‚æ•¸æ“š": [
        "è‚¡ç¥¨åƒ¹æ ¼",
        "äº¤æ˜“é‡",
        "å¸‚å ´æ·±åº¦",
        "å¯¦æ™‚æ–°è"
    ],
    "åŸºæœ¬é¢æ•¸æ“š": [
        "è²¡å‹™å ±è¡¨",
        "å…¬å¸æ¦‚å†µ",
        "åˆ†æå¸«è©•ç´š",
        "ç›ˆåˆ©é æ¸¬"
    ],
    "æŠ€è¡“æŒ‡æ¨™": [
        "RSI",
        "MACD",
        "å¸ƒæ—å¸¶",
        "ç§»å‹•å¹³å‡ç·š"
    ],
    "å¸‚å ´æ•¸æ“š": [
        "IPOæ—¥æ­·",
        "åˆ†çº¢ä¿¡æ¯",
        "è‚¡ç¥¨åˆ†å‰²",
        "æœŸæ¬Šæ•¸æ“š"
    ]
}
```

#### API é…ç½®
```python
# finnhub_utils.py
import finnhub

class FinnHubDataProvider:
    """FinnHub æ•¸æ“šæä¾›å™¨"""
    
    def __init__(self, api_key: str):
        self.client = finnhub.Client(api_key=api_key)
        self.rate_limiter = RateLimiter(calls_per_minute=60)  # å…è²»ç‰ˆé™åˆ¶
    
    def get_stock_price(self, symbol: str) -> Dict:
        """ç²å–è‚¡ç¥¨åƒ¹æ ¼"""
        with self.rate_limiter:
            quote = self.client.quote(symbol)
            return {
                "symbol": symbol,
                "current_price": quote.get("c"),
                "change": quote.get("d"),
                "change_percent": quote.get("dp"),
                "high": quote.get("h"),
                "low": quote.get("l"),
                "open": quote.get("o"),
                "previous_close": quote.get("pc"),
                "timestamp": quote.get("t")
            }
    
    def get_company_profile(self, symbol: str) -> Dict:
        """ç²å–å…¬å¸æ¦‚å†µ"""
        with self.rate_limiter:
            profile = self.client.company_profile2(symbol=symbol)
            return {
                "symbol": symbol,
                "name": profile.get("name"),
                "industry": profile.get("finnhubIndustry"),
                "sector": profile.get("gsubind"),
                "market_cap": profile.get("marketCapitalization"),
                "shares_outstanding": profile.get("shareOutstanding"),
                "website": profile.get("weburl"),
                "logo": profile.get("logo"),
                "exchange": profile.get("exchange")
            }
    
    def get_financial_statements(self, symbol: str, statement_type: str = "ic") -> Dict:
        """ç²å–è²¡å‹™å ±è¡¨"""
        with self.rate_limiter:
            financials = self.client.financials(symbol, statement_type, "annual")
            return {
                "symbol": symbol,
                "statement_type": statement_type,
                "data": financials.get("financials", []),
                "currency": financials.get("currency"),
                "last_updated": financials.get("cik")
            }
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
# åˆå§‹åŒ– FinnHub å®¢æˆ¶ç«¯
finnhub_provider = FinnHubDataProvider(api_key=os.getenv("FINNHUB_API_KEY"))

# ç²å–è‚¡ç¥¨åƒ¹æ ¼
price_data = finnhub_provider.get_stock_price("AAPL")
print(f"AAPL ç•¶å‰åƒ¹æ ¼: ${price_data['current_price']}")

# ç²å–å…¬å¸ä¿¡æ¯
company_info = finnhub_provider.get_company_profile("AAPL")
print(f"å…¬å¸åç¨±: {company_info['name']}")
```

### 2. Yahoo Finance

#### ç°¡ä»‹
Yahoo Finance æä¾›å…è²»çš„æ­·å²è‚¡ç¥¨æ•¸æ“šã€è²¡å‹™ä¿¡æ¯å’Œå¸‚å ´æŒ‡æ¨™ï¼Œæ˜¯ç²å–æ­·å²æ•¸æ“šçš„å„ªç§€é¸æ“‡ã€‚

#### æ•¸æ“šé¡å‹
```python
yahoo_finance_data_types = {
    "æ­·å²æ•¸æ“š": [
        "è‚¡ç¥¨åƒ¹æ ¼æ­·å²",
        "äº¤æ˜“é‡æ­·å²",
        "èª¿æ•´å¾Œåƒ¹æ ¼",
        "è‚¡æ¯æ­·å²"
    ],
    "è²¡å‹™æ•¸æ“š": [
        "æç›Šè¡¨",
        "è³‡ç”¢è´Ÿå€ºè¡¨",
        "ç¾é‡‘æµé‡è¡¨",
        "é—œé”®æŒ‡æ¨™"
    ],
    "å¸‚å ´æ•¸æ“š": [
        "æœŸæ¬Šéˆ",
        "åˆ†æå¸«å»ºè®®",
        "æ©Ÿæ§‹æŒè‚¡",
        "å…§éƒ¨äººäº¤æ˜“"
    ]
}
```

#### API é›†æˆ
```python
# yfin_utils.py
import yfinance as yf
import pandas as pd

class YahooFinanceProvider:
    """Yahoo Finance æ•¸æ“šæä¾›å™¨"""
    
    def __init__(self):
        self.cache = {}
        self.cache_duration = 300  # 5åˆ†é˜ç·©å­˜
    
    def get_historical_data(self, symbol: str, period: str = "1y") -> pd.DataFrame:
        """ç²å–æ­·å²æ•¸æ“š"""
        cache_key = f"{symbol}_{period}"
        
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]["data"]
        
        ticker = yf.Ticker(symbol)
        hist_data = ticker.history(period=period)
        
        # ç·©å­˜æ•¸æ“š
        self.cache[cache_key] = {
            "data": hist_data,
            "timestamp": time.time()
        }
        
        return hist_data
    
    def get_financial_info(self, symbol: str) -> Dict:
        """ç²å–è²¡å‹™ä¿¡æ¯"""
        ticker = yf.Ticker(symbol)
        info = ticker.info
        
        return {
            "symbol": symbol,
            "market_cap": info.get("marketCap"),
            "enterprise_value": info.get("enterpriseValue"),
            "pe_ratio": info.get("trailingPE"),
            "pb_ratio": info.get("priceToBook"),
            "debt_to_equity": info.get("debtToEquity"),
            "roe": info.get("returnOnEquity"),
            "revenue_growth": info.get("revenueGrowth"),
            "profit_margins": info.get("profitMargins"),
            "beta": info.get("beta")
        }
    
    def get_technical_indicators(self, symbol: str, period: str = "1y") -> Dict:
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
        hist_data = self.get_historical_data(symbol, period)
        
        # è¨ˆç®—ç§»å‹•å¹³å‡ç·š
        hist_data["MA_20"] = hist_data["Close"].rolling(window=20).mean()
        hist_data["MA_50"] = hist_data["Close"].rolling(window=50).mean()
        
        # è¨ˆç®— RSI
        hist_data["RSI"] = self._calculate_rsi(hist_data["Close"])
        
        # è¨ˆç®— MACD
        macd_data = self._calculate_macd(hist_data["Close"])
        hist_data = pd.concat([hist_data, macd_data], axis=1)
        
        return {
            "symbol": symbol,
            "indicators": hist_data.tail(1).to_dict("records")[0],
            "trend_analysis": self._analyze_trend(hist_data),
            "support_resistance": self._find_support_resistance(hist_data)
        }
```

### 3. Reddit API

#### ç°¡ä»‹
Reddit API æä¾›ç¤¾äº¤åª’é«”è¨è«–æ•¸æ“šï¼Œç”¨æ–¼åˆ†ææŠ•è³‡è€…æƒ…ç»ªå’Œå¸‚å ´ç†±é»ã€‚

#### æ•¸æ“šé¡å‹
```python
reddit_data_types = {
    "è¨è«–æ•¸æ“š": [
        "ç†±é–€å¸–å­",
        "è©•è«–å…§å®¹",
        "ç”¨æˆ¶äº’å‹•",
        "è©±é¡Œè¶‹åŠ¿"
    ],
    "æƒ…æ„Ÿæ•¸æ“š": [
        "æƒ…æ„Ÿæ¥µæ€§",
        "æƒ…æ„Ÿå¼ºåº¦",
        "æƒ…æ„Ÿåˆ†å¸ƒ",
        "æƒ…æ„Ÿè®ŠåŒ–"
    ],
    "ç†±åº¦æŒ‡æ¨™": [
        "æåŠé »ç‡",
        "è¨è«–ç†±åº¦",
        "ç”¨æˆ¶åƒä¸åº¦",
        "å‚³æ’­é€Ÿåº¦"
    ]
}
```

#### API é›†æˆ
```python
# reddit_utils.py
import praw
from textblob import TextBlob

class RedditDataProvider:
    """Reddit æ•¸æ“šæä¾›å™¨"""
    
    def __init__(self, client_id: str, client_secret: str, user_agent: str):
        self.reddit = praw.Reddit(
            client_id=client_id,
            client_secret=client_secret,
            user_agent=user_agent
        )
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def get_stock_discussions(self, symbol: str, subreddit: str = "stocks", limit: int = 100) -> List[Dict]:
        """ç²å–è‚¡ç¥¨è¨è«–"""
        discussions = []
        
        # æœç´¢ç›¸é—œå¸–å­
        for submission in self.reddit.subreddit(subreddit).search(symbol, limit=limit):
            # åˆ†ææƒ…æ„Ÿ
            sentiment = self.sentiment_analyzer.analyze(submission.title + " " + submission.selftext)
            
            discussions.append({
                "id": submission.id,
                "title": submission.title,
                "content": submission.selftext,
                "score": submission.score,
                "num_comments": submission.num_comments,
                "created_utc": submission.created_utc,
                "author": str(submission.author),
                "url": submission.url,
                "sentiment": sentiment
            })
        
        return discussions
    
    def analyze_sentiment_trends(self, discussions: List[Dict]) -> Dict:
        """åˆ†ææƒ…æ„Ÿè¶‹åŠ¿"""
        if not discussions:
            return {"error": "No discussions found"}
        
        # è¨ˆç®—æ•´é«”æƒ…æ„Ÿ
        sentiments = [d["sentiment"]["polarity"] for d in discussions]
        avg_sentiment = sum(sentiments) / len(sentiments)
        
        # æ™‚é–“åºåˆ—åˆ†æ
        time_series = self._create_sentiment_time_series(discussions)
        
        # ç†±åº¦åˆ†æ
        engagement_metrics = self._calculate_engagement_metrics(discussions)
        
        return {
            "overall_sentiment": avg_sentiment,
            "sentiment_distribution": self._calculate_sentiment_distribution(sentiments),
            "time_series": time_series,
            "engagement_metrics": engagement_metrics,
            "trending_topics": self._extract_trending_topics(discussions)
        }
```

### 4. Google News

#### ç°¡ä»‹
Google News API æä¾›å¯¦æ™‚æ–°èæ•¸æ“šï¼Œç”¨æ–¼åˆ†æå¸‚å ´äº‹ä»¶å’Œæ–°èå°è‚¡åƒ¹çš„å½±éŸ¿ã€‚

#### æ•¸æ“šé¡å‹
```python
google_news_data_types = {
    "æ–°èå…§å®¹": [
        "æ–°èæ¨™é¡Œ",
        "æ–°èæ­£æ–‡",
        "ç™¼å¸ƒæ™‚é–“",
        "æ–°èä¾†æº"
    ],
    "å½±éŸ¿åˆ†æ": [
        "æ–°èæƒ…æ„Ÿ",
        "å½±éŸ¿ç¨‹åº¦",
        "ç›¸é—œæ€§è©•åˆ†",
        "æ™‚æ•ˆæ€§åˆ†æ"
    ],
    "äº‹ä»¶è¿½è¹¤": [
        "äº‹ä»¶æ™‚é–“ç·š",
        "é—œè¯äº‹ä»¶",
        "å½±éŸ¿ç¯„å›´",
        "å¾Œç»­ç™¼å±•"
    ]
}
```

#### API é›†æˆ
```python
# googlenews_utils.py
from GoogleNews import GoogleNews
import requests
from bs4 import BeautifulSoup

class GoogleNewsProvider:
    """Google News æ•¸æ“šæä¾›å™¨"""
    
    def __init__(self):
        self.googlenews = GoogleNews()
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def get_stock_news(self, symbol: str, days: int = 7) -> List[Dict]:
        """ç²å–è‚¡ç¥¨ç›¸é—œæ–°è"""
        # è¨­ç½®æœç´¢åƒæ•¸
        self.googlenews.clear()
        self.googlenews.set_time_range(f"{days}d")
        self.googlenews.set_lang("en")
        
        # æœç´¢æ–°è
        search_terms = [symbol, f"{symbol} stock", f"{symbol} earnings"]
        all_news = []
        
        for term in search_terms:
            self.googlenews.search(term)
            news_results = self.googlenews.results()
            
            for news in news_results:
                # ç²å–æ–°èè©³æƒ…
                news_detail = self._get_news_detail(news)
                if news_detail:
                    all_news.append(news_detail)
        
        # å»é‡å’Œæ’åº
        unique_news = self._deduplicate_news(all_news)
        return sorted(unique_news, key=lambda x: x["published_date"], reverse=True)
    
    def _get_news_detail(self, news_item: Dict) -> Dict:
        """ç²å–æ–°èè©³æƒ…"""
        try:
            # åˆ†ææ–°èæƒ…æ„Ÿ
            sentiment = self.sentiment_analyzer.analyze(news_item.get("title", ""))
            
            # è©•ä¼°æ–°èé‡è¦æ€§
            importance = self._assess_news_importance(news_item)
            
            return {
                "title": news_item.get("title"),
                "link": news_item.get("link"),
                "published_date": news_item.get("date"),
                "source": news_item.get("media"),
                "sentiment": sentiment,
                "importance": importance,
                "relevance_score": self._calculate_relevance_score(news_item)
            }
        except Exception as e:
            print(f"Error processing news item: {e}")
            return None
    
    def analyze_news_impact(self, news_list: List[Dict], symbol: str) -> Dict:
        """åˆ†ææ–°èå½±éŸ¿"""
        if not news_list:
            return {"error": "No news found"}
        
        # æƒ…æ„Ÿåˆ†æ
        sentiment_analysis = self._analyze_news_sentiment(news_list)
        
        # å½±éŸ¿è©•ä¼°
        impact_assessment = self._assess_news_impact(news_list, symbol)
        
        # æ™‚é–“ç·šåˆ†æ
        timeline_analysis = self._create_news_timeline(news_list)
        
        return {
            "sentiment_analysis": sentiment_analysis,
            "impact_assessment": impact_assessment,
            "timeline_analysis": timeline_analysis,
            "key_events": self._identify_key_events(news_list),
            "market_implications": self._analyze_market_implications(news_list, symbol)
        }
```

## æ•¸æ“šé›†æˆæ¥å£

### çµ±ä¸€æ•¸æ“šæ¥å£
```python
# interface.py
class DataInterface:
    """çµ±ä¸€æ•¸æ“šæ¥å£"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.providers = self._initialize_providers()
        self.cache_manager = CacheManager()
        
    def _initialize_providers(self) -> Dict:
        """åˆå§‹åŒ–æ•¸æ“šæä¾›å™¨"""
        providers = {}
        
        # FinnHub
        if self.config.get("finnhub_api_key"):
            providers["finnhub"] = FinnHubDataProvider(self.config["finnhub_api_key"])
        
        # Yahoo Finance
        providers["yahoo"] = YahooFinanceProvider()
        
        # Reddit
        if self.config.get("reddit_credentials"):
            providers["reddit"] = RedditDataProvider(**self.config["reddit_credentials"])
        
        # Google News
        providers["google_news"] = GoogleNewsProvider()
        
        return providers
    
    def get_comprehensive_data(self, symbol: str, date: str = None) -> Dict:
        """ç²å–ç»¼åˆæ•¸æ“š"""
        data = {}
        
        # ä¸¦è¡Œç²å–æ•¸æ“š
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {
                executor.submit(self._get_price_data, symbol): "price_data",
                executor.submit(self._get_fundamental_data, symbol): "fundamental_data",
                executor.submit(self._get_news_data, symbol): "news_data",
                executor.submit(self._get_social_data, symbol): "social_data"
            }
            
            for future in as_completed(futures):
                data_type = futures[future]
                try:
                    data[data_type] = future.result()
                except Exception as e:
                    print(f"Error fetching {data_type}: {e}")
                    data[data_type] = {}
        
        return data
    
    def _get_price_data(self, symbol: str) -> Dict:
        """ç²å–åƒ¹æ ¼æ•¸æ“š"""
        # å„ªå…ˆä½¿ç”¨ FinnHubï¼Œå¤‡ç”¨ Yahoo Finance
        if "finnhub" in self.providers:
            try:
                return self.providers["finnhub"].get_stock_price(symbol)
            except Exception:
                pass
        
        if "yahoo" in self.providers:
            hist_data = self.providers["yahoo"].get_historical_data(symbol, "5d")
            latest = hist_data.iloc[-1]
            return {
                "symbol": symbol,
                "current_price": latest["Close"],
                "change": latest["Close"] - latest["Open"],
                "high": latest["High"],
                "low": latest["Low"],
                "volume": latest["Volume"]
            }
        
        return {}
```

## æ•¸æ“šè´¨é‡æ§åˆ¶

### æ•¸æ“šé©—è­‰
```python
class DataValidator:
    """æ•¸æ“šé©—è­‰å™¨"""
    
    def validate_data(self, data: Dict, data_type: str) -> Tuple[bool, List[str]]:
        """é©—è­‰æ•¸æ“šè´¨é‡"""
        errors = []
        
        # åŸºæœ¬å®Œæ•´æ€§æª¢æŸ¥
        if not data:
            errors.append("Data is empty")
            return False, errors
        
        # ç‰¹å®šé¡å‹é©—è­‰
        if data_type == "price_data":
            errors.extend(self._validate_price_data(data))
        elif data_type == "fundamental_data":
            errors.extend(self._validate_fundamental_data(data))
        elif data_type == "news_data":
            errors.extend(self._validate_news_data(data))
        elif data_type == "social_data":
            errors.extend(self._validate_social_data(data))
        
        return len(errors) == 0, errors
    
    def _validate_price_data(self, data: Dict) -> List[str]:
        """é©—è­‰åƒ¹æ ¼æ•¸æ“š"""
        errors = []
        
        required_fields = ["symbol", "current_price"]
        for field in required_fields:
            if field not in data:
                errors.append(f"Missing required field: {field}")
        
        # åƒ¹æ ¼åˆç†æ€§æª¢æŸ¥
        if "current_price" in data:
            price = data["current_price"]
            if not isinstance(price, (int, float)) or price <= 0:
                errors.append("Invalid price value")
        
        return errors
```

## ä½¿ç”¨æœ€ä½³å¯¦è¸

### 1. API é™åˆ¶ç®¡ç†
```python
class RateLimiter:
    """API é™åˆ¶ç®¡ç†å™¨"""
    
    def __init__(self, calls_per_minute: int):
        self.calls_per_minute = calls_per_minute
        self.calls = []
    
    def __enter__(self):
        current_time = time.time()
        
        # æ¸…ç†éæœŸçš„èª¿ç”¨è¨˜éŒ„
        self.calls = [call_time for call_time in self.calls if current_time - call_time < 60]
        
        # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
        if len(self.calls) >= self.calls_per_minute:
            sleep_time = 60 - (current_time - self.calls[0])
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.calls.append(current_time)
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass
```

### 2. éŒ¯èª¤è™•ç†å’Œé‡è©¦
```python
def with_retry(max_retries: int = 3, delay: float = 1.0):
    """é‡è©¦è£é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    time.sleep(delay * (2 ** attempt))  # æŒ‡æ•¸é€€é¿
            return None
        return wrapper
    return decorator
```

### 3. æ•¸æ“šç·©å­˜ç­–ç•¥
```python
class CacheManager:
    """ç·©å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = {
            "price_data": 60,      # 1åˆ†é˜
            "fundamental_data": 3600,  # 1å°æ™‚
            "news_data": 1800,     # 30åˆ†é˜
            "social_data": 900     # 15åˆ†é˜
        }
    
    def get(self, key: str, data_type: str) -> Optional[Dict]:
        """ç²å–ç·©å­˜æ•¸æ“š"""
        if key in self.cache:
            cached_item = self.cache[key]
            ttl = self.cache_ttl.get(data_type, 3600)
            
            if time.time() - cached_item["timestamp"] < ttl:
                return cached_item["data"]
            else:
                del self.cache[key]
        
        return None
    
    def set(self, key: str, data: Dict, data_type: str):
        """è¨­ç½®ç·©å­˜æ•¸æ“š"""
        self.cache[key] = {
            "data": data,
            "timestamp": time.time(),
            "type": data_type
        }
```

é€šéé€™äº›æ•¸æ“šæºçš„é›†æˆï¼ŒTradingAgents èƒ½å¤ ç²å¾—å…¨é¢ã€å¯¦æ™‚ã€é«˜è´¨é‡çš„å¸‚å ´æ•¸æ“šï¼Œç‚ºæ™ºèƒ½é«”çš„åˆ†æå’Œæ±ºç­–æä¾›åšå¯¦çš„æ•¸æ“šåŸºç¡€ã€‚
