# LLM é©é…å™¨æ¸¬è©¦æŒ‡å—èˆ‡é©—è­‰æ¸…å–®

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†å®Œæ•´çš„ LLM é©é…å™¨æ¸¬è©¦æµç¨‹ï¼Œç¢ºä¿æ–°é›†æˆçš„å¤§æ¨¡å‹èƒ½å¤ ç©©å®šé‹è¡Œä¸¦æ­£ç¢ºé›†æˆåˆ° TradingAgents ç³»çµ±ä¸­ã€‚

## ğŸ§ª æ¸¬è©¦é¡å‹

### 1. åŸºç¤é€£æ¥æ¸¬è©¦
é©—è­‰é©é…å™¨èƒ½å¤ æˆåŠŸé€£æ¥åˆ° LLM æä¾›å•†çš„ APIã€‚

### 2. å·¥å…·èª¿ç”¨æ¸¬è©¦
é©—è­‰é©é…å™¨èƒ½å¤ æ­£ç¢ºåŸ·è¡Œ function callingï¼Œé€™æ˜¯ TradingAgents åˆ†æåŠŸèƒ½çš„æ ¸å¿ƒã€‚

### 3. Web ç•Œé¢é›†æˆæ¸¬è©¦
é©—è­‰æ–°çš„ LLM é¸é …åœ¨å‰ç«¯ç•Œé¢ä¸­æ­£ç¢ºé¡¯ç¤ºå’Œå·¥ä½œã€‚

### 4. ç«¯åˆ°ç«¯åˆ†ææ¸¬è©¦
é©—è­‰å®Œæ•´çš„è‚¡ç¥¨åˆ†ææµç¨‹èƒ½å¤ ä½¿ç”¨æ–°çš„ LLM æ­£å¸¸é‹è¡Œã€‚

## ğŸ”§ æ¸¬è©¦ç’°å¢ƒæº–å‚™

### ç¬¬ä¸€æ­¥ï¼šè¨­ç½® API å¯†é‘°

1. **è¤‡åˆ¶ç’°å¢ƒè®Šé‡æ¨¡æ¿**
   ```bash
   cp .env.example .env
   ```

2. **æ·»åŠ æ‚¨çš„ API å¯†é‘°**
   ```bash
   # åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ 
   YOUR_PROVIDER_API_KEY=your_actual_api_key_here
   ```

3. **é©—è­‰ç’°å¢ƒè®Šé‡åŠ è¼‰**
   ```python
   import os
   from dotenv import load_dotenv
   
   load_dotenv()
   api_key = os.getenv("YOUR_PROVIDER_API_KEY")
   print(f"API Key æ˜¯å¦é…ç½®: {'æ˜¯' if api_key else 'å¦'}")
   ```

### ç¬¬äºŒæ­¥ï¼šå®‰è£æ¸¬è©¦ä¾è³´

```bash
# ç¢ºä¿é …ç›®å·²å®‰è£
pip install -e .

# å®‰è£æ¸¬è©¦ç›¸é—œä¾è³´
pip install pytest pytest-asyncio
```

## ğŸ“ æ¸¬è©¦è…³æœ¬æ¨¡æ¿

### åŸºç¤é€£æ¥æ¸¬è©¦

å‰µå»º `tests/test_your_provider_adapter.py`ï¼š

### æ¨¡å‹å°ˆé …æ¸¬è©¦ï¼ˆOpenAI å…¼å®¹æ¨¡å¼ï¼‰

å‰µå»º `tests/test__adapter.py`ï¼š

```python
import os
from tradingagents.llm_adapters.openai_compatible_base import create_openai_compatible_llm
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage

def test__api_key_config():
    """æ¸¬è©¦ API Key é…ç½®"""
    api_key = os.environ.get("_API_KEY")
    
    if not api_key:
        print("âŒ ç¼ºå°‘APIå¯†é‘°é…ç½®: _API_KEY")
        return False
    
    if not api_key.startswith("bce-v3/"):
        print("âš ï¸ APIå¯†é‘°æ ¼å¼å¯èƒ½ä¸æ­£ç¢ºï¼Œå»ºè­°ä½¿ç”¨ bce-v3/ é–‹é ­çš„æ ¼å¼")
        return False
    
    print(f"âœ… APIå¯†é‘°é…ç½®æ­£ç¢º (æ ¼å¼: {api_key[:10]}...)")
    return True

def test__basic_chat():
    """æ¸¬è©¦åŸºç¤å°è©±ï¼ˆOpenAI å…¼å®¹æ¨¡å¼ï¼‰"""
    try:
        llm = create_openai_compatible_llm(
            provider="",
            model="ernie-3.5-8k",
            temperature=0.1,
            max_tokens=500
        )
        
        response = llm.invoke([
            HumanMessage(content="ä½ å¥½ï¼Œè«‹ç°¡å–®ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±")
        ])
        
        print(f"âœ… å°è©±æˆåŠŸ: {response.content[:100]}...")
        return True
    except Exception as e:
        print(f"âŒ å°è©±å¤±æ•—: {e}")
        return False

def test__function_calling():
    """æ¸¬è©¦å·¥å…·èª¿ç”¨åŠŸèƒ½"""
    try:
        @tool
        def get_stock_price(symbol: str) -> str:
            """ç²å–è‚¡ç¥¨åƒ¹æ ¼
            
            Args:
                symbol: è‚¡ç¥¨ä»£ç¢¼ï¼Œå¦‚ AAPL
            
            Returns:
                è‚¡ç¥¨åƒ¹æ ¼ä¿¡æ¯
            """
            return f"è‚¡ç¥¨ {symbol} çš„ç•¶å‰åƒ¹æ ¼æ˜¯ $150.00"
        
        llm = create_openai_compatible_llm(
            provider="",
            model="ernie-4.0-turbo-8k",
            temperature=0.1
        )
        
        llm_with_tools = llm.bind_tools([get_stock_price])
        
        response = llm_with_tools.invoke([
            HumanMessage(content="è«‹å¹«æˆ‘æŸ¥è©¢ AAPL è‚¡ç¥¨çš„åƒ¹æ ¼")
        ])
        
        print(f"âœ… å·¥å…·èª¿ç”¨æˆåŠŸ: {response.content[:200]}...")
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å·¥å…·èª¿ç”¨çµæœ
        if "150.00" in response.content or "AAPL" in response.content:
            print("âœ… å·¥å…·èª¿ç”¨çµæœæ­£ç¢ºè¿”å›")
            return True
        else:
            print("âš ï¸ å·¥å…·èª¿ç”¨å¯èƒ½æœªæ­£ç¢ºåŸ·è¡Œ")
            return False
            
    except Exception as e:
        print(f"âŒ å·¥å…·èª¿ç”¨å¤±æ•—: {e}")
        return False

def test__chinese_analysis():
    """æ¸¬è©¦ä¸­æ–‡é‡‘èåˆ†æèƒ½åŠ›"""
    try:
        llm = create_openai_compatible_llm(
            provider="",
            model="ernie-3.5-8k",
            temperature=0.1
        )
        
        test_prompt = """è«‹ç°¡è¦åˆ†æè‹¹æœå…¬å¸ï¼ˆAAPLï¼‰çš„æŠ•è³‡åƒ¹å€¼ï¼ŒåŒ…æ‹¬ï¼š
        1. å…¬å¸åŸºæœ¬é¢
        2. æŠ€è¡“é¢è¶¨å‹¢
        3. æŠ•è³‡å»ºè­°
        
        è«‹ç”¨ä¸­æ–‡å›ç­”ï¼Œå­—æ•¸æ§åˆ¶åœ¨200å­—ä»¥å…§ã€‚"""
        
        response = llm.invoke([HumanMessage(content=test_prompt)])
        
        # æª¢æŸ¥éŸ¿æ‡‰æ˜¯å¦åŒ…å«ä¸­æ–‡å’Œé—œéµåˆ†æè¦ç´ 
        content = response.content
        if (any('\u4e00' <= char <= '\u9fff' for char in content) and 
            ("è‹¹æœ" in content or "AAPL" in content) and
            len(content) > 50):
            print("âœ… ä¸­æ–‡é‡‘èåˆ†æèƒ½åŠ›æ­£å¸¸")
            print(f"ğŸ“„ åˆ†æå…§å®¹é è¦½: {content[:150]}...")
            return True
        else:
            print("âš ï¸ ä¸­æ–‡åˆ†æéŸ¿æ‡‰å¯èƒ½æœ‰å•é¡Œ")
            print(f"ğŸ“„ å¯¦éš›éŸ¿æ‡‰: {content}")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸­æ–‡åˆ†ææ¸¬è©¦å¤±æ•—: {e}")
        return False

def test__model_variants():
    """æ¸¬è©¦ä¸åŒæ¨¡å‹è®Šé«”"""
    models_to_test = ["ernie-3.5-8k", "ernie-4.0-turbo-8k", "
    
    for model in models_to_test:
        try:
            llm = create_openai_compatible_llm(
                provider="",
                model=model,
                temperature=0.1,
                max_tokens=100
            )
            
            response = llm.invoke([
                HumanMessage(content="ç°¡å–®èªªæ˜ä¸€ä¸‹ä½ çš„èƒ½åŠ›ç‰¹é»")
            ])
            
            print(f"âœ… æ¨¡å‹ {model} é€£æ¥æˆåŠŸ: {response.content[:50]}...")
        except Exception as e:
            print(f"âŒ æ¨¡å‹ {model} æ¸¬è©¦å¤±æ•—: {e}")

if __name__ == "__main__":
    print("=== æ¨¡å‹å°ˆé …æ¸¬è©¦ï¼ˆOpenAI å…¼å®¹æ¨¡å¼ï¼‰===")
    print()
    
    # åŸºç¤é…ç½®æ¸¬è©¦
    test__api_key_config()
    print()
    
    # åŸºç¤å°è©±æ¸¬è©¦
    test__basic_chat()
    print()
    
    # å·¥å…·èª¿ç”¨æ¸¬è©¦
    test__function_calling()
    print()
    
    # ä¸­æ–‡åˆ†ææ¸¬è©¦
    test__chinese_analysis()
    print()
    
    # æ¨¡å‹è®Šé«”æ¸¬è©¦
    print("--- æ¸¬è©¦ä¸åŒæ¨¡å‹è®Šé«” ---")
    test__model_variants()
```

```python
#!/usr/bin/env python3
"""
{Provider} é©é…å™¨æ¸¬è©¦è…³æœ¬
æ¸¬è©¦åŸºç¤é€£æ¥ã€å·¥å…·èª¿ç”¨å’Œé›†æˆåŠŸèƒ½
"""

import os
import sys
import pytest
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage

# åŠ è¼‰ç’°å¢ƒè®Šé‡
load_dotenv()

def test_api_key_configuration():
    """æ¸¬è©¦ API å¯†é‘°é…ç½®"""
    print("\nğŸ”‘ æ¸¬è©¦ API å¯†é‘°é…ç½®")
    print("=" * 50)
    
    api_key = os.getenv("YOUR_PROVIDER_API_KEY")
    assert api_key is not None, "YOUR_PROVIDER_API_KEY ç’°å¢ƒè®Šé‡æœªè¨­ç½®"
    assert len(api_key) > 10, "API å¯†é‘°é•·åº¦ä¸è¶³ï¼Œè«‹æª¢æŸ¥æ˜¯å¦æ­£ç¢º"
    
    print(f"âœ… API å¯†é‘°å·²é…ç½® (é•·åº¦: {len(api_key)})")
    return True

def test_adapter_import():
    """æ¸¬è©¦é©é…å™¨å°å…¥"""
    print("\nğŸ“¦ æ¸¬è©¦é©é…å™¨å°å…¥")
    print("=" * 50)
    
    try:
        from tradingagents.llm_adapters.your_provider_adapter import ChatYourProvider
        print("âœ… é©é…å™¨å°å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ é©é…å™¨å°å…¥å¤±æ•—: {e}")
        pytest.fail(f"é©é…å™¨å°å…¥å¤±æ•—: {e}")

def test_basic_connection():
    """æ¸¬è©¦åŸºç¤é€£æ¥"""
    print("\nğŸ”— æ¸¬è©¦åŸºç¤é€£æ¥")
    print("=" * 50)
    
    try:
        from tradingagents.llm_adapters.your_provider_adapter import ChatYourProvider
        
        # å‰µå»ºé©é…å™¨å¯¦ä¾‹
        llm = ChatYourProvider(
            model="your-default-model",
            temperature=0.1,
            max_tokens=100
        )
        
        # ç™¼é€ç°¡å–®æ¸¬è©¦æ¶ˆæ¯
        response = llm.invoke([
            HumanMessage(content="è«‹å›è¤‡'é€£æ¥æ¸¬è©¦æˆåŠŸ'")
        ])
        
        print(f"âœ… é€£æ¥æˆåŠŸ")
        print(f"ğŸ“„ å›è¤‡å…§å®¹: {response.content[:100]}...")
        return True
        
    except Exception as e:
        print(f"âŒ é€£æ¥å¤±æ•—: {e}")
        pytest.fail(f"åŸºç¤é€£æ¥æ¸¬è©¦å¤±æ•—: {e}")

def test_function_calling():
    """æ¸¬è©¦å·¥å…·èª¿ç”¨åŠŸèƒ½"""
    print("\nğŸ› ï¸ æ¸¬è©¦å·¥å…·èª¿ç”¨åŠŸèƒ½")
    print("=" * 50)
    
    try:
        from tradingagents.llm_adapters.your_provider_adapter import ChatYourProvider
        
        # å®šç¾©æ¸¬è©¦å·¥å…·
        @tool
        def get_stock_price(symbol: str) -> str:
            """ç²å–è‚¡ç¥¨åƒ¹æ ¼
            
            Args:
                symbol: è‚¡ç¥¨ä»£ç¢¼ï¼Œå¦‚ AAPL
            
            Returns:
                è‚¡ç¥¨åƒ¹æ ¼ä¿¡æ¯
            """
            return f"è‚¡ç¥¨ {symbol} çš„ç•¶å‰åƒ¹æ ¼æ˜¯ $150.00"
        
        # å‰µå»ºå¸¶å·¥å…·çš„é©é…å™¨
        llm = ChatYourProvider(
            model="your-default-model",
            temperature=0.1,
            max_tokens=500
        )
        llm_with_tools = llm.bind_tools([get_stock_price])
        
        # æ¸¬è©¦å·¥å…·èª¿ç”¨
        response = llm_with_tools.invoke([
            HumanMessage(content="è«‹å¹«æˆ‘æŸ¥è©¢ AAPL è‚¡ç¥¨çš„åƒ¹æ ¼")
        ])
        
        print(f"âœ… å·¥å…·èª¿ç”¨æˆåŠŸ")
        print(f"ğŸ“„ å›è¤‡å…§å®¹: {response.content[:200]}...")
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å·¥å…·èª¿ç”¨
        if "150.00" in response.content or "AAPL" in response.content:
            print("âœ… å·¥å…·èª¿ç”¨çµæœæ­£ç¢ºè¿”å›")
            return True
        else:
            print("âš ï¸ å·¥å…·èª¿ç”¨å¯èƒ½æœªæ­£ç¢ºåŸ·è¡Œ")
            return False
            
    except Exception as e:
        print(f"âŒ å·¥å…·èª¿ç”¨å¤±æ•—: {e}")
        pytest.fail(f"å·¥å…·èª¿ç”¨æ¸¬è©¦å¤±æ•—: {e}")

def test_factory_function():
    """æ¸¬è©¦å·¥å» å‡½æ•¸"""
    print("\nğŸ­ æ¸¬è©¦å·¥å» å‡½æ•¸")
    print("=" * 50)
    
    try:
        from tradingagents.llm_adapters.openai_compatible_base import create_openai_compatible_llm
        
        # ä½¿ç”¨å·¥å» å‡½æ•¸å‰µå»ºå¯¦ä¾‹
        llm = create_openai_compatible_llm(
            provider="your_provider",
            model="your-default-model",
            temperature=0.1,
            max_tokens=100
        )
        
        # æ¸¬è©¦ç°¡å–®èª¿ç”¨
        response = llm.invoke([
            HumanMessage(content="æ¸¬è©¦å·¥å» å‡½æ•¸")
        ])
        
        print(f"âœ… å·¥å» å‡½æ•¸æ¸¬è©¦æˆåŠŸ")
        print(f"ğŸ“„ å›è¤‡å…§å®¹: {response.content[:100]}...")
        return True
        
    except Exception as e:
        print(f"âŒ å·¥å» å‡½æ•¸æ¸¬è©¦å¤±æ•—: {e}")
        pytest.fail(f"å·¥å» å‡½æ•¸æ¸¬è©¦å¤±æ•—: {e}")

def test_trading_graph_integration():
    """æ¸¬è©¦èˆ‡ TradingGraph çš„é›†æˆ"""
    print("\nğŸ”§ æ¸¬è©¦èˆ‡ TradingGraph çš„é›†æˆ")
    print("=" * 50)
    
    try:
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        
        # å‰µå»ºé…ç½®
        config = {
            "llm_provider": "your_provider",
            "deep_think_llm": "your-default-model",
            "quick_think_llm": "your-default-model",
            "max_debate_rounds": 1,
            "online_tools": False,  # é—œé—­åœ¨ç·šå·¥å…·ä»¥åŠ å¿«æ¸¬è©¦
            "selected_analysts": ["fundamentals_analyst"]
        }
        
        print("ğŸ”„ å‰µå»º TradingGraph...")
        graph = TradingAgentsGraph(config)
        
        print("âœ… TradingGraph å‰µå»ºæˆåŠŸ")
        print(f"   Deep thinking LLM: {type(graph.deep_thinking_llm).__name__}")
        print(f"   Quick thinking LLM: {type(graph.quick_thinking_llm).__name__}")
        
        return True
        
    except Exception as e:
        print(f"âŒ TradingGraph é›†æˆæ¸¬è©¦å¤±æ•—: {e}")
        pytest.fail(f"TradingGraph é›†æˆæ¸¬è©¦å¤±æ•—: {e}")

def run_all_tests():
    """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("ğŸš€ é–‹å§‹ {Provider} é©é…å™¨å…¨å¥—æ¸¬è©¦")
    print("=" * 60)
    
    tests = [
        test_api_key_configuration,
        test_adapter_import,
        test_basic_connection,
        test_function_calling,
        test_factory_function,
        test_trading_graph_integration
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test()
            passed += 1
        except (AssertionError, Exception) as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {test.__name__}")
            print(f"   éŒ¯èª¤ä¿¡æ¯: {e}")
            failed += 1
        print()
    
    print("ğŸ“Š æ¸¬è©¦çµæœæ‘˜è¦")
    print("=" * 60)
    print(f"âœ… é€šé: {passed}")
    print(f"âŒ å¤±æ•—: {failed}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {passed/(passed+failed)*100:.1f}%")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼é©é…å™¨å¯ä»¥æ­£å¸¸ä½¿ç”¨")
    else:
        print(f"\nâš ï¸ æœ‰ {failed} å€‹æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥é…ç½®")

if __name__ == "__main__":
    run_all_tests()
```

## ğŸŒ Web ç•Œé¢æ¸¬è©¦

### æ‰‹å‹•æ¸¬è©¦æ­¥é©Ÿ

1. **å•Ÿå‹• Web æ‡‰ç”¨**
   ```bash
   python start_web.py
   ```

2. **æª¢æŸ¥æ¨¡å‹é¸æ“‡å™¨**
   - åœ¨å·¦å´é‚Šæ¬„æ‰¾åˆ°"LLMæä¾›å•†"ä¸‹æ‹‰èœå–®
   - ç¢ºèªæ‚¨çš„æä¾›å•†å‡ºç¾åœ¨é¸é …ä¸­
   - é¸æ“‡æ‚¨çš„æä¾›å•†

3. **æª¢æŸ¥æ¨¡å‹é¸é …**
   - é¸æ“‡æä¾›å•†å¾Œï¼Œç¢ºèªæ¨¡å‹é¸æ“‡å™¨é¡¯ç¤ºæ­£ç¢ºçš„æ¨¡å‹åˆ—è¡¨
   - å˜—è©¦é¸æ“‡ä¸åŒçš„æ¨¡å‹

4. **é€²è¡Œç°¡å–®åˆ†æ**
   - è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¦‚ AAPLï¼‰
   - é¸æ“‡ä¸€å€‹åˆ†æå¸«ï¼ˆå»ºè­°é¸æ“‡"åŸºæœ¬é¢åˆ†æå¸«"ï¼‰
   - é»æ“Š"é–‹å§‹åˆ†æ"
   - è§€å¯Ÿåˆ†ææ˜¯å¦æ­£å¸¸é€²è¡Œ

### è‡ªå‹•åŒ– Web æ¸¬è©¦

å‰µå»º `tests/test_web_integration.py`ï¼š

```python
import streamlit as st
from unittest.mock import patch, MagicMock
import sys
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def test_sidebar_integration():
    """æ¸¬è©¦å´é‚Šæ¬„é›†æˆ"""
    print("\nğŸ”§ æ¸¬è©¦ Web ç•Œé¢é›†æˆ")
    print("=" * 50)
    
    try:
        # æ¨¡æ“¬ Streamlit session state
        with patch('streamlit.session_state') as mock_state:
            mock_state.llm_provider = "your_provider"
            mock_state.llm_model = "your-default-model"
            
            # å°å…¥å´é‚Šæ¬„çµ„ä»¶
            from web.components.sidebar import create_sidebar
            
            # æ¨¡æ“¬ Streamlit çµ„ä»¶
            with patch('streamlit.selectbox') as mock_selectbox:
                mock_selectbox.return_value = "your_provider"
                
                # æ¸¬è©¦å´é‚Šæ¬„å‰µå»º
                config = create_sidebar()
                
                print("âœ… å´é‚Šæ¬„é›†æˆæ¸¬è©¦é€šé")
                return True
                
    except Exception as e:
        print(f"âŒ Web ç•Œé¢é›†æˆæ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    test_sidebar_integration()
```

## ğŸ“Š å®Œæ•´é©—è­‰æ¸…å–®

### âœ… é–‹ç™¼éšæ®µé©—è­‰

- [ ] **ä»£ç¢¼å“è³ª**
  - [ ] é©é…å™¨é¡ç¹¼æ‰¿è‡ª `OpenAICompatibleBase`
  - [ ] æ­£ç¢ºè¨­ç½® `provider_name`ã€`api_key_env_var`ã€`base_url`
  - [ ] æ¨¡å‹é…ç½®æ·»åŠ åˆ° `OPENAI_COMPATIBLE_PROVIDERS`
  - [ ] é©é…å™¨å°å‡ºæ·»åŠ åˆ° `__init__.py`

- [ ] **åŸºç¤åŠŸèƒ½**
  - [ ] API å¯†é‘°ç’°å¢ƒè®Šé‡æ­£ç¢ºé…ç½®
  - [ ] åŸºç¤é€£æ¥æ¸¬è©¦é€šé
  - [ ] ç°¡å–®æ–‡æœ¬ç”Ÿæˆæ­£å¸¸å·¥ä½œ
  - [ ] éŒ¯èª¤è™•ç†æ©Ÿåˆ¶æœ‰æ•ˆ

- [ ] **å·¥å…·èª¿ç”¨åŠŸèƒ½**
  - [ ] Function calling æ­£å¸¸å·¥ä½œ
  - [ ] å·¥å…·åƒæ•¸æ­£ç¢ºè§£æ
  - [ ] å·¥å…·çµæœæ­£ç¢ºè¿”å›
  - [ ] è¤‡é›œå·¥å…·èª¿ç”¨å ´æ™¯ç©©å®š

### âœ… é›†æˆéšæ®µé©—è­‰

- [ ] **å‰ç«¯é›†æˆ**
  - [ ] æä¾›å•†å‡ºç¾åœ¨ä¸‹æ‹‰èœå–®ä¸­
  - [ ] æ¨¡å‹é¸æ“‡å™¨æ­£å¸¸å·¥ä½œ
  - [ ] UI æ ¼å¼åŒ–é¡¯ç¤ºæ­£ç¢º
  - [ ] æœƒè©±ç‹€æ…‹æ­£ç¢ºä¿å­˜

- [ ] **å¾Œç«¯é›†æˆ**
  - [ ] å·¥å» å‡½æ•¸æ­£ç¢ºå‰µå»ºå¯¦ä¾‹
  - [ ] TradingGraph æ­£ç¢ºä½¿ç”¨é©é…å™¨
  - [ ] é…ç½®åƒæ•¸æ­£ç¢ºå‚³é
  - [ ] éŒ¯èª¤è™•ç†æ­£ç¢ºé›†æˆ

- [ ] **ç³»çµ±é›†æˆ**
  - [ ] ç’°å¢ƒè®Šé‡æª¢æŸ¥è…³æœ¬æ”¯æŒæ–°æä¾›å•†
  - [ ] æ—¥èªŒè¨˜éŒ„æ­£å¸¸å·¥ä½œ
  - [ ] Token ä½¿ç”¨çµ±è¨ˆæ­£ç¢º
  - [ ] å…§å­˜ç®¡ç†æ­£å¸¸

### âœ… ç«¯åˆ°ç«¯é©—è­‰

- [ ] **åŸºæœ¬åˆ†ææµç¨‹**
  - [ ] èƒ½å¤ é€²è¡Œç°¡å–®è‚¡ç¥¨åˆ†æ
  - [ ] åˆ†æå¸«é¸æ“‡æ­£å¸¸å·¥ä½œ
  - [ ] å·¥å…·èª¿ç”¨åœ¨åˆ†æä¸­æ­£å¸¸åŸ·è¡Œ
  - [ ] åˆ†æçµæœæ ¼å¼æ­£ç¢º

- [ ] **é«˜ç´šåŠŸèƒ½**
  - [ ] å¤šè¼ªå°è©±æ­£å¸¸å·¥ä½œ
  - [ ] è¨˜å¿†åŠŸèƒ½æ­£å¸¸ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
  - [ ] ä¸¦ç™¼è«‹æ±‚è™•ç†ç©©å®š
  - [ ] é•·æ™‚é–“é‹è¡Œç©©å®š

- [ ] **éŒ¯èª¤è™•ç†**
  - [ ] API éŒ¯èª¤æ­£ç¢ºè™•ç†
  - [ ] ç¶²çµ¡éŒ¯èª¤å„ªé›…é™ç´š
  - [ ] é…ç½®éŒ¯èª¤æ¸…æ™°æç¤º
  - [ ] é‡è©¦æ©Ÿåˆ¶æ­£å¸¸å·¥ä½œ

### âœ… æ€§èƒ½èˆ‡ç©©å®šæ€§é©—è­‰

- [ ] **æ€§èƒ½æŒ‡æ¨™**
  - [ ] éŸ¿æ‡‰æ™‚é–“åˆç†ï¼ˆ< 30ç§’ï¼‰
  - [ ] å…§å­˜ä½¿ç”¨ç©©å®š
  - [ ] CPU ä½¿ç”¨ç‡æ­£å¸¸
  - [ ] ç„¡å…§å­˜æ³„æ¼

- [ ] **ç©©å®šæ€§æ¸¬è©¦**
  - [ ] é€£çºŒé‹è¡Œ 30 åˆ†é˜ç„¡éŒ¯èª¤
  - [ ] è™•ç† 50+ è«‹æ±‚ç„¡å•é¡Œ
  - [ ] ç¶²çµ¡ä¸­æ–·å¾Œèƒ½æ¢å¾©
  - [ ] ä¸¦ç™¼è«‹æ±‚è™•ç†æ­£ç¢º

## ğŸ› å¸¸è¦‹æ¸¬è©¦å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### å•é¡Œ 1: API å¯†é‘°éŒ¯èª¤

**ç—‡ç‹€**: `AuthenticationError` æˆ– `InvalidAPIKey`

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥ç’°å¢ƒè®Šé‡
echo $YOUR_PROVIDER_API_KEY

# é‡æ–°åŠ è¼‰ç’°å¢ƒè®Šé‡
source .env

# é©—è­‰ API å¯†é‘°æ ¼å¼
python -c "import os; print(f'API Key: {os.getenv(\"YOUR_PROVIDER_API_KEY\")[:10]}...')"
```

### å•é¡Œ 2: å·¥å…·èª¿ç”¨å¤±æ•—

**ç—‡ç‹€**: `ToolCallError` æˆ–å·¥å…·æœªè¢«èª¿ç”¨

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æª¢æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ function calling
from tradingagents.llm_adapters.openai_compatible_base import OPENAI_COMPATIBLE_PROVIDERS

provider_config = OPENAI_COMPATIBLE_PROVIDERS["your_provider"]
models = provider_config["models"]
print(f"æ¨¡å‹æ”¯æŒ function calling: {models}")
```

### å•é¡Œ 3: å‰ç«¯é›†æˆå¤±æ•—

**ç—‡ç‹€**: æä¾›å•†ä¸å‡ºç¾åœ¨ä¸‹æ‹‰èœå–®ä¸­

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æª¢æŸ¥ sidebar.py é…ç½®
# ç¢ºä¿åœ¨ options åˆ—è¡¨ä¸­åŒ…å«æ‚¨çš„æä¾›å•†
# ç¢ºä¿åœ¨ format_func å­—å…¸ä¸­åŒ…å«æ ¼å¼åŒ–æ˜ å°„
```

### å•é¡Œ 4: å°å…¥éŒ¯èª¤

**ç—‡ç‹€**: `ModuleNotFoundError` æˆ– `ImportError`

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# ç¢ºä¿é …ç›®å·²å®‰è£
pip install -e .

# æª¢æŸ¥ __init__.py å°å‡º
python -c "from tradingagents.llm_adapters import ChatYourProvider; print('å°å…¥æˆåŠŸ')"
```

### å•é¡Œ 5: æ¨¡å‹èªè­‰å¤±æ•—

**ç—‡ç‹€**: `AuthenticationError` æˆ– `invalid_client`

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥APIå¯†é‘°é…ç½®ï¼ˆåƒ…éœ€ä¸€å€‹å¯†é‘°ï¼‰
echo $_API_KEY

# é©—è­‰å¯†é‘°æ ¼å¼ï¼ˆæ‡‰è©²ä»¥ bce-v3/ é–‹é ­ï¼‰
python -c "import os; print(f'API Keyæ ¼å¼: {os.getenv("_API_KEY", "æœªè¨­ç½®")[:10]}...')"

# å»ºè­°ï¼šä½¿ç”¨ OpenAI å…¼å®¹è·¯å¾‘é€²è¡Œé€£é€šæ€§é©—è­‰ï¼ˆç„¡éœ€ AK/SK ç²å– Tokenï¼‰
python - << 'PY'
from tradingagents.llm_adapters.openai_compatible_base import create_openai_compatible_llm
llm = create_openai_compatible_llm(provider="", model="ernie-3.5-8k")
print(llm.invoke("ping").content)
PY
```

### å•é¡Œ 6: æ¨¡å‹ä¸­æ–‡äº‚ç¢¼

**ç—‡ç‹€**: è¿”å›å…§å®¹åŒ…å«äº‚ç¢¼æˆ–ç·¨ç¢¼éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æª¢æŸ¥ç³»çµ±ç·¨ç¢¼è¨­ç½®
import locale
import sys
print(f"ç³»çµ±ç·¨ç¢¼: {locale.getpreferredencoding()}")
print(f"Pythonç·¨ç¢¼: {sys.getdefaultencoding()}")

# å¼·åˆ¶è¨­ç½®UTF-8ç·¨ç¢¼
import os
os.environ['PYTHONIOENCODING'] = 'utf-8'

# æ¸¬è©¦ä¸­æ–‡è™•ç†
test_text = "æ¸¬è©¦ä¸­æ–‡ç·¨ç¢¼"
print(f"åŸæ–‡: {test_text}")
print(f"ç·¨ç¢¼: {test_text.encode('utf-8')}")
print(f"è§£ç¢¼: {test_text.encode('utf-8').decode('utf-8')}")
```

### å•é¡Œ 7: èª¿ç”¨å¤±æ•—ï¼ˆOpenAI å…¼å®¹è·¯å¾‘ï¼‰

**ç—‡ç‹€**: `AuthenticationError`ã€`RateLimitError` æˆ– `ModelNotFound`

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# 1) æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢ºè¨­ç½®
action = "å·²è¨­ç½®" if os.getenv("_API_KEY") else "æœªè¨­ç½®"
print(f"_API_KEY: {action}")

# 2) ç¢ºèªæ¨¡å‹åç¨±æ˜¯å¦åœ¨æ˜ å°„åˆ—è¡¨
from tradingagents.llm_adapters.openai_compatible_base import OPENAI_COMPATIBLE_PROVIDERS
print(OPENAI_COMPATIBLE_PROVIDERS[""]["models"].keys())

# 3) ä½ä¸¦ç™¼/å»¶æ™‚é‡è©¦
from tradingagents.llm_adapters.openai_compatible_base import create_openai_compatible_llm
llm = create_openai_compatible_llm(provider="", model="ernie-3.5-8k", request_timeout=60)
print(llm.invoke("hello").content)
```

## ğŸ“ æ¸¬è©¦å ±å‘Šæ¨¡æ¿

å®Œæˆæ¸¬è©¦å¾Œï¼Œå‰µå»ºæ¸¬è©¦å ±å‘Šï¼š

```markdown
# {Provider} é©é…å™¨æ¸¬è©¦å ±å‘Š

## åŸºæœ¬ä¿¡æ¯
- **æä¾›å•†**: {Provider}
- **é©é…å™¨é¡**: Chat{Provider}
- **æ¸¬è©¦æ—¥æœŸ**: {Date}
- **æ¸¬è©¦è€…**: {Name}

## æ¸¬è©¦çµæœæ‘˜è¦
- âœ… åŸºç¤é€£æ¥: é€šé
- âœ… å·¥å…·èª¿ç”¨: é€šé  
- âœ… Web é›†æˆ: é€šé
- âœ… ç«¯åˆ°ç«¯: é€šé

## æ€§èƒ½æŒ‡æ¨™
- å¹³å‡éŸ¿æ‡‰æ™‚é–“: {X}ç§’
- å·¥å…·èª¿ç”¨æˆåŠŸç‡: {X}%
- å…§å­˜ä½¿ç”¨: {X}MB
- ç©©å®šæ€§æ¸¬è©¦: é€šé

## å·²çŸ¥å•é¡Œ
- ç„¡é‡å¤§å•é¡Œ

## å»ºè­°
- é©é…å™¨å¯ä»¥æ­£å¸¸ä½¿ç”¨
- å»ºè­°åˆä¸¦åˆ°ä¸»åˆ†æ”¯
```

## ğŸ¯ æœ€ä½³å¯¦è¸

1. **æ¸¬è©¦é©…å‹•é–‹ç™¼**: å…ˆå¯«æ¸¬è©¦ï¼Œå†å¯¦ç¾åŠŸèƒ½
2. **å°æ­¥å¿«è·‘**: æ¯å®Œæˆä¸€å€‹åŠŸèƒ½å°±é€²è¡Œæ¸¬è©¦
3. **è‡ªå‹•åŒ–æ¸¬è©¦**: ä½¿ç”¨è…³æœ¬è‡ªå‹•é‹è¡Œæ‰€æœ‰æ¸¬è©¦
4. **æ–‡æª”åŒæ­¥**: æ¸¬è©¦é€šéå¾ŒåŠæ™‚æ›´æ–°æ–‡æª”
5. **ç‰ˆæœ¬æ§åˆ¶**: æ¯æ¬¡æ¸¬è©¦å‰µå»º git æäº¤è¨˜éŒ„

## ğŸ”„ æŒçºŒé©—è­‰

é›†æˆå®Œæˆå¾Œï¼Œå»ºè­°å®šæœŸé€²è¡Œä»¥ä¸‹é©—è­‰ï¼š

- **æ¯å‘¨**: é‹è¡ŒåŸºç¤é€£æ¥æ¸¬è©¦
- **æ¯æœˆ**: é‹è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶
- **ç‰ˆæœ¬æ›´æ–°**: é‡æ–°é‹è¡Œæ‰€æœ‰æ¸¬è©¦
- **API è®Šæ›´**: é‡æ–°é©—è­‰å·¥å…·èª¿ç”¨åŠŸèƒ½

---

é€šééµå¾ªé€™å€‹å®Œæ•´çš„æ¸¬è©¦æŒ‡å—ï¼Œæ‚¨å¯ä»¥ç¢ºä¿æ–°é›†æˆçš„ LLM é©é…å™¨å“è³ªå¯é ï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œèƒ½å¤ ç©©å®šåœ°ç‚º TradingAgents ç”¨æˆ¶æä¾›æœå‹™ã€‚