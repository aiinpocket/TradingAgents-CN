"""
æ–°èéæ¿¾é›†æˆæ¨¡å¡Š
å°†æ–°èéæ¿¾å™¨é›†æˆåˆ°ç¾æœ‰çš„æ–°èç²å–æµç¨‹ä¸­
"""

import pandas as pd
import logging
from typing import Optional, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)

def integrate_news_filtering(original_get_stock_news_em):
    """
    è£é¥°å™¨ï¼šç‚ºget_stock_news_emå‡½æ•¸æ·»åŠ æ–°èéæ¿¾åŠŸèƒ½
    
    Args:
        original_get_stock_news_em: åŸå§‹çš„get_stock_news_emå‡½æ•¸
        
    Returns:
        åŒ…è£å¾Œçš„å‡½æ•¸ï¼Œå…·æœ‰æ–°èéæ¿¾åŠŸèƒ½
    """
    def filtered_get_stock_news_em(symbol: str, enable_filter: bool = True, min_score: float = 30, 
                                  use_semantic: bool = False, use_local_model: bool = False) -> pd.DataFrame:
        """
        å¢å¼ºç‰ˆget_stock_news_emï¼Œé›†æˆæ–°èéæ¿¾åŠŸèƒ½
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            enable_filter: æ˜¯å¦å•Ÿç”¨æ–°èéæ¿¾
            min_score: æœ€ä½ç›¸é—œæ€§è©•åˆ†é˜ˆå€¼
            use_semantic: æ˜¯å¦ä½¿ç”¨èªç¾©ç›¸ä¼¼åº¦éæ¿¾
            use_local_model: æ˜¯å¦ä½¿ç”¨æœ¬åœ°åˆ†é¡æ¨¡å‹
            
        Returns:
            pd.DataFrame: éæ¿¾å¾Œçš„æ–°èæ•¸æ“š
        """
        logger.info(f"[æ–°èéæ¿¾é›†æˆ] é–‹å§‹ç²å– {symbol} çš„æ–°èï¼Œéæ¿¾é–‹é—œ: {enable_filter}")
        
        # èª¿ç”¨åŸå§‹å‡½æ•¸ç²å–æ–°è
        start_time = datetime.now()
        try:
            news_df = original_get_stock_news_em(symbol)
            fetch_time = (datetime.now() - start_time).total_seconds()
            
            if news_df.empty:
                logger.warning(f"[æ–°èéæ¿¾é›†æˆ] åŸå§‹å‡½æ•¸æœªç²å–åˆ° {symbol} çš„æ–°èæ•¸æ“š")
                return news_df
            
            logger.info(f"[æ–°èéæ¿¾é›†æˆ] åŸå§‹æ–°èç²å–æˆåŠŸ: {len(news_df)}æ¢ï¼Œè€—æ™‚: {fetch_time:.2f}ç§’")
            
            # å¦‚æœä¸å•Ÿç”¨éæ¿¾ï¼Œç›´æ¥è¿”å›åŸå§‹æ•¸æ“š
            if not enable_filter:
                logger.info(f"[æ–°èéæ¿¾é›†æˆ] éæ¿¾åŠŸèƒ½å·²ç¦ç”¨ï¼Œè¿”å›åŸå§‹æ–°èæ•¸æ“š")
                return news_df
            
            # å•Ÿç”¨æ–°èéæ¿¾
            filter_start_time = datetime.now()
            
            try:
                # å°å…¥éæ¿¾å™¨
                from tradingagents.utils.enhanced_news_filter import create_enhanced_news_filter
                
                # å‰µå»ºéæ¿¾å™¨
                news_filter = create_enhanced_news_filter(
                    symbol, 
                    use_semantic=use_semantic, 
                    use_local_model=use_local_model
                )
                
                # åŸ·è¡Œéæ¿¾
                filtered_df = news_filter.filter_news_enhanced(news_df, min_score=min_score)
                
                filter_time = (datetime.now() - filter_start_time).total_seconds()
                
                # è¨˜éŒ„éæ¿¾çµ±è¨ˆ
                original_count = len(news_df)
                filtered_count = len(filtered_df)
                filter_rate = (original_count - filtered_count) / original_count * 100 if original_count > 0 else 0
                
                logger.info(f"[æ–°èéæ¿¾é›†æˆ] æ–°èéæ¿¾å®Œæˆ:")
                logger.info(f"  - åŸå§‹æ–°è: {original_count}æ¢")
                logger.info(f"  - éæ¿¾å¾Œæ–°è: {filtered_count}æ¢")
                logger.info(f"  - éæ¿¾ç‡: {filter_rate:.1f}%")
                logger.info(f"  - éæ¿¾è€—æ™‚: {filter_time:.2f}ç§’")
                
                if not filtered_df.empty:
                    avg_score = filtered_df['final_score'].mean()
                    max_score = filtered_df['final_score'].max()
                    logger.info(f"  - å¹³å‡è©•åˆ†: {avg_score:.1f}")
                    logger.info(f"  - æœ€é«˜è©•åˆ†: {max_score:.1f}")
                
                return filtered_df
                
            except Exception as filter_error:
                logger.error(f"[æ–°èéæ¿¾é›†æˆ] æ–°èéæ¿¾å¤±è´¥: {filter_error}")
                logger.error(f"[æ–°èéæ¿¾é›†æˆ] è¿”å›åŸå§‹æ–°èæ•¸æ“šä½œç‚ºå¤‡ç”¨")
                return news_df
                
        except Exception as fetch_error:
            logger.error(f"[æ–°èéæ¿¾é›†æˆ] åŸå§‹æ–°èç²å–å¤±è´¥: {fetch_error}")
            return pd.DataFrame()  # è¿”å›ç©ºDataFrame
    
    return filtered_get_stock_news_em


def patch_akshare_utils():
    """
    ç‚ºakshare_utilsæ¨¡å¡Šçš„get_stock_news_emå‡½æ•¸æ·»åŠ éæ¿¾åŠŸèƒ½
    """
    try:
        from tradingagents.dataflows import akshare_utils
        
        # ä¿å­˜åŸå§‹å‡½æ•¸
        if not hasattr(akshare_utils, '_original_get_stock_news_em'):
            akshare_utils._original_get_stock_news_em = akshare_utils.get_stock_news_em
            
            # æ‡‰ç”¨éæ¿¾è£é¥°å™¨
            akshare_utils.get_stock_news_em = integrate_news_filtering(
                akshare_utils._original_get_stock_news_em
            )
            
            logger.info("[æ–°èéæ¿¾é›†æˆ] âœ… æˆåŠŸç‚ºakshare_utils.get_stock_news_emæ·»åŠ éæ¿¾åŠŸèƒ½")
        else:
            logger.info("[æ–°èéæ¿¾é›†æˆ] akshare_utils.get_stock_news_emå·²ç¶“è¢«å¢å¼º")
            
    except Exception as e:
        logger.error(f"[æ–°èéæ¿¾é›†æˆ] ç„¡æ³•å¢å¼ºakshare_utils.get_stock_news_em: {e}")


def create_filtered_realtime_news_function():
    """
    å‰µå»ºå¢å¼ºç‰ˆçš„å¯¦æ™‚æ–°èç²å–å‡½æ•¸
    """
    def get_filtered_realtime_stock_news(ticker: str, curr_date: str, hours_back: int = 6, 
                                       enable_filter: bool = True, min_score: float = 30) -> str:
        """
        å¢å¼ºç‰ˆå¯¦æ™‚æ–°èç²å–å‡½æ•¸ï¼Œé›†æˆæ–°èéæ¿¾
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç¢¼
            curr_date: ç•¶å‰æ—¥æœŸ
            hours_back: å›æº¯å°æ™‚æ•¸
            enable_filter: æ˜¯å¦å•Ÿç”¨æ–°èéæ¿¾
            min_score: æœ€ä½ç›¸é—œæ€§è©•åˆ†é˜ˆå€¼
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ–°èå ±å‘Š
        """
        logger.info(f"[å¢å¼ºå¯¦æ™‚æ–°è] é–‹å§‹ç²å– {ticker} çš„éæ¿¾æ–°è")
        
        try:
            # å°å…¥åŸå§‹å‡½æ•¸
            from tradingagents.dataflows.realtime_news_utils import get_realtime_stock_news
            
            # èª¿ç”¨åŸå§‹å‡½æ•¸ç²å–æ–°è
            original_report = get_realtime_stock_news(ticker, curr_date, hours_back)
            
            if not enable_filter:
                logger.info(f"[å¢å¼ºå¯¦æ™‚æ–°è] éæ¿¾åŠŸèƒ½å·²ç¦ç”¨ï¼Œè¿”å›åŸå§‹å ±å‘Š")
                return original_report
            
            # å¦‚æœå•Ÿç”¨éæ¿¾ä¸”æ˜¯Aè‚¡ï¼Œå˜—è©¦é‡æ–°ç²å–ä¸¦éæ¿¾
            if any(suffix in ticker for suffix in ['.SH', '.SZ', '.SS', '.XSHE', '.XSHG']) or \
               (not '.' in ticker and ticker.isdigit()):
                
                logger.info(f"[å¢å¼ºå¯¦æ™‚æ–°è] æª¢æ¸¬åˆ°Aè‚¡ä»£ç¢¼ï¼Œå˜—è©¦ä½¿ç”¨éæ¿¾ç‰ˆä¸œæ–¹è²¡å¯Œæ–°è")
                
                try:
                    from tradingagents.dataflows.akshare_utils import get_stock_news_em
                    
                    # æ¸…ç†è‚¡ç¥¨ä»£ç¢¼
                    clean_ticker = ticker.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                                    .replace('.XSHE', '').replace('.XSHG', '')
                    
                    # å…ˆç²å–åŸå§‹æ–°è
                    original_news_df = get_stock_news_em(clean_ticker)
                     
                    if enable_filter and not original_news_df.empty:
                         # æ‡‰ç”¨æ–°èéæ¿¾
                         from tradingagents.utils.news_filter import create_news_filter
                         news_filter = create_news_filter(clean_ticker)
                         filtered_news_df = news_filter.filter_news(original_news_df, min_score=min_score)
                         
                         # è¨˜éŒ„éæ¿¾çµ±è¨ˆ
                         filter_stats = news_filter.get_filter_statistics(original_news_df, filtered_news_df)
                         logger.info(f"[æ–°èéæ¿¾é›†æˆ] æ–°èéæ¿¾å®Œæˆ:")
                         logger.info(f"  - åŸå§‹æ–°è: {len(original_news_df)}æ¢")
                         logger.info(f"  - éæ¿¾å¾Œæ–°è: {len(filtered_news_df)}æ¢")
                         logger.info(f"  - éæ¿¾ç‡: {filter_stats['filter_rate']:.1f}%")
                    else:
                         filtered_news_df = original_news_df
                    
                    if not filtered_news_df.empty:
                        # æ§‹å»ºéæ¿¾å¾Œçš„å ±å‘Š
                        news_count = len(filtered_news_df)
                        
                        report = f"# {ticker} éæ¿¾æ–°èå ±å‘Š\n\n"
                        report += f"ğŸ“… ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                        report += f"ğŸ“Š éæ¿¾å¾Œæ–°èæ€»æ•¸: {news_count}æ¢\n"
                        report += f"ğŸ” éæ¿¾é˜ˆå€¼: {min_score}åˆ†\n\n"
                        
                        # æ·»åŠ éæ¿¾çµ±è¨ˆä¿¡æ¯
                        if 'final_score' in filtered_news_df.columns:
                            avg_score = filtered_news_df['final_score'].mean()
                            max_score = filtered_news_df['final_score'].max()
                            report += f"ğŸ“ˆ å¹³å‡ç›¸é—œæ€§è©•åˆ†: {avg_score:.1f}åˆ†\n"
                            report += f"ğŸ† æœ€é«˜ç›¸é—œæ€§è©•åˆ†: {max_score:.1f}åˆ†\n\n"
                        
                        # æ·»åŠ æ–°èå…§å®¹
                        for idx, (_, row) in enumerate(filtered_news_df.iterrows()):
                            report += f"### {row.get('æ–°èæ¨™é¡Œ', 'ç„¡æ¨™é¡Œ')}\n"
                            report += f"ğŸ“… {row.get('ç™¼å¸ƒæ™‚é–“', 'ç„¡æ™‚é–“')}\n"
                            
                            if 'final_score' in row:
                                report += f"â­ ç›¸é—œæ€§è©•åˆ†: {row['final_score']:.1f}åˆ†\n"
                            
                            report += f"ğŸ”— {row.get('æ–°èéˆæ¥', 'ç„¡éˆæ¥')}\n\n"
                            report += f"{row.get('æ–°èå…§å®¹', 'ç„¡å…§å®¹')}\n\n"
                        
                        logger.info(f"[å¢å¼ºå¯¦æ™‚æ–°è] âœ… æˆåŠŸç”Ÿæˆéæ¿¾æ–°èå ±å‘Šï¼ŒåŒ…å« {news_count} æ¢é«˜è´¨é‡æ–°è")
                        return report
                    else:
                        logger.warning(f"[å¢å¼ºå¯¦æ™‚æ–°è] éæ¿¾å¾Œç„¡ç¬¦åˆæ¢ä»¶çš„æ–°èï¼Œè¿”å›åŸå§‹å ±å‘Š")
                        return original_report
                        
                except Exception as filter_error:
                    logger.error(f"[å¢å¼ºå¯¦æ™‚æ–°è] æ–°èéæ¿¾å¤±è´¥: {filter_error}")
                    return original_report
            else:
                logger.info(f"[å¢å¼ºå¯¦æ™‚æ–°è] éAè‚¡ä»£ç¢¼ï¼Œè¿”å›åŸå§‹å ±å‘Š")
                return original_report
                
        except Exception as e:
            logger.error(f"[å¢å¼ºå¯¦æ™‚æ–°è] å¢å¼ºæ–°èç²å–å¤±è´¥: {e}")
            return f"âŒ æ–°èç²å–å¤±è´¥: {str(e)}"
    
    return get_filtered_realtime_stock_news


# è‡ªå‹•æ‡‰ç”¨è£œä¸
def apply_news_filtering_patches():
    """
    è‡ªå‹•æ‡‰ç”¨æ–°èéæ¿¾è£œä¸
    """
    logger.info("[æ–°èéæ¿¾é›†æˆ] é–‹å§‹æ‡‰ç”¨æ–°èéæ¿¾è£œä¸...")
    
    # 1. å¢å¼ºakshare_utils
    patch_akshare_utils()
    
    # 2. å‰µå»ºå¢å¼ºç‰ˆå¯¦æ™‚æ–°èå‡½æ•¸
    enhanced_function = create_filtered_realtime_news_function()
    
    logger.info("[æ–°èéæ¿¾é›†æˆ] âœ… æ–°èéæ¿¾è£œä¸æ‡‰ç”¨å®Œæˆ")
    
    return enhanced_function


if __name__ == "__main__":
    # æ¸¬è©¦é›†æˆåŠŸèƒ½
    print("=== æ¸¬è©¦æ–°èéæ¿¾é›†æˆ ===")
    
    # æ‡‰ç”¨è£œä¸
    enhanced_news_function = apply_news_filtering_patches()
    
    # æ¸¬è©¦å¢å¼ºç‰ˆå‡½æ•¸
    test_result = enhanced_news_function(
        ticker="600036",
        curr_date="2024-07-28",
        enable_filter=True,
        min_score=30
    )
    
    print(f"æ¸¬è©¦çµæœé•·åº¦: {len(test_result)} å­—ç¬¦")
    print(f"æ¸¬è©¦çµæœé è¦½: {test_result[:200]}...")