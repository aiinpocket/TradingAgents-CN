#!/usr/bin/env python3
"""
Tushareæ•¸æ“šé©é…å™¨
æä¾›çµ±ä¸€çš„ä¸­åœ‹è‚¡ç¥¨æ•¸æ“šæ¥å£ï¼Œæ”¯æŒç·©å­˜å’ŒéŒ¯èª¤è™•ç†
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Union
import warnings
warnings.filterwarnings('ignore')

# å°å…¥çµ±ä¸€æ—¥èªŒç³»çµ±
from tradingagents.utils.logging_init import get_logger
logger = get_logger("default")

# å°å…¥Tushareå·¥å…·
try:
    from .tushare_utils import get_tushare_provider
    TUSHARE_AVAILABLE = True
except ImportError:
    TUSHARE_AVAILABLE = False
    logger.warning("âŒ Tushareå·¥å…·ä¸å¯ç”¨")

# å°å…¥ç·©å­˜ç®¡ç†å™¨
try:
    from .cache_manager import get_cache
    CACHE_AVAILABLE = True
except ImportError:
    CACHE_AVAILABLE = False
    logger.warning("âš ï¸ ç·©å­˜ç®¡ç†å™¨ä¸å¯ç”¨")


class TushareDataAdapter:
    """Tushareæ•¸æ“šé©é…å™¨"""
    
    def __init__(self, enable_cache: bool = True):
        """
        åˆå§‹åŒ–Tushareæ•¸æ“šé©é…å™¨
        
        Args:
            enable_cache: æ˜¯å¦å•Ÿç”¨ç·©å­˜
        """
        self.enable_cache = enable_cache and CACHE_AVAILABLE
        self.provider = None
        
        # åˆå§‹åŒ–ç·©å­˜ç®¡ç†å™¨
        self.cache_manager = None
        if self.enable_cache:
            try:
                from .cache_manager import get_cache
                self.cache_manager = get_cache()
            except Exception as e:
                logger.warning(f"âš ï¸ ç·©å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_cache = False

        # åˆå§‹åŒ–Tushareæä¾›å™¨
        if TUSHARE_AVAILABLE:
            try:
                self.provider = get_tushare_provider()
                if self.provider.connected:
                    logger.info("ğŸ“Š Tushareæ•¸æ“šé©é…å™¨åˆå§‹åŒ–å®Œæˆ")
                else:
                    logger.warning("âš ï¸ Tushareé€£æ¥å¤±è´¥ï¼Œæ•¸æ“šé©é…å™¨åŠŸèƒ½å—é™")
            except Exception as e:
                logger.warning(f"âš ï¸ Tushareæä¾›å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        else:
            logger.error("âŒ Tushareä¸å¯ç”¨")
    
    def get_stock_data(self, symbol: str, start_date: str = None, end_date: str = None, 
                      data_type: str = "daily") -> pd.DataFrame:
        """
        ç²å–è‚¡ç¥¨æ•¸æ“š
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            data_type: æ•¸æ“šé¡å‹ ("daily", "realtime")
            
        Returns:
            DataFrame: è‚¡ç¥¨æ•¸æ“š
        """
        if not self.provider or not self.provider.connected:
            logger.error("âŒ Tushareæ•¸æ“šæºä¸å¯ç”¨")
            return pd.DataFrame()

        try:
            logger.debug(f"ğŸ”„ ç²å–{symbol}æ•¸æ“š (é¡å‹: {data_type})...")

            # æ·»åŠ è©³ç´°çš„è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤æ—¥èªŒ
            logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] TushareAdapter.get_stock_data æ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç¢¼: '{symbol}' (é¡å‹: {type(symbol)})")
            logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] è‚¡ç¥¨ä»£ç¢¼é•·åº¦: {len(str(symbol))}")
            logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] è‚¡ç¥¨ä»£ç¢¼å­—ç¬¦: {list(str(symbol))}")

            if data_type == "daily":
                logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] èª¿ç”¨ _get_daily_dataï¼Œå‚³å…¥åƒæ•¸: symbol='{symbol}'")
                return self._get_daily_data(symbol, start_date, end_date)
            elif data_type == "realtime":
                return self._get_realtime_data(symbol)
            else:
                logger.error(f"âŒ ä¸æ”¯æŒçš„æ•¸æ“šé¡å‹: {data_type}")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"âŒ ç²å–{symbol}æ•¸æ“šå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _get_daily_data(self, symbol: str, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """ç²å–æ—¥ç·šæ•¸æ“š"""

        # è¨˜éŒ„è©³ç´°çš„èª¿ç”¨ä¿¡æ¯
        logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] _get_daily_data é–‹å§‹åŸ·è¡Œ")
        logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] è¼¸å…¥åƒæ•¸: symbol='{symbol}', start_date='{start_date}', end_date='{end_date}'")
        logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] ç·©å­˜å•Ÿç”¨ç‹€æ…‹: {self.enable_cache}")

        # 1. å˜—è©¦å¾ç·©å­˜ç²å–
        if self.enable_cache:
            try:
                logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] é–‹å§‹æŸ¥æ‰¾ç·©å­˜æ•¸æ“š...")
                cache_key = self.cache_manager.find_cached_stock_data(
                    symbol=symbol,
                    start_date=start_date,
                    end_date=end_date,
                    max_age_hours=24  # æ—¥ç·šæ•¸æ“šç·©å­˜24å°æ™‚
                )

                if cache_key:
                    logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] æ‰¾åˆ°ç·©å­˜é”®: {cache_key}")
                    cached_data = self.cache_manager.load_stock_data(cache_key)
                    if cached_data is not None:
                        # æª¢æŸ¥æ˜¯å¦ç‚ºDataFrameä¸”ä¸ç‚ºç©º
                        if hasattr(cached_data, 'empty') and not cached_data.empty:
                            logger.debug(f"ğŸ“¦ å¾ç·©å­˜ç²å–{symbol}æ•¸æ“š: {len(cached_data)}æ¢")
                            logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] ç·©å­˜æ•¸æ“šæœ‰æ•ˆï¼Œç¢ºä¿æ¨™æº–åŒ–å¾Œè¿”å›")
                            # ç¢ºä¿ç·©å­˜æ•¸æ“šä¹Ÿç¶“éæ¨™æº–åŒ–é©—è­‰ï¼ˆä¿®è¤‡KeyError: 'volume'å•é¡Œï¼‰
                            return self._validate_and_standardize_data(cached_data)
                        elif isinstance(cached_data, str) and cached_data.strip():
                            logger.debug(f"ğŸ“¦ å¾ç·©å­˜ç²å–{symbol}æ•¸æ“š: å­—ç¬¦ä¸²æ ¼å¼")
                            logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] ç·©å­˜æ•¸æ“šç‚ºå­—ç¬¦ä¸²æ ¼å¼")
                            return cached_data
                        else:
                            logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] ç·©å­˜æ•¸æ“šç„¡æ•ˆ: {type(cached_data)}")
                    else:
                        logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] ç·©å­˜æ•¸æ“šç‚ºNone")
                else:
                    logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] æœªæ‰¾åˆ°æœ‰æ•ˆç·©å­˜")
            except Exception as e:
                logger.warning(f"âš ï¸ ç·©å­˜ç²å–å¤±è´¥: {e}")
                logger.warning(f"âš ï¸ [TushareAdapterè©³ç´°æ—¥èªŒ] ç·©å­˜ç•°å¸¸é¡å‹: {type(e).__name__}")
        else:
            logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] ç·©å­˜æœªå•Ÿç”¨ï¼Œç›´æ¥å¾APIç²å–")

        # 2. å¾Tushareç²å–æ•¸æ“š
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] _get_daily_data èª¿ç”¨ provider.get_stock_dailyï¼Œå‚³å…¥åƒæ•¸: symbol='{symbol}'")
        logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] é–‹å§‹èª¿ç”¨Tushare Provider...")

        import time
        provider_start_time = time.time()
        data = self.provider.get_stock_daily(symbol, start_date, end_date)
        provider_duration = time.time() - provider_start_time

        logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] Providerèª¿ç”¨å®Œæˆï¼Œè€—æ™‚: {provider_duration:.3f}ç§’")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] adapter.get_stock_data è¿”å›æ•¸æ“šå½¢ç‹€: {data.shape if data is not None and hasattr(data, 'shape') else 'None'}")

        if data is not None and not data.empty:
            logger.debug(f"âœ… å¾Tushareç²å–{symbol}æ•¸æ“šæˆåŠŸ: {len(data)}æ¢")
            logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] provider.get_stock_daily è¿”å›æ•¸æ“šå½¢ç‹€: {data.shape}")
            logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] æ•¸æ“šç²å–æˆåŠŸï¼Œé–‹å§‹æª¢æŸ¥æ•¸æ“šå…§å®¹...")

            # æª¢æŸ¥æ•¸æ“šä¸­çš„è‚¡ç¥¨ä»£ç¢¼åˆ—
            if 'ts_code' in data.columns:
                unique_codes = data['ts_code'].unique()
                logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] è¿”å›æ•¸æ“šä¸­çš„è‚¡ç¥¨ä»£ç¢¼: {unique_codes}")
            if 'symbol' in data.columns:
                unique_symbols = data['symbol'].unique()
                logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç¢¼è¿½è¹¤] è¿”å›æ•¸æ“šä¸­çš„symbol: {unique_symbols}")

            logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] é–‹å§‹æ¨™æº–åŒ–æ•¸æ“š...")
            standardized_data = self._standardize_data(data)
            logger.info(f"ğŸ” [TushareAdapterè©³ç´°æ—¥èªŒ] æ•¸æ“šæ¨™æº–åŒ–å®Œæˆ")
            return standardized_data
        else:
            logger.warning(f"âš ï¸ Tushareè¿”å›ç©ºæ•¸æ“š")
            logger.warning(f"âš ï¸ [TushareAdapterè©³ç´°æ—¥èªŒ] ç©ºæ•¸æ“šè©³æƒ…: data={data}, type={type(data)}")
            if data is not None:
                logger.warning(f"âš ï¸ [TushareAdapterè©³ç´°æ—¥èªŒ] DataFrameç‚ºç©º: {data.empty}")
            return pd.DataFrame()
    
    def _get_realtime_data(self, symbol: str) -> pd.DataFrame:
        """ç²å–å¯¦æ™‚æ•¸æ“šï¼ˆä½¿ç”¨æœ€æ–°æ—¥ç·šæ•¸æ“šï¼‰"""
        
        # Tushareå…è²»ç‰ˆä¸æ”¯æŒå¯¦æ™‚æ•¸æ“šï¼Œä½¿ç”¨æœ€æ–°æ—¥ç·šæ•¸æ“š
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=5)).strftime('%Y-%m-%d')
        
        data = self.provider.get_stock_daily(symbol, start_date, end_date)
        
        if data is not None and not data.empty:
            # è¿”å›æœ€æ–°ä¸€æ¢æ•¸æ“š
            latest_data = data.tail(1)
            logger.debug(f"âœ… å¾Tushareç²å–{symbol}æœ€æ–°æ•¸æ“š")
            return self._standardize_data(latest_data)
        else:
            logger.warning(f"âš ï¸ ç„¡æ³•ç²å–{symbol}å¯¦æ™‚æ•¸æ“š")
            return pd.DataFrame()
    
    def _validate_and_standardize_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """é©—è­‰ä¸¦æ¨™æº–åŒ–æ•¸æ“šæ ¼å¼ï¼Œå¢å¼ºç‰ˆæœ¬ï¼ˆä¿®è¤‡KeyError: 'volume'å•é¡Œï¼‰"""
        if data.empty:
            logger.info("ğŸ” [æ•¸æ“šæ¨™æº–åŒ–] è¼¸å…¥æ•¸æ“šç‚ºç©ºï¼Œç›´æ¥è¿”å›")
            return data

        try:
            logger.info(f"ğŸ” [æ•¸æ“šæ¨™æº–åŒ–] é–‹å§‹æ¨™æº–åŒ–æ•¸æ“šï¼Œè¼¸å…¥åˆ—å: {list(data.columns)}")

            # è¤‡åˆ¶æ•¸æ“šé¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
            standardized = data.copy()

            # åˆ—åæ˜ å°„
            column_mapping = {
                'trade_date': 'date',
                'ts_code': 'code',
                'open': 'open',
                'high': 'high',
                'low': 'low',
                'close': 'close',
                'vol': 'volume',  # é—œé”®æ˜ å°„ï¼švol -> volume
                'amount': 'amount',
                'pct_chg': 'pct_change',
                'change': 'change'
            }

            # è¨˜éŒ„æ˜ å°„éç¨‹
            mapped_columns = []

            # é‡å‘½ååˆ—
            for old_col, new_col in column_mapping.items():
                if old_col in standardized.columns:
                    standardized = standardized.rename(columns={old_col: new_col})
                    mapped_columns.append(f"{old_col}->{new_col}")
                    logger.debug(f"ğŸ”„ [æ•¸æ“šæ¨™æº–åŒ–] åˆ—æ˜ å°„: {old_col} -> {new_col}")

            logger.info(f"ğŸ” [æ•¸æ“šæ¨™æº–åŒ–] å®Œæˆåˆ—æ˜ å°„: {mapped_columns}")

            # é©—è­‰é—œé”®åˆ—æ˜¯å¦å­˜åœ¨ï¼Œæ·»åŠ å¤‡ç”¨è™•ç†
            required_columns = ['volume', 'close', 'high', 'low']
            missing_columns = [col for col in required_columns if col not in standardized.columns]
            if missing_columns:
                logger.warning(f"âš ï¸ [æ•¸æ“šæ¨™æº–åŒ–] ç¼ºå°‘é—œé”®åˆ—: {missing_columns}")
                self._add_fallback_columns(standardized, missing_columns, data)

            # ç¢ºä¿æ—¥æœŸåˆ—å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º
            if 'date' in standardized.columns:
                standardized['date'] = pd.to_datetime(standardized['date'])
                standardized = standardized.sort_values('date')
                logger.debug("âœ… [æ•¸æ“šæ¨™æº–åŒ–] æ—¥æœŸåˆ—æ ¼å¼åŒ–å®Œæˆ")

            # æ·»åŠ è‚¡ç¥¨ä»£ç¢¼åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if 'code' in standardized.columns and 'è‚¡ç¥¨ä»£ç¢¼' not in standardized.columns:
                standardized['è‚¡ç¥¨ä»£ç¢¼'] = standardized['code'].str.replace('.SH', '').str.replace('.SZ', '').str.replace('.BJ', '')
                logger.debug("âœ… [æ•¸æ“šæ¨™æº–åŒ–] è‚¡ç¥¨ä»£ç¢¼åˆ—æ·»åŠ å®Œæˆ")

            # æ·»åŠ æ¶¨è·Œå¹…åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if 'pct_change' in standardized.columns and 'æ¶¨è·Œå¹…' not in standardized.columns:
                standardized['æ¶¨è·Œå¹…'] = standardized['pct_change']
                logger.debug("âœ… [æ•¸æ“šæ¨™æº–åŒ–] æ¶¨è·Œå¹…åˆ—æ·»åŠ å®Œæˆ")

            logger.info("âœ… [æ•¸æ“šæ¨™æº–åŒ–] æ•¸æ“šæ¨™æº–åŒ–å®Œæˆ")
            return standardized

        except Exception as e:
            logger.error(f"âŒ [æ•¸æ“šæ¨™æº–åŒ–] æ•¸æ“šæ¨™æº–åŒ–å¤±è´¥: {e}", exc_info=True)
            logger.error(f"âŒ [æ•¸æ“šæ¨™æº–åŒ–] åŸå§‹æ•¸æ“šåˆ—å: {list(data.columns) if not data.empty else 'ç©ºæ•¸æ“š'}")
            return data

    def _add_fallback_columns(self, standardized: pd.DataFrame, missing_columns: list, original_data: pd.DataFrame):
        """ç‚ºç¼ºå¤±çš„é—œé”®åˆ—æ·»åŠ å¤‡ç”¨å€¼"""
        try:
            import numpy as np
            for col in missing_columns:
                if col == 'volume':
                    # å˜—è©¦å¯»æ‰¾å¯èƒ½çš„æˆäº¤é‡åˆ—å
                    volume_candidates = ['vol', 'volume', 'turnover', 'trade_volume']
                    for candidate in volume_candidates:
                        if candidate in original_data.columns:
                            standardized['volume'] = original_data[candidate]
                            logger.info(f"âœ… [æ•¸æ“šæ¨™æº–åŒ–] ä½¿ç”¨å¤‡ç”¨åˆ— {candidate} ä½œç‚º volume")
                            break
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°ä»»ä½•æˆäº¤é‡åˆ—ï¼Œè¨­ç½®ç‚º0
                        standardized['volume'] = 0
                        logger.warning(f"âš ï¸ [æ•¸æ“šæ¨™æº–åŒ–] æœªæ‰¾åˆ°æˆäº¤é‡æ•¸æ“šï¼Œè¨­ç½®ç‚º0")

                elif col in ['close', 'high', 'low', 'open']:
                    # å°æ–¼åƒ¹æ ¼åˆ—ï¼Œå¦‚æœç¼ºå¤±å‰‡è¨­ç½®ç‚ºNaN
                    if col not in standardized.columns:
                        standardized[col] = np.nan
                        logger.warning(f"âš ï¸ [æ•¸æ“šæ¨™æº–åŒ–] ç¼ºå¤±åƒ¹æ ¼åˆ— {col}ï¼Œè¨­ç½®ç‚ºNaN")

        except Exception as e:
            logger.error(f"âŒ [æ•¸æ“šæ¨™æº–åŒ–] æ·»åŠ å¤‡ç”¨åˆ—å¤±è´¥: {e}")

    def _standardize_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ¨™æº–åŒ–æ•¸æ“šæ ¼å¼ - ä¿æŒå‘å¾Œå…¼å®¹æ€§ï¼Œèª¿ç”¨å¢å¼ºç‰ˆæœ¬"""
        return self._validate_and_standardize_data(data)
    
    def get_stock_info(self, symbol: str) -> Dict:
        """
        ç²å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            Dict: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        """
        if not self.provider or not self.provider.connected:
            return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'unknown'}
        
        try:
            info = self.provider.get_stock_info(symbol)
            if info and info.get('name') and info.get('name') != f'è‚¡ç¥¨{symbol}':
                logger.debug(f"âœ… å¾Tushareç²å–{symbol}åŸºæœ¬ä¿¡æ¯æˆåŠŸ")
                return info
            else:
                return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'unknown'}

        except Exception as e:
            logger.error(f"âŒ ç²å–{symbol}è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'unknown'}
    
    def search_stocks(self, keyword: str) -> pd.DataFrame:
        """
        æœç´¢è‚¡ç¥¨
        
        Args:
            keyword: æœç´¢é—œé”®è©
            
        Returns:
            DataFrame: æœç´¢çµæœ
        """
        if not self.provider or not self.provider.connected:
            logger.error("âŒ Tushareæ•¸æ“šæºä¸å¯ç”¨")
            return pd.DataFrame()

        try:
            results = self.provider.search_stocks(keyword)

            if results is not None and not results.empty:
                logger.debug(f"âœ… æœç´¢'{keyword}'æˆåŠŸ: {len(results)}æ¢çµæœ")
                return results
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…'{keyword}'çš„è‚¡ç¥¨")
                return pd.DataFrame()

        except Exception as e:
            logger.error(f"âŒ æœç´¢è‚¡ç¥¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_fundamentals(self, symbol: str) -> str:
        """
        ç²å–åŸºæœ¬é¢æ•¸æ“š
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            str: åŸºæœ¬é¢åˆ†æå ±å‘Š
        """
        if not self.provider or not self.provider.connected:
            return f"âŒ Tushareæ•¸æ“šæºä¸å¯ç”¨ï¼Œç„¡æ³•ç²å–{symbol}åŸºæœ¬é¢æ•¸æ“š"
        
        try:
            logger.debug(f"ğŸ“Š ç²å–{symbol}åŸºæœ¬é¢æ•¸æ“š...")

            # ç²å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = self.get_stock_info(symbol)
            
            # ç²å–è²¡å‹™æ•¸æ“š
            financial_data = self.provider.get_financial_data(symbol)
            
            # ç”ŸæˆåŸºæœ¬é¢åˆ†æå ±å‘Š
            report = self._generate_fundamentals_report(symbol, stock_info, financial_data)
            
            # ç·©å­˜åŸºæœ¬é¢æ•¸æ“š
            if self.enable_cache and self.cache_manager:
                try:
                    cache_key = self.cache_manager.save_fundamentals_data(
                        symbol=symbol,
                        fundamentals_data=report,
                        data_source="tushare_analysis"
                    )
                    logger.debug(f"ğŸ’¼ Aè‚¡åŸºæœ¬é¢æ•¸æ“šå·²ç·©å­˜: {symbol} (tushare_analysis) -> {cache_key}")
                except Exception as e:
                    logger.warning(f"âš ï¸ åŸºæœ¬é¢æ•¸æ“šç·©å­˜å¤±è´¥: {e}")

            return report

        except Exception as e:
            logger.error(f"âŒ ç²å–{symbol}åŸºæœ¬é¢æ•¸æ“šå¤±è´¥: {e}")
            return f"âŒ ç²å–{symbol}åŸºæœ¬é¢æ•¸æ“šå¤±è´¥: {e}"
    
    def _generate_fundamentals_report(self, symbol: str, stock_info: Dict, financial_data: Dict) -> str:
        """ç”ŸæˆåŸºæœ¬é¢åˆ†æå ±å‘Š"""
        
        report = f"ğŸ“Š {symbol} åŸºæœ¬é¢åˆ†æå ±å‘Š (Tushareæ•¸æ“šæº)\n"
        report += "=" * 50 + "\n\n"
        
        # åŸºæœ¬ä¿¡æ¯
        report += "ğŸ“‹ åŸºæœ¬ä¿¡æ¯\n"
        report += f"è‚¡ç¥¨ä»£ç¢¼: {symbol}\n"
        report += f"è‚¡ç¥¨åç¨±: {stock_info.get('name', 'æœªçŸ¥')}\n"
        report += f"æ‰€å±¬åœ°åŒº: {stock_info.get('area', 'æœªçŸ¥')}\n"
        report += f"æ‰€å±¬è¡Œæ¥­: {stock_info.get('industry', 'æœªçŸ¥')}\n"
        report += f"ä¸Šå¸‚å¸‚å ´: {stock_info.get('market', 'æœªçŸ¥')}\n"
        report += f"ä¸Šå¸‚æ—¥æœŸ: {stock_info.get('list_date', 'æœªçŸ¥')}\n\n"
        
        # è²¡å‹™æ•¸æ“š
        if financial_data:
            report += "ğŸ’° è²¡å‹™æ•¸æ“š\n"
            
            # è³‡ç”¢è´Ÿå€ºè¡¨
            balance_sheet = financial_data.get('balance_sheet', [])
            if balance_sheet:
                latest_balance = balance_sheet[0] if balance_sheet else {}
                report += f"æ€»è³‡ç”¢: {latest_balance.get('total_assets', 'N/A')}\n"
                report += f"æ€»è´Ÿå€º: {latest_balance.get('total_liab', 'N/A')}\n"
                report += f"è‚¡ä¸œæ¬Šç›Š: {latest_balance.get('total_hldr_eqy_exc_min_int', 'N/A')}\n"
            
            # åˆ©æ¶¦è¡¨
            income_statement = financial_data.get('income_statement', [])
            if income_statement:
                latest_income = income_statement[0] if income_statement else {}
                report += f"ç‡Ÿæ¥­æ”¶å…¥: {latest_income.get('total_revenue', 'N/A')}\n"
                report += f"ç‡Ÿæ¥­åˆ©æ¶¦: {latest_income.get('operate_profit', 'N/A')}\n"
                report += f"å‡€åˆ©æ¶¦: {latest_income.get('n_income', 'N/A')}\n"
            
            # ç¾é‡‘æµé‡è¡¨
            cash_flow = financial_data.get('cash_flow', [])
            if cash_flow:
                latest_cash = cash_flow[0] if cash_flow else {}
                report += f"ç¶“ç‡Ÿæ´»å‹•ç¾é‡‘æµ: {latest_cash.get('c_fr_sale_sg', 'N/A')}\n"
        else:
            report += "ğŸ’° è²¡å‹™æ•¸æ“š: æš‚ç„¡æ•¸æ“š\n"
        
        report += f"\nğŸ“… å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"ğŸ“Š æ•¸æ“šä¾†æº: Tushare\n"
        
        return report


# å…¨å±€é©é…å™¨å¯¦ä¾‹
_tushare_adapter = None

def get_tushare_adapter() -> TushareDataAdapter:
    """ç²å–å…¨å±€Tushareæ•¸æ“šé©é…å™¨å¯¦ä¾‹"""
    global _tushare_adapter
    if _tushare_adapter is None:
        _tushare_adapter = TushareDataAdapter()
    return _tushare_adapter


def get_china_stock_data_tushare_adapter(symbol: str, start_date: str = None, end_date: str = None) -> pd.DataFrame:
    """
    ç²å–ä¸­åœ‹è‚¡ç¥¨æ•¸æ“šçš„ä¾¿æ·å‡½æ•¸ï¼ˆTushareé©é…å™¨ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç¢¼
        start_date: é–‹å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ
        
    Returns:
        DataFrame: è‚¡ç¥¨æ•¸æ“š
    """
    adapter = get_tushare_adapter()
    return adapter.get_stock_data(symbol, start_date, end_date)


def get_china_stock_info_tushare_adapter(symbol: str) -> Dict:
    """
    ç²å–ä¸­åœ‹è‚¡ç¥¨ä¿¡æ¯çš„ä¾¿æ·å‡½æ•¸ï¼ˆTushareé©é…å™¨ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç¢¼
        
    Returns:
        Dict: è‚¡ç¥¨ä¿¡æ¯
    """
    adapter = get_tushare_adapter()
    return adapter.get_stock_info(symbol)
