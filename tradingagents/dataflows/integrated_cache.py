#!/usr/bin/env python3
"""
é›†æˆç·©å­˜ç®¡ç†å™¨
çµåˆåŸæœ‰ç·©å­˜ç³»çµ±å’Œæ–°çš„è‡ªé©æ‡‰æ•¸æ“šåº«æ”¯æŒ
æä¾›å‘å¾Œå…¼å®¹çš„æ¥å£
"""

import os
import logging
from pathlib import Path
from typing import Any, Dict, Optional, Union
import pandas as pd

# å°å…¥çµ±ä¸€æ—¥èªŒç³»çµ±
from tradingagents.utils.logging_init import setup_dataflow_logging

# å°å…¥åŸæœ‰ç·©å­˜ç³»çµ±
from .cache_manager import StockDataCache

# å°å…¥è‡ªé©æ‡‰ç·©å­˜ç³»çµ±
try:
    from .adaptive_cache import get_cache_system
    from ..config.database_manager import get_database_manager
    ADAPTIVE_CACHE_AVAILABLE = True
except ImportError:
    ADAPTIVE_CACHE_AVAILABLE = False

class IntegratedCacheManager:
    """é›†æˆç·©å­˜ç®¡ç†å™¨ - æ™ºèƒ½é¸æ“‡ç·©å­˜ç­–ç•¥"""
    
    def __init__(self, cache_dir: str = None):
        self.logger = setup_dataflow_logging()
        
        # åˆå§‹åŒ–åŸæœ‰ç·©å­˜ç³»çµ±ï¼ˆä½œç‚ºå¤‡ç”¨ï¼‰
        self.legacy_cache = StockDataCache(cache_dir)
        
        # å˜—è©¦åˆå§‹åŒ–è‡ªé©æ‡‰ç·©å­˜ç³»çµ±
        self.adaptive_cache = None
        self.use_adaptive = False
        
        if ADAPTIVE_CACHE_AVAILABLE:
            try:
                self.adaptive_cache = get_cache_system()
                self.db_manager = get_database_manager()
                self.use_adaptive = True
                self.logger.info("âœ… è‡ªé©æ‡‰ç·©å­˜ç³»çµ±å·²å•Ÿç”¨")
            except Exception as e:
                self.logger.warning(f"è‡ªé©æ‡‰ç·©å­˜ç³»çµ±åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨å‚³çµ±ç·©å­˜: {e}")
                self.use_adaptive = False
        else:
            self.logger.info("è‡ªé©æ‡‰ç·©å­˜ç³»çµ±ä¸å¯ç”¨ï¼Œä½¿ç”¨å‚³çµ±æ–‡ä»¶ç·©å­˜")
        
        # é¡¯ç¤ºç•¶å‰é…ç½®
        self._log_cache_status()
    
    def _log_cache_status(self):
        """è¨˜éŒ„ç·©å­˜ç‹€æ…‹"""
        if self.use_adaptive:
            backend = self.adaptive_cache.primary_backend
            mongodb_available = self.db_manager.is_mongodb_available()
            redis_available = self.db_manager.is_redis_available()
            
            self.logger.info(f"ğŸ“Š ç·©å­˜é…ç½®:")
            self.logger.info(f"  ä¸»è¦å¾Œç«¯: {backend}")
            self.logger.info(f"  MongoDB: {'âœ… å¯ç”¨' if mongodb_available else 'âŒ ä¸å¯ç”¨'}")
            self.logger.info(f"  Redis: {'âœ… å¯ç”¨' if redis_available else 'âŒ ä¸å¯ç”¨'}")
            self.logger.info(f"  é™ç´šæ”¯æŒ: {'âœ… å•Ÿç”¨' if self.adaptive_cache.fallback_enabled else 'âŒ ç¦ç”¨'}")
        else:
            self.logger.info("ğŸ“ ä½¿ç”¨å‚³çµ±æ–‡ä»¶ç·©å­˜ç³»çµ±")
    
    def save_stock_data(self, symbol: str, data: Any, start_date: str = None, 
                       end_date: str = None, data_source: str = "default") -> str:
        """
        ä¿å­˜è‚¡ç¥¨æ•¸æ“šåˆ°ç·©å­˜
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            data: è‚¡ç¥¨æ•¸æ“š
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            data_source: æ•¸æ“šæº
            
        Returns:
            ç·©å­˜é”®
        """
        if self.use_adaptive:
            # ä½¿ç”¨è‡ªé©æ‡‰ç·©å­˜ç³»çµ±
            return self.adaptive_cache.save_data(
                symbol=symbol,
                data=data,
                start_date=start_date or "",
                end_date=end_date or "",
                data_source=data_source,
                data_type="stock_data"
            )
        else:
            # ä½¿ç”¨å‚³çµ±ç·©å­˜ç³»çµ±
            return self.legacy_cache.save_stock_data(
                symbol=symbol,
                data=data,
                start_date=start_date,
                end_date=end_date,
                data_source=data_source
            )
    
    def load_stock_data(self, cache_key: str) -> Optional[Any]:
        """
        å¾ç·©å­˜åŠ è¼‰è‚¡ç¥¨æ•¸æ“š
        
        Args:
            cache_key: ç·©å­˜é”®
            
        Returns:
            è‚¡ç¥¨æ•¸æ“šæˆ–None
        """
        if self.use_adaptive:
            # ä½¿ç”¨è‡ªé©æ‡‰ç·©å­˜ç³»çµ±
            return self.adaptive_cache.load_data(cache_key)
        else:
            # ä½¿ç”¨å‚³çµ±ç·©å­˜ç³»çµ±
            return self.legacy_cache.load_stock_data(cache_key)
    
    def find_cached_stock_data(self, symbol: str, start_date: str = None, 
                              end_date: str = None, data_source: str = "default") -> Optional[str]:
        """
        æŸ¥æ‰¾ç·©å­˜çš„è‚¡ç¥¨æ•¸æ“š
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            data_source: æ•¸æ“šæº
            
        Returns:
            ç·©å­˜é”®æˆ–None
        """
        if self.use_adaptive:
            # ä½¿ç”¨è‡ªé©æ‡‰ç·©å­˜ç³»çµ±
            return self.adaptive_cache.find_cached_data(
                symbol=symbol,
                start_date=start_date or "",
                end_date=end_date or "",
                data_source=data_source,
                data_type="stock_data"
            )
        else:
            # ä½¿ç”¨å‚³çµ±ç·©å­˜ç³»çµ±
            return self.legacy_cache.find_cached_stock_data(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                data_source=data_source
            )
    
    def save_news_data(self, symbol: str, data: Any, data_source: str = "default") -> str:
        """ä¿å­˜æ–°èæ•¸æ“š"""
        if self.use_adaptive:
            return self.adaptive_cache.save_data(
                symbol=symbol,
                data=data,
                data_source=data_source,
                data_type="news_data"
            )
        else:
            return self.legacy_cache.save_news_data(symbol, data, data_source)
    
    def load_news_data(self, cache_key: str) -> Optional[Any]:
        """åŠ è¼‰æ–°èæ•¸æ“š"""
        if self.use_adaptive:
            return self.adaptive_cache.load_data(cache_key)
        else:
            return self.legacy_cache.load_news_data(cache_key)
    
    def save_fundamentals_data(self, symbol: str, data: Any, data_source: str = "default") -> str:
        """ä¿å­˜åŸºæœ¬é¢æ•¸æ“š"""
        if self.use_adaptive:
            return self.adaptive_cache.save_data(
                symbol=symbol,
                data=data,
                data_source=data_source,
                data_type="fundamentals_data"
            )
        else:
            return self.legacy_cache.save_fundamentals_data(symbol, data, data_source)
    
    def load_fundamentals_data(self, cache_key: str) -> Optional[Any]:
        """åŠ è¼‰åŸºæœ¬é¢æ•¸æ“š"""
        if self.use_adaptive:
            return self.adaptive_cache.load_data(cache_key)
        else:
            return self.legacy_cache.load_fundamentals_data(cache_key)
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """ç²å–ç·©å­˜çµ±è¨ˆä¿¡æ¯"""
        if self.use_adaptive:
            # ç²å–è‡ªé©æ‡‰ç·©å­˜çµ±è¨ˆ
            adaptive_stats = self.adaptive_cache.get_cache_stats()
            
            # æ·»åŠ å‚³çµ±ç·©å­˜çµ±è¨ˆ
            legacy_stats = self.legacy_cache.get_cache_stats()
            
            return {
                "cache_system": "adaptive",
                "adaptive_cache": adaptive_stats,
                "legacy_cache": legacy_stats,
                "database_available": self.db_manager.is_database_available(),
                "mongodb_available": self.db_manager.is_mongodb_available(),
                "redis_available": self.db_manager.is_redis_available()
            }
        else:
            # åªè¿”å›å‚³çµ±ç·©å­˜çµ±è¨ˆ
            legacy_stats = self.legacy_cache.get_cache_stats()
            return {
                "cache_system": "legacy",
                "legacy_cache": legacy_stats,
                "database_available": False,
                "mongodb_available": False,
                "redis_available": False
            }
    
    def clear_expired_cache(self):
        """æ¸…ç†éæœŸç·©å­˜"""
        if self.use_adaptive:
            self.adaptive_cache.clear_expired_cache()
        
        # æ€»æ˜¯æ¸…ç†å‚³çµ±ç·©å­˜
        self.legacy_cache.clear_expired_cache()
    
    def get_cache_backend_info(self) -> Dict[str, Any]:
        """ç²å–ç·©å­˜å¾Œç«¯ä¿¡æ¯"""
        if self.use_adaptive:
            return {
                "system": "adaptive",
                "primary_backend": self.adaptive_cache.primary_backend,
                "fallback_enabled": self.adaptive_cache.fallback_enabled,
                "mongodb_available": self.db_manager.is_mongodb_available(),
                "redis_available": self.db_manager.is_redis_available()
            }
        else:
            return {
                "system": "legacy",
                "primary_backend": "file",
                "fallback_enabled": False,
                "mongodb_available": False,
                "redis_available": False
            }
    
    def is_database_available(self) -> bool:
        """æª¢æŸ¥æ•¸æ“šåº«æ˜¯å¦å¯ç”¨"""
        if self.use_adaptive:
            return self.db_manager.is_database_available()
        return False
    
    def get_performance_mode(self) -> str:
        """ç²å–æ€§èƒ½æ¨¡å¼"""
        if not self.use_adaptive:
            return "åŸºç¡€æ¨¡å¼ (æ–‡ä»¶ç·©å­˜)"
        
        mongodb_available = self.db_manager.is_mongodb_available()
        redis_available = self.db_manager.is_redis_available()
        
        if redis_available and mongodb_available:
            return "é«˜æ€§èƒ½æ¨¡å¼ (Redis + MongoDB + æ–‡ä»¶)"
        elif redis_available:
            return "å¿«é€Ÿæ¨¡å¼ (Redis + æ–‡ä»¶)"
        elif mongodb_available:
            return "æŒä¹…åŒ–æ¨¡å¼ (MongoDB + æ–‡ä»¶)"
        else:
            return "æ¨™æº–æ¨¡å¼ (æ™ºèƒ½æ–‡ä»¶ç·©å­˜)"


# å…¨å±€é›†æˆç·©å­˜ç®¡ç†å™¨å¯¦ä¾‹
_integrated_cache = None

def get_cache() -> IntegratedCacheManager:
    """ç²å–å…¨å±€é›†æˆç·©å­˜ç®¡ç†å™¨å¯¦ä¾‹"""
    global _integrated_cache
    if _integrated_cache is None:
        _integrated_cache = IntegratedCacheManager()
    return _integrated_cache

# å‘å¾Œå…¼å®¹çš„å‡½æ•¸
def get_stock_cache():
    """å‘å¾Œå…¼å®¹ï¼šç²å–è‚¡ç¥¨ç·©å­˜"""
    return get_cache()

def create_cache_manager(cache_dir: str = None):
    """å‘å¾Œå…¼å®¹ï¼šå‰µå»ºç·©å­˜ç®¡ç†å™¨"""
    return IntegratedCacheManager(cache_dir)
