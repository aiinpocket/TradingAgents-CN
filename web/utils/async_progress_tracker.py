#!/usr/bin/env python3
"""
ç•°æ­¥é€²åº¦è·Ÿè¹¤å™¨
æ”¯æŒRediså’Œæ–‡ä»¶ä¸¤ç¨®å­˜å‚¨æ–¹å¼ï¼Œå‰ç«¯å®šæ™‚è½®è©¢ç²å–é€²åº¦
"""

import json
import time
import os
from typing import Dict, Any, Optional, List
from datetime import datetime
import threading
from pathlib import Path

# å°å…¥æ—¥èªŒæ¨¡å¡Š
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('async_progress')

def safe_serialize(obj):
    """å®‰å…¨åºåˆ—åŒ–å°è±¡ï¼Œè™•ç†ä¸å¯åºåˆ—åŒ–çš„é¡å‹"""
    # ç‰¹æ®Šè™•ç†LangChainæ¶ˆæ¯å°è±¡
    if hasattr(obj, '__class__') and 'Message' in obj.__class__.__name__:
        try:
            # å˜—è©¦ä½¿ç”¨LangChainçš„åºåˆ—åŒ–æ–¹æ³•
            if hasattr(obj, 'dict'):
                return obj.dict()
            elif hasattr(obj, 'to_dict'):
                return obj.to_dict()
            else:
                # æ‰‹å‹•æå–æ¶ˆæ¯å…§å®¹
                return {
                    'type': obj.__class__.__name__,
                    'content': getattr(obj, 'content', str(obj)),
                    'additional_kwargs': getattr(obj, 'additional_kwargs', {}),
                    'response_metadata': getattr(obj, 'response_metadata', {})
                }
        except Exception:
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›å­—ç¬¦ä¸²è¡¨ç¤º
            return {
                'type': obj.__class__.__name__,
                'content': str(obj)
            }
    
    if hasattr(obj, 'dict'):
        # Pydanticå°è±¡
        try:
            return obj.dict()
        except Exception:
            return str(obj)
    elif hasattr(obj, '__dict__'):
        # æ™®é€šå°è±¡ï¼Œè½‰æ›ç‚ºå­—å…¸
        result = {}
        for key, value in obj.__dict__.items():
            if not key.startswith('_'):  # è·³éç§æœ‰å±¬æ€§
                try:
                    json.dumps(value)  # æ¸¬è©¦æ˜¯å¦å¯åºåˆ—åŒ–
                    result[key] = value
                except (TypeError, ValueError):
                    result[key] = safe_serialize(value)  # éæ­¸è™•ç†
        return result
    elif isinstance(obj, (list, tuple)):
        return [safe_serialize(item) for item in obj]
    elif isinstance(obj, dict):
        return {key: safe_serialize(value) for key, value in obj.items()}
    else:
        try:
            json.dumps(obj)  # æ¸¬è©¦æ˜¯å¦å¯åºåˆ—åŒ–
            return obj
        except (TypeError, ValueError):
            return str(obj)  # è½‰æ›ç‚ºå­—ç¬¦ä¸²

class AsyncProgressTracker:
    """ç•°æ­¥é€²åº¦è·Ÿè¹¤å™¨"""
    
    def __init__(self, analysis_id: str, analysts: List[str], research_depth: int, llm_provider: str):
        self.analysis_id = analysis_id
        self.analysts = analysts
        self.research_depth = research_depth
        self.llm_provider = llm_provider
        self.start_time = time.time()
        
        # ç”Ÿæˆåˆ†ææ­¥éª¤
        self.analysis_steps = self._generate_dynamic_steps()
        self.estimated_duration = self._estimate_total_duration()
        
        # åˆå§‹åŒ–ç‹€æ…‹
        self.current_step = 0
        self.progress_data = {
            'analysis_id': analysis_id,
            'status': 'running',
            'current_step': 0,
            'total_steps': len(self.analysis_steps),
            'progress_percentage': 0.0,
            'current_step_name': self.analysis_steps[0]['name'],
            'current_step_description': self.analysis_steps[0]['description'],
            'elapsed_time': 0.0,
            'estimated_total_time': self.estimated_duration,
            'remaining_time': self.estimated_duration,
            'last_message': 'æº–å¤‡é–‹å§‹åˆ†æ...',
            'last_update': time.time(),
            'start_time': self.start_time,
            'steps': self.analysis_steps
        }
        
        # å˜—è©¦åˆå§‹åŒ–Redisï¼Œå¤±è´¥å‰‡ä½¿ç”¨æ–‡ä»¶
        self.redis_client = None
        self.use_redis = self._init_redis()
        
        if not self.use_redis:
            # ä½¿ç”¨æ–‡ä»¶å­˜å‚¨
            self.progress_file = f"./data/progress_{analysis_id}.json"
            os.makedirs(os.path.dirname(self.progress_file), exist_ok=True)
        
        # ä¿å­˜åˆå§‹ç‹€æ…‹
        self._save_progress()
        
        logger.info(f"ğŸ“Š [ç•°æ­¥é€²åº¦] åˆå§‹åŒ–å®Œæˆ: {analysis_id}, å­˜å‚¨æ–¹å¼: {'Redis' if self.use_redis else 'æ–‡ä»¶'}")

        # è¨»å†Šåˆ°æ—¥èªŒç³»çµ±é€²è¡Œè‡ªå‹•é€²åº¦æ›´æ–°
        try:
            from .progress_log_handler import register_analysis_tracker
            import threading

            # ä½¿ç”¨è¶…æ™‚æ©Ÿåˆ¶é¿å…æ­»é–
            def register_with_timeout():
                try:
                    register_analysis_tracker(self.analysis_id, self)
                    print(f"âœ… [é€²åº¦é›†æˆ] è·Ÿè¹¤å™¨è¨»å†ŠæˆåŠŸ: {self.analysis_id}")
                except Exception as e:
                    print(f"âŒ [é€²åº¦é›†æˆ] è·Ÿè¹¤å™¨è¨»å†Šå¤±è´¥: {e}")

            # åœ¨å–®ç¨ç·šç¨‹ä¸­è¨»å†Šï¼Œé¿å…é˜»å¡ä¸»ç·šç¨‹
            register_thread = threading.Thread(target=register_with_timeout, daemon=True)
            register_thread.start()
            register_thread.join(timeout=2.0)  # 2ç§’è¶…æ™‚

            if register_thread.is_alive():
                print(f"âš ï¸ [é€²åº¦é›†æˆ] è·Ÿè¹¤å™¨è¨»å†Šè¶…æ™‚ï¼Œç¹¼ç»­åŸ·è¡Œ: {self.analysis_id}")

        except ImportError:
            logger.debug("ğŸ“Š [ç•°æ­¥é€²åº¦] æ—¥èªŒé›†æˆä¸å¯ç”¨")
        except Exception as e:
            print(f"âŒ [é€²åº¦é›†æˆ] è·Ÿè¹¤å™¨è¨»å†Šç•°å¸¸: {e}")
    
    def _init_redis(self) -> bool:
        """åˆå§‹åŒ–Redisé€£æ¥"""
        try:
            # é¦–å…ˆæª¢æŸ¥REDIS_ENABLEDç’°å¢ƒè®Šé‡
            redis_enabled_raw = os.getenv('REDIS_ENABLED', 'false')
            redis_enabled = redis_enabled_raw.lower()
            logger.info(f"ğŸ” [Redisæª¢æŸ¥] REDIS_ENABLEDåŸå€¼='{redis_enabled_raw}' -> è™•ç†å¾Œ='{redis_enabled}'")

            if redis_enabled != 'true':
                logger.info(f"ğŸ“Š [ç•°æ­¥é€²åº¦] Rediså·²ç¦ç”¨ï¼Œä½¿ç”¨æ–‡ä»¶å­˜å‚¨")
                return False

            import redis

            # å¾ç’°å¢ƒè®Šé‡ç²å–Redisé…ç½®
            redis_host = os.getenv('REDIS_HOST', 'localhost')
            redis_port = int(os.getenv('REDIS_PORT', 6379))
            redis_password = os.getenv('REDIS_PASSWORD', None)
            redis_db = int(os.getenv('REDIS_DB', 0))

            # å‰µå»ºRedisé€£æ¥
            if redis_password:
                self.redis_client = redis.Redis(
                    host=redis_host,
                    port=redis_port,
                    password=redis_password,
                    db=redis_db,
                    decode_responses=True
                )
            else:
                self.redis_client = redis.Redis(
                    host=redis_host,
                    port=redis_port,
                    db=redis_db,
                    decode_responses=True
                )

            # æ¸¬è©¦é€£æ¥
            self.redis_client.ping()
            logger.info(f"ğŸ“Š [ç•°æ­¥é€²åº¦] Redisé€£æ¥æˆåŠŸ: {redis_host}:{redis_port}")
            return True
        except Exception as e:
            logger.warning(f"ğŸ“Š [ç•°æ­¥é€²åº¦] Redisé€£æ¥å¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶å­˜å‚¨: {e}")
            return False
    
    def _generate_dynamic_steps(self) -> List[Dict]:
        """æ ¹æ“šåˆ†æå¸«æ•¸é‡å’Œç ”ç©¶æ·±åº¦å‹•æ…‹ç”Ÿæˆåˆ†ææ­¥éª¤"""
        steps = [
            {"name": "ğŸ“‹ æº–å¤‡éšæ®µ", "description": "é©—è­‰è‚¡ç¥¨ä»£ç¢¼ï¼Œæª¢æŸ¥æ•¸æ“šæºå¯ç”¨æ€§", "weight": 0.05},
            {"name": "ğŸ”§ ç’°å¢ƒæª¢æŸ¥", "description": "æª¢æŸ¥APIå¯†é‘°é…ç½®ï¼Œç¢ºä¿æ•¸æ“šç²å–æ­£å¸¸", "weight": 0.02},
            {"name": "ğŸ’° æˆæœ¬ä¼°ç®—", "description": "æ ¹æ“šåˆ†ææ·±åº¦é ä¼°APIèª¿ç”¨æˆæœ¬", "weight": 0.01},
            {"name": "âš™ï¸ åƒæ•¸è¨­ç½®", "description": "é…ç½®åˆ†æåƒæ•¸å’ŒAIæ¨¡å‹é¸æ“‡", "weight": 0.02},
            {"name": "ğŸš€ å•Ÿå‹•å¼•æ“", "description": "åˆå§‹åŒ–AIåˆ†æå¼•æ“ï¼Œæº–å¤‡é–‹å§‹åˆ†æ", "weight": 0.05},
        ]

        # ç‚ºæ¯å€‹åˆ†æå¸«æ·»åŠ å°ˆé–€çš„æ­¥éª¤
        analyst_base_weight = 0.6 / len(self.analysts)  # 60%çš„æ™‚é–“ç”¨æ–¼åˆ†æå¸«å·¥ä½œ
        for analyst in self.analysts:
            analyst_info = self._get_analyst_step_info(analyst)
            steps.append({
                "name": analyst_info["name"],
                "description": analyst_info["description"],
                "weight": analyst_base_weight
            })

        # æ ¹æ“šç ”ç©¶æ·±åº¦æ·»åŠ å¾Œç»­æ­¥éª¤
        if self.research_depth >= 2:
            # æ¨™æº–å’Œæ·±åº¦åˆ†æåŒ…å«ç ”ç©¶å“¡è¾©è«–
            steps.extend([
                {"name": "ğŸ“ˆ å¤šå¤´è§€é»", "description": "å¾ä¹è§€è§’åº¦åˆ†ææŠ•è³‡æ©Ÿæœƒå’Œä¸Šæ¶¨æ½œåŠ›", "weight": 0.06},
                {"name": "ğŸ“‰ ç©ºå¤´è§€é»", "description": "å¾è°¨æ…è§’åº¦åˆ†ææŠ•è³‡é¢¨éšªå’Œä¸‹è·Œå¯èƒ½", "weight": 0.06},
                {"name": "ğŸ¤ è§€é»æ•´åˆ", "description": "ç»¼åˆå¤šç©ºè§€é»ï¼Œå½¢æˆå¹³è¡¡çš„æŠ•è³‡å»ºè®®", "weight": 0.05},
            ])

        # æ‰€æœ‰æ·±åº¦éƒ½åŒ…å«äº¤æ˜“æ±ºç­–
        steps.append({"name": "ğŸ’¡ æŠ•è³‡å»ºè®®", "description": "åŸºæ–¼åˆ†æçµæœåˆ¶å®šå…·é«”çš„ä¹°å–å»ºè®®", "weight": 0.06})

        if self.research_depth >= 3:
            # æ·±åº¦åˆ†æåŒ…å«è©³ç´°é¢¨éšªè©•ä¼°
            steps.extend([
                {"name": "ğŸ”¥ æ¿€é€²ç­–ç•¥", "description": "è©•ä¼°é«˜é¢¨éšªé«˜æ”¶ç›Šçš„æŠ•è³‡ç­–ç•¥", "weight": 0.03},
                {"name": "ğŸ›¡ï¸ ä¿å®ˆç­–ç•¥", "description": "è©•ä¼°ä½é¢¨éšªç©©å¥çš„æŠ•è³‡ç­–ç•¥", "weight": 0.03},
                {"name": "âš–ï¸ å¹³è¡¡ç­–ç•¥", "description": "è©•ä¼°é¢¨éšªæ”¶ç›Šå¹³è¡¡çš„æŠ•è³‡ç­–ç•¥", "weight": 0.03},
                {"name": "ğŸ¯ é¢¨éšªæ§åˆ¶", "description": "åˆ¶å®šé¢¨éšªæ§åˆ¶æªæ–½å’Œæ­¢æç­–ç•¥", "weight": 0.04},
            ])
        else:
            # å¿«é€Ÿå’Œæ¨™æº–åˆ†æçš„ç°¡åŒ–é¢¨éšªè©•ä¼°
            steps.append({"name": "âš ï¸ é¢¨éšªæç¤º", "description": "è¯†åˆ¥ä¸»è¦æŠ•è³‡é¢¨éšªä¸¦æä¾›é¢¨éšªæç¤º", "weight": 0.05})

        # æœ€å¾Œçš„æ•´ç†æ­¥éª¤
        steps.append({"name": "ğŸ“Š ç”Ÿæˆå ±å‘Š", "description": "æ•´ç†æ‰€æœ‰åˆ†æçµæœï¼Œç”Ÿæˆæœ€ç»ˆæŠ•è³‡å ±å‘Š", "weight": 0.04})

        # é‡æ–°å¹³è¡¡æ¬Šé‡ï¼Œç¢ºä¿æ€»å’Œç‚º1.0
        total_weight = sum(step["weight"] for step in steps)
        for step in steps:
            step["weight"] = step["weight"] / total_weight

        return steps
    
    def _get_analyst_display_name(self, analyst: str) -> str:
        """ç²å–åˆ†æå¸«é¡¯ç¤ºåç¨±ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        name_map = {
            'market': 'å¸‚å ´åˆ†æå¸«',
            'fundamentals': 'åŸºæœ¬é¢åˆ†æå¸«',
            'technical': 'æŠ€è¡“åˆ†æå¸«',
            'sentiment': 'æƒ…ç»ªåˆ†æå¸«',
            'risk': 'é¢¨éšªåˆ†æå¸«'
        }
        return name_map.get(analyst, f'{analyst}åˆ†æå¸«')

    def _get_analyst_step_info(self, analyst: str) -> Dict[str, str]:
        """ç²å–åˆ†æå¸«æ­¥éª¤ä¿¡æ¯ï¼ˆåç¨±å’Œæè¿°ï¼‰"""
        analyst_info = {
            'market': {
                "name": "ğŸ“Š å¸‚å ´åˆ†æ",
                "description": "åˆ†æè‚¡åƒ¹èµ°åŠ¿ã€æˆäº¤é‡ã€å¸‚å ´ç†±åº¦ç­‰å¸‚å ´è¡¨ç¾"
            },
            'fundamentals': {
                "name": "ğŸ’¼ åŸºæœ¬é¢åˆ†æ",
                "description": "åˆ†æå…¬å¸è²¡å‹™ç‹€å†µã€ç›ˆåˆ©èƒ½åŠ›ã€æˆé•·æ€§ç­‰åŸºæœ¬é¢"
            },
            'technical': {
                "name": "ğŸ“ˆ æŠ€è¡“åˆ†æ",
                "description": "åˆ†æKç·šåœ–å½¢ã€æŠ€è¡“æŒ‡æ¨™ã€æ”¯æ’‘é˜»åŠ›ç­‰æŠ€è¡“é¢"
            },
            'sentiment': {
                "name": "ğŸ’­ æƒ…ç»ªåˆ†æ",
                "description": "åˆ†æå¸‚å ´æƒ…ç»ªã€æŠ•è³‡è€…å¿ƒç†ã€èˆ†è«–å€¾å‘ç­‰"
            },
            'news': {
                "name": "ğŸ“° æ–°èåˆ†æ",
                "description": "åˆ†æç›¸é—œæ–°èã€å…¬å‘Šã€è¡Œæ¥­å‹•æ…‹å°è‚¡åƒ¹çš„å½±éŸ¿"
            },
            'social_media': {
                "name": "ğŸŒ ç¤¾äº¤åª’é«”",
                "description": "åˆ†æç¤¾äº¤åª’é«”è¨è«–ã€ç¶²çµ¡ç†±åº¦ã€æ•£æˆ¶æƒ…ç»ªç­‰"
            },
            'risk': {
                "name": "âš ï¸ é¢¨éšªåˆ†æ",
                "description": "è¯†åˆ¥æŠ•è³‡é¢¨éšªã€è©•ä¼°é¢¨éšªç­‰ç´šã€åˆ¶å®šé¢¨æ§æªæ–½"
            }
        }

        return analyst_info.get(analyst, {
            "name": f"ğŸ” {analyst}åˆ†æ",
            "description": f"é€²è¡Œ{analyst}ç›¸é—œçš„å°ˆæ¥­åˆ†æ"
        })
    
    def _estimate_total_duration(self) -> float:
        """æ ¹æ“šåˆ†æå¸«æ•¸é‡ã€ç ”ç©¶æ·±åº¦ã€æ¨¡å‹é¡å‹é ä¼°æ€»æ™‚é•·ï¼ˆç§’ï¼‰"""
        # åŸºç¡€æ™‚é–“ï¼ˆç§’ï¼‰- ç’°å¢ƒæº–å¤‡ã€é…ç½®ç­‰
        base_time = 60
        
        # æ¯å€‹åˆ†æå¸«çš„å¯¦é™…è€—æ™‚ï¼ˆåŸºæ–¼çœŸå¯¦æ¸¬è©¦æ•¸æ“šï¼‰
        analyst_base_time = {
            1: 120,  # å¿«é€Ÿåˆ†æï¼šæ¯å€‹åˆ†æå¸«ç´„2åˆ†é˜
            2: 180,  # åŸºç¡€åˆ†æï¼šæ¯å€‹åˆ†æå¸«ç´„3åˆ†é˜  
            3: 240   # æ¨™æº–åˆ†æï¼šæ¯å€‹åˆ†æå¸«ç´„4åˆ†é˜
        }.get(self.research_depth, 180)
        
        analyst_time = len(self.analysts) * analyst_base_time
        
        # æ¨¡å‹é€Ÿåº¦å½±éŸ¿ï¼ˆåŸºæ–¼å¯¦é™…æ¸¬è©¦ï¼‰
        model_multiplier = {
            'dashscope': 1.0,  # é˜¿é‡Œç™¾ç‚¼é€Ÿåº¦é©ä¸­
            'deepseek': 0.7,   # DeepSeekè¼ƒå¿«
            'google': 1.3      # Googleè¼ƒæ…¢
        }.get(self.llm_provider, 1.0)
        
        # ç ”ç©¶æ·±åº¦é¡å¤–å½±éŸ¿ï¼ˆå·¥å…·èª¿ç”¨è¤‡é›œåº¦ï¼‰
        depth_multiplier = {
            1: 0.8,  # å¿«é€Ÿåˆ†æï¼Œè¼ƒå°‘å·¥å…·èª¿ç”¨
            2: 1.0,  # åŸºç¡€åˆ†æï¼Œæ¨™æº–å·¥å…·èª¿ç”¨
            3: 1.3   # æ¨™æº–åˆ†æï¼Œæ›´å¤šå·¥å…·èª¿ç”¨å’Œæ¨ç†
        }.get(self.research_depth, 1.0)
        
        total_time = (base_time + analyst_time) * model_multiplier * depth_multiplier
        return total_time
    
    def update_progress(self, message: str, step: Optional[int] = None):
        """æ›´æ–°é€²åº¦ç‹€æ…‹"""
        current_time = time.time()
        elapsed_time = current_time - self.start_time

        # è‡ªå‹•æª¢æ¸¬æ­¥éª¤
        if step is None:
            step = self._detect_step_from_message(message)

        # æ›´æ–°æ­¥éª¤ï¼ˆé˜²æ­¢å€’é€€ï¼‰
        if step is not None and step >= self.current_step:
            self.current_step = step
            logger.debug(f"ğŸ“Š [ç•°æ­¥é€²åº¦] æ­¥éª¤æ¨é€²åˆ° {self.current_step + 1}/{len(self.analysis_steps)}")

        # å¦‚æœæ˜¯å®Œæˆæ¶ˆæ¯ï¼Œç¢ºä¿é€²åº¦ç‚º100%
        if "åˆ†æå®Œæˆ" in message or "åˆ†ææˆåŠŸ" in message or "âœ… åˆ†æå®Œæˆ" in message:
            self.current_step = len(self.analysis_steps) - 1
            logger.info(f"ğŸ“Š [ç•°æ­¥é€²åº¦] åˆ†æå®Œæˆï¼Œè¨­ç½®ç‚ºæœ€ç»ˆæ­¥éª¤")

        # è¨ˆç®—é€²åº¦
        progress_percentage = self._calculate_weighted_progress() * 100
        remaining_time = self._estimate_remaining_time(progress_percentage / 100, elapsed_time)

        # æ›´æ–°é€²åº¦æ•¸æ“š
        current_step_info = self.analysis_steps[self.current_step] if self.current_step < len(self.analysis_steps) else self.analysis_steps[-1]

        # ç‰¹æ®Šè™•ç†å·¥å…·èª¿ç”¨æ¶ˆæ¯ï¼Œæ›´æ–°æ­¥éª¤æè¿°ä½†ä¸æ”¹è®Šæ­¥éª¤
        step_description = current_step_info['description']
        if "å·¥å…·èª¿ç”¨" in message:
            # æå–å·¥å…·åç¨±ä¸¦æ›´æ–°æè¿°
            if "get_stock_market_data_unified" in message:
                step_description = "æ­£åœ¨ç²å–å¸‚å ´æ•¸æ“šå’ŒæŠ€è¡“æŒ‡æ¨™..."
            elif "get_stock_fundamentals_unified" in message:
                step_description = "æ­£åœ¨ç²å–åŸºæœ¬é¢æ•¸æ“šå’Œè²¡å‹™æŒ‡æ¨™..."
            elif "get_china_stock_data" in message:
                step_description = "æ­£åœ¨ç²å–Aè‚¡å¸‚å ´æ•¸æ“š..."
            elif "get_china_fundamentals" in message:
                step_description = "æ­£åœ¨ç²å–Aè‚¡åŸºæœ¬é¢æ•¸æ“š..."
            else:
                step_description = "æ­£åœ¨èª¿ç”¨åˆ†æå·¥å…·..."
        elif "æ¨¡å¡Šé–‹å§‹" in message:
            step_description = f"é–‹å§‹{current_step_info['name']}..."
        elif "æ¨¡å¡Šå®Œæˆ" in message:
            step_description = f"{current_step_info['name']}å·²å®Œæˆ"

        self.progress_data.update({
            'current_step': self.current_step,
            'progress_percentage': progress_percentage,
            'current_step_name': current_step_info['name'],
            'current_step_description': step_description,
            'elapsed_time': elapsed_time,
            'remaining_time': remaining_time,
            'last_message': message,
            'last_update': current_time,
            'status': 'completed' if progress_percentage >= 100 else 'running'
        })

        # ä¿å­˜åˆ°å­˜å‚¨
        self._save_progress()

        # è©³ç´°çš„æ›´æ–°æ—¥èªŒ
        step_name = current_step_info.get('name', 'æœªçŸ¥')
        logger.info(f"ğŸ“Š [é€²åº¦æ›´æ–°] {self.analysis_id}: {message[:50]}...")
        logger.debug(f"ğŸ“Š [é€²åº¦è©³æƒ…] æ­¥éª¤{self.current_step + 1}/{len(self.analysis_steps)} ({step_name}), é€²åº¦{progress_percentage:.1f}%, è€—æ™‚{elapsed_time:.1f}s")
    
    def _detect_step_from_message(self, message: str) -> Optional[int]:
        """æ ¹æ“šæ¶ˆæ¯å…§å®¹æ™ºèƒ½æª¢æ¸¬ç•¶å‰æ­¥éª¤"""
        message_lower = message.lower()

        # é–‹å§‹åˆ†æéšæ®µ - åªåŒ¹é…æœ€åˆçš„é–‹å§‹æ¶ˆæ¯
        if "ğŸš€ é–‹å§‹è‚¡ç¥¨åˆ†æ" in message:
            return 0
        # æ•¸æ“šé©—è­‰éšæ®µ
        elif "é©—è­‰" in message or "é ç²å–" in message or "æ•¸æ“šæº–å¤‡" in message:
            return 0
        # ç’°å¢ƒæº–å¤‡éšæ®µ
        elif "ç’°å¢ƒ" in message or "api" in message_lower or "å¯†é‘°" in message:
            return 1
        # æˆæœ¬é ä¼°éšæ®µ
        elif "æˆæœ¬" in message or "é ä¼°" in message:
            return 2
        # åƒæ•¸é…ç½®éšæ®µ
        elif "é…ç½®" in message or "åƒæ•¸" in message:
            return 3
        # å¼•æ“åˆå§‹åŒ–éšæ®µ
        elif "åˆå§‹åŒ–" in message or "å¼•æ“" in message:
            return 4
        # æ¨¡å¡Šé–‹å§‹æ—¥èªŒ - åªåœ¨ç¬¬ä¸€æ¬¡é–‹å§‹æ™‚æ¨é€²æ­¥éª¤
        elif "æ¨¡å¡Šé–‹å§‹" in message:
            # å¾æ—¥èªŒä¸­æå–åˆ†æå¸«é¡å‹ï¼ŒåŒ¹é…æ–°çš„æ­¥éª¤åç¨±
            if "market_analyst" in message or "market" in message:
                return self._find_step_by_keyword(["å¸‚å ´åˆ†æ", "å¸‚å ´"])
            elif "fundamentals_analyst" in message or "fundamentals" in message:
                return self._find_step_by_keyword(["åŸºæœ¬é¢åˆ†æ", "åŸºæœ¬é¢"])
            elif "technical_analyst" in message or "technical" in message:
                return self._find_step_by_keyword(["æŠ€è¡“åˆ†æ", "æŠ€è¡“"])
            elif "sentiment_analyst" in message or "sentiment" in message:
                return self._find_step_by_keyword(["æƒ…ç»ªåˆ†æ", "æƒ…ç»ª"])
            elif "news_analyst" in message or "news" in message:
                return self._find_step_by_keyword(["æ–°èåˆ†æ", "æ–°è"])
            elif "social_media_analyst" in message or "social" in message:
                return self._find_step_by_keyword(["ç¤¾äº¤åª’é«”", "ç¤¾äº¤"])
            elif "risk_analyst" in message or "risk" in message:
                return self._find_step_by_keyword(["é¢¨éšªåˆ†æ", "é¢¨éšª"])
            elif "bull_researcher" in message or "bull" in message:
                return self._find_step_by_keyword(["å¤šå¤´è§€é»", "å¤šå¤´", "çœ‹æ¶¨"])
            elif "bear_researcher" in message or "bear" in message:
                return self._find_step_by_keyword(["ç©ºå¤´è§€é»", "ç©ºå¤´", "çœ‹è·Œ"])
            elif "research_manager" in message:
                return self._find_step_by_keyword(["è§€é»æ•´åˆ", "æ•´åˆ"])
            elif "trader" in message:
                return self._find_step_by_keyword(["æŠ•è³‡å»ºè®®", "å»ºè®®"])
            elif "risk_manager" in message:
                return self._find_step_by_keyword(["é¢¨éšªæ§åˆ¶", "æ§åˆ¶"])
            elif "graph_signal_processing" in message or "signal" in message:
                return self._find_step_by_keyword(["ç”Ÿæˆå ±å‘Š", "å ±å‘Š"])
        # å·¥å…·èª¿ç”¨æ—¥èªŒ - ä¸æ¨é€²æ­¥éª¤ï¼Œåªæ›´æ–°æè¿°
        elif "å·¥å…·èª¿ç”¨" in message:
            # ä¿æŒç•¶å‰æ­¥éª¤ï¼Œä¸æ¨é€²
            return None
        # æ¨¡å¡Šå®Œæˆæ—¥èªŒ - æ¨é€²åˆ°ä¸‹ä¸€æ­¥
        elif "æ¨¡å¡Šå®Œæˆ" in message:
            # æ¨¡å¡Šå®Œæˆæ™‚ï¼Œå¾ç•¶å‰æ­¥éª¤æ¨é€²åˆ°ä¸‹ä¸€æ­¥
            # ä¸å†ä¾è³´æ¨¡å¡Šåç¨±ï¼Œè€Œæ˜¯åŸºæ–¼ç•¶å‰é€²åº¦æ¨é€²
            next_step = min(self.current_step + 1, len(self.analysis_steps) - 1)
            logger.debug(f"ğŸ“Š [æ­¥éª¤æ¨é€²] æ¨¡å¡Šå®Œæˆï¼Œå¾æ­¥éª¤{self.current_step}æ¨é€²åˆ°æ­¥éª¤{next_step}")
            return next_step

        return None

    def _find_step_by_keyword(self, keywords) -> Optional[int]:
        """æ ¹æ“šé—œé”®è©æŸ¥æ‰¾æ­¥éª¤ç´¢å¼•"""
        if isinstance(keywords, str):
            keywords = [keywords]

        for i, step in enumerate(self.analysis_steps):
            for keyword in keywords:
                if keyword in step["name"]:
                    return i
        return None

    def _get_next_step(self, keyword: str) -> Optional[int]:
        """ç²å–æŒ‡å®šæ­¥éª¤çš„ä¸‹ä¸€æ­¥"""
        current_step_index = self._find_step_by_keyword(keyword)
        if current_step_index is not None:
            return min(current_step_index + 1, len(self.analysis_steps) - 1)
        return None

    def _calculate_weighted_progress(self) -> float:
        """æ ¹æ“šæ­¥éª¤æ¬Šé‡è¨ˆç®—é€²åº¦"""
        if self.current_step >= len(self.analysis_steps):
            return 1.0

        # å¦‚æœæ˜¯æœ€å¾Œä¸€æ­¥ï¼Œè¿”å›100%
        if self.current_step == len(self.analysis_steps) - 1:
            return 1.0

        completed_weight = sum(step["weight"] for step in self.analysis_steps[:self.current_step])
        total_weight = sum(step["weight"] for step in self.analysis_steps)

        return min(completed_weight / total_weight, 1.0)
    
    def _estimate_remaining_time(self, progress: float, elapsed_time: float) -> float:
        """åŸºæ–¼æ€»é ä¼°æ™‚é–“è¨ˆç®—å‰©ä½™æ™‚é–“"""
        # å¦‚æœé€²åº¦å·²å®Œæˆï¼Œå‰©ä½™æ™‚é–“ç‚º0
        if progress >= 1.0:
            return 0.0

        # ä½¿ç”¨ç°¡å–®è€Œæº–ç¢ºçš„æ–¹æ³•ï¼šæ€»é ä¼°æ™‚é–“ - å·²èŠ±è²»æ™‚é–“
        remaining = max(self.estimated_duration - elapsed_time, 0)

        # å¦‚æœå·²ç¶“è¶…éé ä¼°æ™‚é–“ï¼Œæ ¹æ“šç•¶å‰é€²åº¦å‹•æ…‹èª¿æ•´
        if remaining <= 0 and progress > 0:
            # åŸºæ–¼ç•¶å‰é€²åº¦é‡æ–°ä¼°ç®—æ€»æ™‚é–“ï¼Œç„¶å¾Œè¨ˆç®—å‰©ä½™
            estimated_total = elapsed_time / progress
            remaining = max(estimated_total - elapsed_time, 0)

        return remaining
    
    def _save_progress(self):
        """ä¿å­˜é€²åº¦åˆ°å­˜å‚¨"""
        try:
            current_step_name = self.progress_data.get('current_step_name', 'æœªçŸ¥')
            progress_pct = self.progress_data.get('progress_percentage', 0)
            status = self.progress_data.get('status', 'running')

            if self.use_redis:
                # ä¿å­˜åˆ°Redisï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰
                key = f"progress:{self.analysis_id}"
                safe_data = safe_serialize(self.progress_data)
                data_json = json.dumps(safe_data, ensure_ascii=False)
                self.redis_client.setex(key, 3600, data_json)  # 1å°æ™‚éæœŸ

                logger.info(f"ğŸ“Š [Rediså¯«å…¥] {self.analysis_id} -> {status} | {current_step_name} | {progress_pct:.1f}%")
                logger.debug(f"ğŸ“Š [Redisè©³æƒ…] é”®: {key}, æ•¸æ“šå¤§å°: {len(data_json)} å­—ç¯€")
            else:
                # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰
                safe_data = safe_serialize(self.progress_data)
                with open(self.progress_file, 'w', encoding='utf-8') as f:
                    json.dump(safe_data, f, ensure_ascii=False, indent=2)

                logger.info(f"ğŸ“Š [æ–‡ä»¶å¯«å…¥] {self.analysis_id} -> {status} | {current_step_name} | {progress_pct:.1f}%")
                logger.debug(f"ğŸ“Š [æ–‡ä»¶è©³æƒ…] è·¯å¾‘: {self.progress_file}")

        except Exception as e:
            logger.error(f"ğŸ“Š [ç•°æ­¥é€²åº¦] ä¿å­˜å¤±è´¥: {e}")
            # å˜—è©¦å¤‡ç”¨å­˜å‚¨æ–¹å¼
            try:
                if self.use_redis:
                    # Rediså¤±è´¥ï¼Œå˜—è©¦æ–‡ä»¶å­˜å‚¨
                    logger.warning(f"ğŸ“Š [ç•°æ­¥é€²åº¦] Redisä¿å­˜å¤±è´¥ï¼Œå˜—è©¦æ–‡ä»¶å­˜å‚¨")
                    backup_file = f"./data/progress_{self.analysis_id}.json"
                    os.makedirs(os.path.dirname(backup_file), exist_ok=True)
                    safe_data = safe_serialize(self.progress_data)
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        json.dump(safe_data, f, ensure_ascii=False, indent=2)
                    logger.info(f"ğŸ“Š [å¤‡ç”¨å­˜å‚¨] æ–‡ä»¶ä¿å­˜æˆåŠŸ: {backup_file}")
                else:
                    # æ–‡ä»¶å­˜å‚¨å¤±è´¥ï¼Œå˜—è©¦ç°¡åŒ–æ•¸æ“š
                    logger.warning(f"ğŸ“Š [ç•°æ­¥é€²åº¦] æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œå˜—è©¦ç°¡åŒ–æ•¸æ“š")
                    simplified_data = {
                        'analysis_id': self.analysis_id,
                        'status': self.progress_data.get('status', 'unknown'),
                        'progress_percentage': self.progress_data.get('progress_percentage', 0),
                        'last_message': str(self.progress_data.get('last_message', '')),
                        'last_update': self.progress_data.get('last_update', time.time())
                    }
                    backup_file = f"./data/progress_{self.analysis_id}.json"
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        json.dump(simplified_data, f, ensure_ascii=False, indent=2)
                    logger.info(f"ğŸ“Š [å¤‡ç”¨å­˜å‚¨] ç°¡åŒ–æ•¸æ“šä¿å­˜æˆåŠŸ: {backup_file}")
            except Exception as backup_e:
                logger.error(f"ğŸ“Š [ç•°æ­¥é€²åº¦] å¤‡ç”¨å­˜å‚¨ä¹Ÿå¤±è´¥: {backup_e}")
    
    def get_progress(self) -> Dict[str, Any]:
        """ç²å–ç•¶å‰é€²åº¦"""
        return self.progress_data.copy()
    
    def mark_completed(self, message: str = "åˆ†æå®Œæˆ", results: Any = None):
        """æ¨™è¨˜åˆ†æå®Œæˆ"""
        self.update_progress(message)
        self.progress_data['status'] = 'completed'
        self.progress_data['progress_percentage'] = 100.0
        self.progress_data['remaining_time'] = 0.0

        # ä¿å­˜åˆ†æçµæœï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰
        if results is not None:
            try:
                self.progress_data['raw_results'] = safe_serialize(results)
                logger.info(f"ğŸ“Š [ç•°æ­¥é€²åº¦] ä¿å­˜åˆ†æçµæœ: {self.analysis_id}")
            except Exception as e:
                logger.warning(f"ğŸ“Š [ç•°æ­¥é€²åº¦] çµæœåºåˆ—åŒ–å¤±è´¥: {e}")
                self.progress_data['raw_results'] = str(results)  # æœ€å¾Œçš„fallback

        self._save_progress()
        logger.info(f"ğŸ“Š [ç•°æ­¥é€²åº¦] åˆ†æå®Œæˆ: {self.analysis_id}")

        # å¾æ—¥èªŒç³»çµ±è¨»éŠ·
        try:
            from .progress_log_handler import unregister_analysis_tracker
            unregister_analysis_tracker(self.analysis_id)
        except ImportError:
            pass
    
    def mark_failed(self, error_message: str):
        """æ¨™è¨˜åˆ†æå¤±è´¥"""
        self.progress_data['status'] = 'failed'
        self.progress_data['last_message'] = f"åˆ†æå¤±è´¥: {error_message}"
        self.progress_data['last_update'] = time.time()
        self._save_progress()
        logger.error(f"ğŸ“Š [ç•°æ­¥é€²åº¦] åˆ†æå¤±è´¥: {self.analysis_id}, éŒ¯èª¤: {error_message}")

        # å¾æ—¥èªŒç³»çµ±è¨»éŠ·
        try:
            from .progress_log_handler import unregister_analysis_tracker
            unregister_analysis_tracker(self.analysis_id)
        except ImportError:
            pass

def get_progress_by_id(analysis_id: str) -> Optional[Dict[str, Any]]:
    """æ ¹æ“šåˆ†æIDç²å–é€²åº¦"""
    try:
        # æª¢æŸ¥REDIS_ENABLEDç’°å¢ƒè®Šé‡
        redis_enabled = os.getenv('REDIS_ENABLED', 'false').lower() == 'true'

        # å¦‚æœRediså•Ÿç”¨ï¼Œå…ˆå˜—è©¦Redis
        if redis_enabled:
            try:
                import redis

                # å¾ç’°å¢ƒè®Šé‡ç²å–Redisé…ç½®
                redis_host = os.getenv('REDIS_HOST', 'localhost')
                redis_port = int(os.getenv('REDIS_PORT', 6379))
                redis_password = os.getenv('REDIS_PASSWORD', None)
                redis_db = int(os.getenv('REDIS_DB', 0))

                # å‰µå»ºRedisé€£æ¥
                if redis_password:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        password=redis_password,
                        db=redis_db,
                        decode_responses=True
                    )
                else:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        db=redis_db,
                        decode_responses=True
                    )

                key = f"progress:{analysis_id}"
                data = redis_client.get(key)
                if data:
                    return json.loads(data)
            except Exception as e:
                logger.debug(f"ğŸ“Š [ç•°æ­¥é€²åº¦] Redisè®€å–å¤±è´¥: {e}")

        # å˜—è©¦æ–‡ä»¶
        progress_file = f"./data/progress_{analysis_id}.json"
        if os.path.exists(progress_file):
            with open(progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)

        return None
    except Exception as e:
        logger.error(f"ğŸ“Š [ç•°æ­¥é€²åº¦] ç²å–é€²åº¦å¤±è´¥: {analysis_id}, éŒ¯èª¤: {e}")
        return None

def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ™‚é–“é¡¯ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}åˆ†é˜"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}å°æ™‚"


def get_latest_analysis_id() -> Optional[str]:
    """ç²å–æœ€æ–°çš„åˆ†æID"""
    try:
        # æª¢æŸ¥REDIS_ENABLEDç’°å¢ƒè®Šé‡
        redis_enabled = os.getenv('REDIS_ENABLED', 'false').lower() == 'true'

        # å¦‚æœRediså•Ÿç”¨ï¼Œå…ˆå˜—è©¦å¾Redisç²å–
        if redis_enabled:
            try:
                import redis

                # å¾ç’°å¢ƒè®Šé‡ç²å–Redisé…ç½®
                redis_host = os.getenv('REDIS_HOST', 'localhost')
                redis_port = int(os.getenv('REDIS_PORT', 6379))
                redis_password = os.getenv('REDIS_PASSWORD', None)
                redis_db = int(os.getenv('REDIS_DB', 0))

                # å‰µå»ºRedisé€£æ¥
                if redis_password:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        password=redis_password,
                        db=redis_db,
                        decode_responses=True
                    )
                else:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        db=redis_db,
                        decode_responses=True
                    )

                # ç²å–æ‰€æœ‰progressé”®
                keys = redis_client.keys("progress:*")
                if not keys:
                    return None

                # ç²å–æ¯å€‹é”®çš„æ•¸æ“šï¼Œæ‰¾åˆ°æœ€æ–°çš„
                latest_time = 0
                latest_id = None

                for key in keys:
                    try:
                        data = redis_client.get(key)
                        if data:
                            progress_data = json.loads(data)
                            last_update = progress_data.get('last_update', 0)
                            if last_update > latest_time:
                                latest_time = last_update
                                # å¾é”®åä¸­æå–analysis_id (å»æ‰"progress:"å‰ç¼€)
                                latest_id = key.replace('progress:', '')
                    except Exception:
                        continue

                if latest_id:
                    logger.info(f"ğŸ“Š [æ¢è¤‡åˆ†æ] æ‰¾åˆ°æœ€æ–°åˆ†æID: {latest_id}")
                    return latest_id

            except Exception as e:
                logger.debug(f"ğŸ“Š [æ¢è¤‡åˆ†æ] RedisæŸ¥æ‰¾å¤±è´¥: {e}")

        # å¦‚æœRediså¤±è´¥æˆ–æœªå•Ÿç”¨ï¼Œå˜—è©¦å¾æ–‡ä»¶æŸ¥æ‰¾
        data_dir = Path("data")
        if data_dir.exists():
            progress_files = list(data_dir.glob("progress_*.json"))
            if progress_files:
                # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼Œç²å–æœ€æ–°çš„
                latest_file = max(progress_files, key=lambda f: f.stat().st_mtime)
                # å¾æ–‡ä»¶åæå–analysis_id
                filename = latest_file.name
                if filename.startswith("progress_") and filename.endswith(".json"):
                    analysis_id = filename[9:-5]  # å»æ‰å‰ç¼€å’Œå¾Œç¼€
                    logger.debug(f"ğŸ“Š [æ¢è¤‡åˆ†æ] å¾æ–‡ä»¶æ‰¾åˆ°æœ€æ–°åˆ†æID: {analysis_id}")
                    return analysis_id

        return None
    except Exception as e:
        logger.error(f"ğŸ“Š [æ¢è¤‡åˆ†æ] ç²å–æœ€æ–°åˆ†æIDå¤±è´¥: {e}")
        return None
