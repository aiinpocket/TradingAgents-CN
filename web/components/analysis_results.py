"""
åˆ†æçµæœç®¡ç†çµ„ä»¶
æä¾›è‚¡ç¥¨åˆ†ææ­·å²çµæœçš„æŸ¥çœ‹å’Œç®¡ç†åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from typing import Dict, List, Any
import json
import os
from pathlib import Path
import hashlib
import logging

# MongoDBç›¸é—œå°å…¥
try:
    from web.utils.mongodb_report_manager import MongoDBReportManager
    MONGODB_AVAILABLE = True
    print("âœ… MongoDBæ¨¡å¡Šå°å…¥æˆåŠŸ")
except ImportError as e:
    MONGODB_AVAILABLE = False
    print(f"âŒ MongoDBæ¨¡å¡Šå°å…¥å¤±è´¥: {e}")

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

def safe_timestamp_to_datetime(timestamp_value):
    """å®‰å…¨åœ°å°†æ™‚é–“æˆ³è½‰æ›ç‚ºdatetimeå°è±¡"""
    if isinstance(timestamp_value, datetime):
        # å¦‚æœå·²ç¶“æ˜¯datetimeå°è±¡ï¼ˆä¾†è‡ªMongoDBï¼‰
        return timestamp_value
    elif isinstance(timestamp_value, (int, float)):
        # å¦‚æœæ˜¯æ™‚é–“æˆ³æ•¸å­—ï¼ˆä¾†è‡ªæ–‡ä»¶ç³»çµ±ï¼‰
        try:
            return datetime.fromtimestamp(timestamp_value)
        except (ValueError, OSError):
            # æ™‚é–“æˆ³ç„¡æ•ˆï¼Œä½¿ç”¨ç•¶å‰æ™‚é–“
            return datetime.now()
    else:
        # å…¶ä»–æƒ…æ³ï¼Œä½¿ç”¨ç•¶å‰æ™‚é–“
        return datetime.now()

def get_analysis_results_dir():
    """ç²å–åˆ†æçµæœç›®éŒ„"""
    results_dir = Path(__file__).parent.parent / "data" / "analysis_results"
    results_dir.mkdir(parents=True, exist_ok=True)
    return results_dir

def get_favorites_file():
    """ç²å–æ”¶è—æ–‡ä»¶è·¯å¾‘"""
    return get_analysis_results_dir() / "favorites.json"

def get_tags_file():
    """ç²å–æ¨™ç°½æ–‡ä»¶è·¯å¾‘"""
    return get_analysis_results_dir() / "tags.json"

def load_favorites():
    """åŠ è¼‰æ”¶è—åˆ—è¡¨"""
    favorites_file = get_favorites_file()
    if favorites_file.exists():
        try:
            with open(favorites_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []

def save_favorites(favorites):
    """ä¿å­˜æ”¶è—åˆ—è¡¨"""
    favorites_file = get_favorites_file()
    try:
        with open(favorites_file, 'w', encoding='utf-8') as f:
            json.dump(favorites, f, ensure_ascii=False, indent=2)
        return True
    except:
        return False

def load_tags():
    """åŠ è¼‰æ¨™ç°½æ•¸æ“š"""
    tags_file = get_tags_file()
    if tags_file.exists():
        try:
            with open(tags_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_tags(tags):
    """ä¿å­˜æ¨™ç°½æ•¸æ“š"""
    tags_file = get_tags_file()
    try:
        with open(tags_file, 'w', encoding='utf-8') as f:
            json.dump(tags, f, ensure_ascii=False, indent=2)
        return True
    except:
        return False

def add_tag_to_analysis(analysis_id, tag):
    """ç‚ºåˆ†æçµæœæ·»åŠ æ¨™ç°½"""
    tags = load_tags()
    if analysis_id not in tags:
        tags[analysis_id] = []
    if tag not in tags[analysis_id]:
        tags[analysis_id].append(tag)
        save_tags(tags)

def remove_tag_from_analysis(analysis_id, tag):
    """å¾åˆ†æçµæœç§»é™¤æ¨™ç°½"""
    tags = load_tags()
    if analysis_id in tags and tag in tags[analysis_id]:
        tags[analysis_id].remove(tag)
        if not tags[analysis_id]:  # å¦‚æœæ²¡æœ‰æ¨™ç°½äº†ï¼Œåˆªé™¤è¯¥æ¢ç›®
            del tags[analysis_id]
        save_tags(tags)

def get_analysis_tags(analysis_id):
    """ç²å–åˆ†æçµæœçš„æ¨™ç°½"""
    tags = load_tags()
    return tags.get(analysis_id, [])

def load_analysis_results(start_date=None, end_date=None, stock_symbol=None, analyst_type=None,
                         limit=100, search_text=None, tags_filter=None, favorites_only=False):
    """åŠ è¼‰åˆ†æçµæœ - å„ªå…ˆå¾MongoDBåŠ è¼‰"""
    all_results = []
    favorites = load_favorites() if favorites_only else []
    tags_data = load_tags()
    mongodb_loaded = False

    # å„ªå…ˆå¾MongoDBåŠ è¼‰æ•¸æ“š
    if MONGODB_AVAILABLE:
        try:
            print("ğŸ” [æ•¸æ“šåŠ è¼‰] å¾MongoDBåŠ è¼‰åˆ†æçµæœ")
            mongodb_manager = MongoDBReportManager()
            mongodb_results = mongodb_manager.get_all_reports()
            print(f"ğŸ” [æ•¸æ“šåŠ è¼‰] MongoDBè¿”å› {len(mongodb_results)} å€‹çµæœ")

            for mongo_result in mongodb_results:
                # è½‰æ›MongoDBçµæœæ ¼å¼
                result = {
                    'analysis_id': mongo_result.get('analysis_id', ''),
                    'timestamp': mongo_result.get('timestamp', 0),
                    'stock_symbol': mongo_result.get('stock_symbol', ''),
                    'analysts': mongo_result.get('analysts', []),
                    'research_depth': mongo_result.get('research_depth', 1),
                    'status': mongo_result.get('status', 'completed'),
                    'summary': mongo_result.get('summary', ''),
                    'performance': mongo_result.get('performance', {}),
                    'tags': tags_data.get(mongo_result.get('analysis_id', ''), []),
                    'is_favorite': mongo_result.get('analysis_id', '') in favorites,
                    'reports': mongo_result.get('reports', {}),
                    'source': 'mongodb'  # æ¨™è¨˜æ•¸æ“šä¾†æº
                }
                all_results.append(result)

            mongodb_loaded = True
            print(f"âœ… å¾MongoDBåŠ è¼‰äº† {len(mongodb_results)} å€‹åˆ†æçµæœ")

        except Exception as e:
            print(f"âŒ MongoDBåŠ è¼‰å¤±è´¥: {e}")
            logger.error(f"MongoDBåŠ è¼‰å¤±è´¥: {e}")
            mongodb_loaded = False
    else:
        print("âš ï¸ MongoDBä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ–‡ä»¶ç³»çµ±æ•¸æ“š")

    # åªæœ‰åœ¨MongoDBåŠ è¼‰å¤±è´¥æˆ–ä¸å¯ç”¨æ™‚æ‰å¾æ–‡ä»¶ç³»çµ±åŠ è¼‰
    if not mongodb_loaded:
        print("ğŸ”„ [å‚™ç”¨æ•¸æ“šæº] å¾æ–‡ä»¶ç³»çµ±åŠ è¼‰åˆ†æçµæœ")

        # é¦–å…ˆå˜—è©¦å¾Webç•Œé¢çš„ä¿å­˜ä½ç½®è®€å–
        web_results_dir = get_analysis_results_dir()
        for result_file in web_results_dir.glob("*.json"):
            if result_file.name in ['favorites.json', 'tags.json']:
                continue

            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    result = json.load(f)

                    # æ·»åŠ æ¨™ç°½ä¿¡æ¯
                    result['tags'] = tags_data.get(result.get('analysis_id', ''), [])
                    result['is_favorite'] = result.get('analysis_id', '') in favorites
                    result['source'] = 'file_system'  # æ¨™è¨˜æ•¸æ“šä¾†æº

                    all_results.append(result)
            except Exception as e:
                st.warning(f"è®€å–åˆ†æçµæœæ–‡ä»¶ {result_file.name} å¤±è´¥: {e}")

        # ç„¶å¾Œå¾å¯¦é™…çš„åˆ†æçµæœä¿å­˜ä½ç½®è®€å–
        project_results_dir = Path(__file__).parent.parent.parent / "data" / "analysis_results" / "detailed"

        if project_results_dir.exists():
            # éæ­·è‚¡ç¥¨ä»£ç¢¼ç›®éŒ„
            for stock_dir in project_results_dir.iterdir():
                if not stock_dir.is_dir():
                    continue

                stock_code = stock_dir.name

                # éæ­·æ—¥æœŸç›®éŒ„
                for date_dir in stock_dir.iterdir():
                    if not date_dir.is_dir():
                        continue

                    date_str = date_dir.name
                    reports_dir = date_dir / "reports"

                    if not reports_dir.exists():
                        continue

                    # è®€å–æ‰€æœ‰å ±å‘Šæ–‡ä»¶
                    reports = {}
                    summary_content = ""

                    for report_file in reports_dir.glob("*.md"):
                        try:
                            with open(report_file, 'r', encoding='utf-8') as f:
                                content = f.read()
                                report_name = report_file.stem
                                reports[report_name] = content

                                # å¦‚æœæ˜¯æœ€çµ‚æ±ºç­–å ±å‘Šï¼Œæå–æ‘˜è¦
                                if report_name == "final_trade_decision":
                                    # æå–å‰200å€‹å­—ç¬¦ä½œç‚ºæ‘˜è¦
                                    summary_content = content[:200].replace('#', '').replace('*', '').strip()
                                    if len(content) > 200:
                                        summary_content += "..."

                        except Exception as e:
                            continue

                    if reports:
                        # è§£ææ—¥æœŸ
                        try:
                            analysis_date = datetime.strptime(date_str, '%Y-%m-%d')
                            timestamp = analysis_date.timestamp()
                        except:
                            timestamp = datetime.now().timestamp()

                        # å‰µå»ºåˆ†æçµæœæ¢ç›®
                        analysis_id = f"{stock_code}_{date_str}_{int(timestamp)}"

                        # å˜—è©¦å¾å…ƒæ•¸æ“šæ–‡ä»¶ä¸­è®€å–çœŸå¯¦çš„ç ”ç©¶æ·±åº¦å’Œåˆ†æå¸«ä¿¡æ¯
                        research_depth = 1
                        analysts = ['market', 'fundamentals', 'trader']  # é»˜èªå€¼

                        metadata_file = date_dir / "analysis_metadata.json"
                        if metadata_file.exists():
                            try:
                                with open(metadata_file, 'r', encoding='utf-8') as f:
                                    metadata = json.load(f)
                                    research_depth = metadata.get('research_depth', 1)
                                    analysts = metadata.get('analysts', analysts)
                            except Exception as e:
                                # å¦‚æœè®€å–å…ƒæ•¸æ“šå¤±è´¥ï¼Œä½¿ç”¨æ¨æ–·é‚è¼¯
                                if len(reports) >= 5:
                                    research_depth = 3
                                elif len(reports) >= 3:
                                    research_depth = 2
                        else:
                            # å¦‚æœæ²¡æœ‰å…ƒæ•¸æ“šæ–‡ä»¶ï¼Œä½¿ç”¨æ¨æ–·é‚è¼¯
                            if len(reports) >= 5:
                                research_depth = 3
                            elif len(reports) >= 3:
                                research_depth = 2

                        result = {
                            'analysis_id': analysis_id,
                            'timestamp': timestamp,
                            'stock_symbol': stock_code,
                            'analysts': analysts,
                            'research_depth': research_depth,
                            'status': 'completed',
                            'summary': summary_content,
                            'performance': {},
                            'tags': tags_data.get(analysis_id, []),
                            'is_favorite': analysis_id in favorites,
                            'reports': reports,  # ä¿å­˜æ‰€æœ‰å ±å‘Šå…§å®¹
                            'source': 'file_system'  # æ¨™è¨˜æ•¸æ“šä¾†æº
                        }

                        all_results.append(result)

        print(f"ğŸ”„ [å‚™ç”¨æ•¸æ“šæº] å¾æ–‡ä»¶ç³»çµ±åŠ è¼‰äº† {len(all_results)} å€‹åˆ†æçµæœ")
    
    # éæ¿¾çµæœ
    filtered_results = []
    for result in all_results:
        # æ”¶è—éæ¿¾
        if favorites_only and not result.get('is_favorite', False):
            continue
            
        # æ™‚é–“éæ¿¾
        if start_date or end_date:
            result_time = safe_timestamp_to_datetime(result.get('timestamp', 0))
            if start_date and result_time.date() < start_date:
                continue
            if end_date and result_time.date() > end_date:
                continue
        
        # è‚¡ç¥¨ä»£ç¢¼éæ¿¾
        if stock_symbol and stock_symbol.upper() not in result.get('stock_symbol', '').upper():
            continue
        
        # åˆ†æå¸«é¡å‹éæ¿¾
        if analyst_type and analyst_type not in result.get('analysts', []):
            continue
            
        # æ–‡æœ¬æœç´¢éæ¿¾
        if search_text:
            search_text = search_text.lower()
            searchable_text = f"{result.get('stock_symbol', '')} {result.get('summary', '')} {' '.join(result.get('analysts', []))}".lower()
            if search_text not in searchable_text:
                continue
                
        # æ¨™ç°½éæ¿¾
        if tags_filter:
            result_tags = result.get('tags', [])
            if not any(tag in result_tags for tag in tags_filter):
                continue
        
        filtered_results.append(result)
    
    # æŒ‰æ™‚é–“å€’åºæ’åˆ— - ä½¿ç”¨å®‰å…¨çš„æ™‚é–“æˆ³è½‰æ›å‡½æ•¸ç¢ºä¿é¡å‹ä¸€è‡´
    filtered_results.sort(key=lambda x: safe_timestamp_to_datetime(x.get('timestamp', 0)), reverse=True)
    
    # é™åˆ¶æ•¸é‡
    return filtered_results[:limit]

def render_analysis_results():
    """æ¸²æŸ“åˆ†æçµæœç®¡ç†ç•Œé¢"""
    
    # æª¢æŸ¥æ¬Šé™
    try:
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
        from utils.auth_manager import auth_manager
        
        if not auth_manager or not auth_manager.check_permission("analysis"):
            st.error("âŒ æ‚¨æ²¡æœ‰æ¬Šé™è¨ªå•åˆ†æçµæœ")
            st.info("ğŸ’¡ æç¤ºï¼šåˆ†æçµæœåŠŸèƒ½éœ€è¦ 'analysis' æ¬Šé™")
            return
    except Exception as e:
        st.error(f"âŒ æ¬Šé™æª¢æŸ¥å¤±è´¥: {e}")
        return
    
    st.title("ğŸ“Š åˆ†æçµæœæ­·å²è¨˜éŒ„")
    
    # ä¾§é‚Šæ éæ¿¾é¸é …
    with st.sidebar:
        st.header("ğŸ” æœç´¢ä¸éæ¿¾")
        
        # æ–‡æœ¬æœç´¢
        search_text = st.text_input("ğŸ” é—œé”®è©æœç´¢", placeholder="æœç´¢è‚¡ç¥¨ä»£ç¢¼ã€æ‘˜è¦å…§å®¹...")
        
        # æ”¶è—éæ¿¾
        favorites_only = st.checkbox("â­ ä»…é¡¯ç¤ºæ”¶è—")
        
        # æ—¥æœŸç¯„å›´é¸æ“‡
        date_range = st.selectbox(
            "ğŸ“… æ™‚é–“ç¯„å›´",
            ["æœ€è¿‘1å¤©", "æœ€è¿‘3å¤©", "æœ€è¿‘7å¤©", "æœ€è¿‘30å¤©", "è‡ªå®šç¾©"],
            index=2
        )
        
        if date_range == "è‡ªå®šç¾©":
            start_date = st.date_input("é–‹å§‹æ—¥æœŸ", datetime.now() - timedelta(days=7))
            end_date = st.date_input("çµæŸæ—¥æœŸ", datetime.now())
        else:
            days_map = {"æœ€è¿‘1å¤©": 1, "æœ€è¿‘3å¤©": 3, "æœ€è¿‘7å¤©": 7, "æœ€è¿‘30å¤©": 30}
            days = days_map[date_range]
            end_date = datetime.now().date()
            start_date = (datetime.now() - timedelta(days=days)).date()
        
        # è‚¡ç¥¨ä»£ç¢¼éæ¿¾
        stock_filter = st.text_input("ğŸ“ˆ è‚¡ç¥¨ä»£ç¢¼", placeholder="å¦‚: 000001, AAPL")
        
        # åˆ†æå¸«é¡å‹éæ¿¾
        analyst_filter = st.selectbox(
            "ğŸ‘¥ åˆ†æå¸«é¡å‹",
            ["å…¨éƒ¨", "market_analyst", "social_media_analyst", "news_analyst", "fundamental_analyst"],
            help="è¨»æ„ï¼šç¤¾äº¤åª’é«”åˆ†æå¸«ä»…é©ç”¨æ–¼ç¾è‚¡å’Œæ¸¯è‚¡ï¼ŒAè‚¡åˆ†æä¸­ä¸åŒ…å«æ­¤é¡å‹"
        )
        
        if analyst_filter == "å…¨éƒ¨":
            analyst_filter = None
            
        # æ¨™ç°½éæ¿¾
        all_tags = set()
        tags_data = load_tags()
        for tag_list in tags_data.values():
            all_tags.update(tag_list)
        
        if all_tags:
            selected_tags = st.multiselect("ğŸ·ï¸ æ¨™ç°½éæ¿¾", sorted(all_tags))
        else:
            selected_tags = []
    
    # åŠ è¼‰åˆ†æçµæœ
    results = load_analysis_results(
        start_date=start_date,
        end_date=end_date,
        stock_symbol=stock_filter if stock_filter else None,
        analyst_type=analyst_filter,
        limit=200,
        search_text=search_text if search_text else None,
        tags_filter=selected_tags if selected_tags else None,
        favorites_only=favorites_only
    )
    
    if not results:
        st.warning("ğŸ“­ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„åˆ†æçµæœ")
        return
    
    # é¡¯ç¤ºçµ±è¨ˆæ¦‚è¦½
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“Š æ€»åˆ†ææ•¸", len(results))
    
    with col2:
        unique_stocks = len(set(result.get('stock_symbol', 'unknown') for result in results))
        st.metric("ğŸ“ˆ åˆ†æè‚¡ç¥¨", unique_stocks)
    
    with col3:
        successful_analyses = sum(1 for result in results if result.get('status') == 'completed')
        success_rate = (successful_analyses / len(results) * 100) if results else 0
        st.metric("âœ… æˆåŠŸç‡", f"{success_rate:.1f}%")
    
    with col4:
        favorites_count = sum(1 for result in results if result.get('is_favorite', False))
        st.metric("â­ æ”¶è—æ•¸", favorites_count)
    
    # ä¿ç•™éœ€è¦çš„åŠŸèƒ½æŒ‰é’®ï¼Œç§»é™¤ä¸éœ€è¦çš„åŠŸèƒ½
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“‹ çµæœåˆ—è¡¨", "ğŸ“ˆ çµ±è¨ˆåœ–è¡¨", "ğŸ“Š è©³ç´°åˆ†æ"
    ])
    
    with tab1:
        render_results_list(results)
    
    with tab2:
        render_results_charts(results)
    
    with tab3:
        render_detailed_analysis(results)

def render_results_list(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æçµæœåˆ—è¡¨"""
    
    st.subheader("ğŸ“‹ åˆ†æçµæœåˆ—è¡¨")
    
    # æ’åºé¸é …
    col1, col2 = st.columns([2, 1])
    with col1:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["æ™‚é–“å€’åº", "æ™‚é–“æ­£åº", "è‚¡ç¥¨ä»£ç¢¼", "æˆåŠŸç‡"])
    with col2:
        view_mode = st.selectbox("é¡¯ç¤ºæ¨¡å¼", ["å¡ç‰‡è¦–åœ–", "è¡¨æ ¼è¦–åœ–"])
    
    # æ’åºçµæœ
    if sort_by == "æ™‚é–“æ­£åº":
        results.sort(key=lambda x: safe_timestamp_to_datetime(x.get('timestamp', 0)))
    elif sort_by == "è‚¡ç¥¨ä»£ç¢¼":
        results.sort(key=lambda x: x.get('stock_symbol', ''))
    elif sort_by == "æˆåŠŸç‡":
        results.sort(key=lambda x: 1 if x.get('status') == 'completed' else 0, reverse=True)
    
    if view_mode == "è¡¨æ ¼è¦–åœ–":
        render_results_table(results)
    else:
        render_results_cards(results)

def render_results_table(results: List[Dict[str, Any]]):
    """æ¸²æŸ“è¡¨æ ¼è¦–åœ–"""
    
    # æº–å¤‡è¡¨æ ¼æ•¸æ“š
    table_data = []
    for result in results:
        table_data.append({
            'æ™‚é–“': safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M'),
            'è‚¡ç¥¨': result.get('stock_symbol', 'unknown'),
            'åˆ†æå¸«': ', '.join(result.get('analysts', [])[:2]) + ('...' if len(result.get('analysts', [])) > 2 else ''),
            'ç‹€æ…‹': 'âœ…' if result.get('status') == 'completed' else 'âŒ',
            'æ”¶è—': 'â­' if result.get('is_favorite', False) else '',
            'æ¨™ç°½': ', '.join(result.get('tags', [])[:2]) + ('...' if len(result.get('tags', [])) > 2 else ''),
            'æ‘˜è¦': (result.get('summary', '')[:50] + '...') if len(result.get('summary', '')) > 50 else result.get('summary', '')
        })
    
    if table_data:
        df = pd.DataFrame(table_data)
        st.dataframe(df, use_container_width=True)

def render_results_cards(results: List[Dict[str, Any]]):
    """æ¸²æŸ“å¡ç‰‡è¦–åœ–"""
    
    # åˆ†é¡µè¨­ç½®
    page_size = st.selectbox("æ¯é¡µé¡¯ç¤º", [5, 10, 20, 50], index=1)
    total_pages = (len(results) + page_size - 1) // page_size
    
    if total_pages > 1:
        page = st.number_input("é¡µç¢¼", min_value=1, max_value=total_pages, value=1) - 1
    else:
        page = 0
    
    # ç²å–ç•¶å‰é¡µæ•¸æ“š
    start_idx = page * page_size
    end_idx = min(start_idx + page_size, len(results))
    page_results = results[start_idx:end_idx]
    
    # é¡¯ç¤ºçµæœå¡ç‰‡
    for i, result in enumerate(page_results):
        analysis_id = result.get('analysis_id', '')
        
        with st.container():
            # å¡ç‰‡é ­éƒ¨
            col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
            
            with col1:
                st.markdown(f"### ğŸ“Š {result.get('stock_symbol', 'unknown')}")
                st.caption(f"ğŸ• {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M:%S')}")
            
            with col2:
                # æ”¶è—æŒ‰é’®
                is_favorite = result.get('is_favorite', False)
                if st.button("â­" if is_favorite else "â˜†", key=f"fav_{start_idx + i}"):
                    toggle_favorite(analysis_id)
                    st.rerun()
            
            with col3:
                # æŸ¥çœ‹è©³æƒ…æŒ‰é’®
                result_id = result.get('_id') or result.get('analysis_id') or f"result_{start_idx + i}"
                current_expanded = st.session_state.get('expanded_result_id') == result_id
                button_text = "ğŸ”¼ æ”¶èµ·" if current_expanded else "ğŸ‘ï¸ è©³æƒ…"

                if st.button(button_text, key=f"view_{start_idx + i}"):
                    if current_expanded:
                        # å¦‚æœç•¶å‰å·²å±•é–‹ï¼Œå‰‡æ”¶èµ·
                        st.session_state['expanded_result_id'] = None
                    else:
                        # å±•é–‹ç•¶å‰çµæœçš„è©³æƒ…
                        st.session_state['expanded_result_id'] = result_id
                        st.session_state['selected_result_for_detail'] = result
                    st.rerun()
            
            with col4:
                # ç‹€æ…‹é¡¯ç¤º
                status_icon = "âœ…" if result.get('status') == 'completed' else "âŒ"
                st.markdown(f"**ç‹€æ…‹**: {status_icon}")
            
            # å¡ç‰‡å…§å®¹
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**åˆ†æå¸«**: {', '.join(result.get('analysts', []))}")
                st.write(f"**ç ”ç©¶æ·±åº¦**: {result.get('research_depth', 'unknown')}")

                # é¡¯ç¤ºåˆ†ææ‘˜è¦
                if result.get('summary'):
                    summary = result['summary'][:150] + "..." if len(result['summary']) > 150 else result['summary']
                    st.write(f"**æ‘˜è¦**: {summary}")
            
            with col2:
                # é¡¯ç¤ºæ¨™ç°½
                tags = result.get('tags', [])
                if tags:
                    st.write("**æ¨™ç°½**:")
                    for tag in tags[:3]:  # æœ€å¤šé¡¯ç¤º3å€‹æ¨™ç°½
                        st.markdown(f"`{tag}`")
                    if len(tags) > 3:
                        st.caption(f"è¿˜æœ‰ {len(tags) - 3} å€‹æ¨™ç°½...")

            # é¡¯ç¤ºæŠ˜å è©³æƒ…
            result_id = result.get('_id') or result.get('analysis_id') or f"result_{start_idx + i}"
            if st.session_state.get('expanded_result_id') == result_id:
                show_expanded_detail(result)

            st.divider()
    
    # é¡¯ç¤ºåˆ†é¡µä¿¡æ¯
    if total_pages > 1:
        st.info(f"ç¬¬ {page + 1} é¡µï¼Œå…± {total_pages} é¡µï¼Œæ€»è¨ˆ {len(results)} æ¢è¨˜éŒ„")
    
    # è¨»æ„ï¼šè©³æƒ…ç¾åœ¨ä»¥æŠ˜å æ–¹å¼é¡¯ç¤ºåœ¨æ¯å€‹çµæœä¸‹æ–¹

# å¼¹çª—åŠŸèƒ½å·²ç§»é™¤ï¼Œè©³æƒ…ç¾åœ¨ä»¥æŠ˜å æ–¹å¼é¡¯ç¤º

def toggle_favorite(analysis_id):
    """åˆ‡æ›æ”¶è—ç‹€æ…‹"""
    favorites = load_favorites()
    if analysis_id in favorites:
        favorites.remove(analysis_id)
    else:
        favorites.append(analysis_id)
    save_favorites(favorites)

def render_results_comparison(results: List[Dict[str, Any]]):
    """æ¸²æŸ“çµæœå°æ¯”åŠŸèƒ½"""
    
    st.subheader("ğŸ”„ åˆ†æçµæœå°æ¯”")
    
    if len(results) < 2:
        st.warning("è‡³å°‘éœ€è¦2å€‹åˆ†æçµæœæ‰èƒ½é€²è¡Œå°æ¯”")
        return
    
    # é¸æ“‡è¦å°æ¯”çš„çµæœ
    col1, col2 = st.columns(2)
    
    result_options = []
    for i, result in enumerate(results[:20]):  # é™åˆ¶é¸é …æ•¸é‡
        option = f"{result.get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M')}"
        result_options.append((option, i))
    
    with col1:
        st.write("**é¸æ“‡çµæœA**")
        selected_a = st.selectbox("çµæœA", result_options, format_func=lambda x: x[0], key="compare_a")
        result_a = results[selected_a[1]]
    
    with col2:
        st.write("**é¸æ“‡çµæœB**")
        selected_b = st.selectbox("çµæœB", result_options, format_func=lambda x: x[0], key="compare_b")
        result_b = results[selected_b[1]]
    
    if selected_a[1] == selected_b[1]:
        st.warning("è«‹é¸æ“‡ä¸åŒçš„åˆ†æçµæœé€²è¡Œå°æ¯”")
        return
    
    # å°æ¯”é¡¯ç¤º
    st.markdown("---")
    
    # åŸºæœ¬ä¿¡æ¯å°æ¯”
    st.subheader("ğŸ“‹ åŸºæœ¬ä¿¡æ¯å°æ¯”")
    
    comparison_data = {
        'é …ç›®': ['è‚¡ç¥¨ä»£ç¢¼', 'åˆ†ææ™‚é–“', 'åˆ†æå¸«', 'ç ”ç©¶æ·±åº¦', 'ç‹€æ…‹'],
        'çµæœA': [
            result_a.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_a.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            ', '.join(result_a.get('analysts', [])),
            str(result_a.get('research_depth', 'unknown')),
            'å®Œæˆ' if result_a.get('status') == 'completed' else 'å¤±è´¥'
        ],
        'çµæœB': [
            result_b.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_b.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            ', '.join(result_b.get('analysts', [])),
            str(result_b.get('research_depth', 'unknown')),
            'å®Œæˆ' if result_b.get('status') == 'completed' else 'å¤±è´¥'
        ]
    }
    
    df_comparison = pd.DataFrame(comparison_data)
    st.dataframe(df_comparison, use_container_width=True)
    
    # æ‘˜è¦å°æ¯”
    if result_a.get('summary') or result_b.get('summary'):
        st.subheader("ğŸ“ åˆ†ææ‘˜è¦å°æ¯”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**çµæœAæ‘˜è¦**")
            st.text_area("", value=result_a.get('summary', 'æš‚ç„¡æ‘˜è¦'), height=200, key="summary_a", disabled=True)
        
        with col2:
            st.write("**çµæœBæ‘˜è¦**")
            st.text_area("", value=result_b.get('summary', 'æš‚ç„¡æ‘˜è¦'), height=200, key="summary_b", disabled=True)
    
    # æ€§èƒ½å°æ¯”
    perf_a = result_a.get('performance', {})
    perf_b = result_b.get('performance', {})
    
    if perf_a or perf_b:
        st.subheader("âš¡ æ€§èƒ½æŒ‡æ¨™å°æ¯”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**çµæœAæ€§èƒ½**")
            if perf_a:
                st.json(perf_a)
            else:
                st.info("æš‚ç„¡æ€§èƒ½æ•¸æ“š")
        
        with col2:
            st.write("**çµæœBæ€§èƒ½**")
            if perf_b:
                st.json(perf_b)
            else:
                st.info("æš‚ç„¡æ€§èƒ½æ•¸æ“š")

def render_results_charts(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æçµæœçµ±è¨ˆåœ–è¡¨"""
    
    st.subheader("ğŸ“ˆ çµ±è¨ˆåœ–è¡¨")
    
    # æŒ‰è‚¡ç¥¨çµ±è¨ˆ
    st.subheader("ğŸ“Š æŒ‰è‚¡ç¥¨çµ±è¨ˆ")
    stock_counts = {}
    for result in results:
        stock = result.get('stock_symbol', 'unknown')
        stock_counts[stock] = stock_counts.get(stock, 0) + 1
    
    if stock_counts:
        # åªé¡¯ç¤ºå‰10å€‹æœ€å¸¸åˆ†æçš„è‚¡ç¥¨
        top_stocks = sorted(stock_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        stocks = [item[0] for item in top_stocks]
        counts = [item[1] for item in top_stocks]
        
        fig_bar = px.bar(
            x=stocks,
            y=counts,
            title="æœ€å¸¸åˆ†æçš„è‚¡ç¥¨ (å‰10å)",
            labels={'x': 'è‚¡ç¥¨ä»£ç¢¼', 'y': 'åˆ†ææ¬¡æ•¸'},
            color=counts,
            color_continuous_scale='viridis'
        )
        st.plotly_chart(fig_bar, use_container_width=True)
    
    # æŒ‰æ™‚é–“çµ±è¨ˆ
    st.subheader("ğŸ“… æ¯æ—¥åˆ†æè¶‹åŠ¿")
    daily_results = {}
    for result in results:
        date_str = safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%Y-%m-%d')
        daily_results[date_str] = daily_results.get(date_str, 0) + 1
    
    if daily_results:
        dates = sorted(daily_results.keys())
        counts = [daily_results[date] for date in dates]
        
        fig_line = go.Figure()
        fig_line.add_trace(go.Scatter(
            x=dates,
            y=counts,
            mode='lines+markers',
            name='æ¯æ—¥åˆ†ææ•¸',
            line=dict(color='#2E8B57', width=3),
            marker=dict(size=8, color='#FF6B6B'),
            fill='tonexty'
        ))
        fig_line.update_layout(
            title="æ¯æ—¥åˆ†æè¶‹åŠ¿",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="åˆ†ææ•¸é‡",
            hovermode='x unified'
        )
        st.plotly_chart(fig_line, use_container_width=True)
    
    # æŒ‰åˆ†æå¸«é¡å‹çµ±è¨ˆ
    st.subheader("ğŸ‘¥ åˆ†æå¸«ä½¿ç”¨åˆ†å¸ƒ")
    analyst_counts = {}
    for result in results:
        analysts = result.get('analysts', [])
        for analyst in analysts:
            analyst_counts[analyst] = analyst_counts.get(analyst, 0) + 1
    
    if analyst_counts:
        fig_pie = px.pie(
            values=list(analyst_counts.values()),
            names=list(analyst_counts.keys()),
            title="åˆ†æå¸«ä½¿ç”¨åˆ†å¸ƒ",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        st.plotly_chart(fig_pie, use_container_width=True)
    
    # æˆåŠŸç‡çµ±è¨ˆ
    st.subheader("âœ… åˆ†ææˆåŠŸç‡çµ±è¨ˆ")
    success_data = {'æˆåŠŸ': 0, 'å¤±è´¥': 0}
    for result in results:
        if result.get('status') == 'completed':
            success_data['æˆåŠŸ'] += 1
        else:
            success_data['å¤±è´¥'] += 1
    
    if success_data['æˆåŠŸ'] + success_data['å¤±è´¥'] > 0:
        fig_success = px.pie(
            values=list(success_data.values()),
            names=list(success_data.keys()),
            title="åˆ†ææˆåŠŸç‡",
            color_discrete_map={'æˆåŠŸ': '#4CAF50', 'å¤±è´¥': '#F44336'}
        )
        st.plotly_chart(fig_success, use_container_width=True)
    
    # æ¨™ç°½ä½¿ç”¨çµ±è¨ˆ
    tags_data = load_tags()
    if tags_data:
        st.subheader("ğŸ·ï¸ æ¨™ç°½ä½¿ç”¨çµ±è¨ˆ")
        tag_counts = {}
        for tag_list in tags_data.values():
            for tag in tag_list:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        if tag_counts:
            # åªé¡¯ç¤ºå‰10å€‹æœ€å¸¸ç”¨çš„æ¨™ç°½
            top_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10]
            tags = [item[0] for item in top_tags]
            counts = [item[1] for item in top_tags]
            
            fig_tags = px.bar(
                x=tags,
                y=counts,
                title="æœ€å¸¸ç”¨æ¨™ç°½ (å‰10å)",
                labels={'x': 'æ¨™ç°½', 'y': 'ä½¿ç”¨æ¬¡æ•¸'},
                color=counts,
                color_continuous_scale='plasma'
            )
            fig_tags.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_tags, use_container_width=True)

def render_tags_management(results: List[Dict[str, Any]]):
    """æ¸²æŸ“æ¨™ç°½ç®¡ç†åŠŸèƒ½"""
    
    st.subheader("ğŸ·ï¸ æ¨™ç°½ç®¡ç†")
    
    # ç²å–æ‰€æœ‰æ¨™ç°½
    all_tags = set()
    tags_data = load_tags()
    for tag_list in tags_data.values():
        all_tags.update(tag_list)
    
    # æ¨™ç°½çµ±è¨ˆ
    if all_tags:
        st.write("**ç¾æœ‰æ¨™ç°½çµ±è¨ˆ**")
        tag_counts = {}
        for tag_list in tags_data.values():
            for tag in tag_list:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        # é¡¯ç¤ºæ¨™ç°½äº‘
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # å‰µå»ºæ¨™ç°½äº‘å¯è¦–åŒ–
            if tag_counts:
                fig = px.bar(
                    x=list(tag_counts.keys()),
                    y=list(tag_counts.values()),
                    title="æ¨™ç°½ä½¿ç”¨é »ç‡",
                    labels={'x': 'æ¨™ç°½', 'y': 'ä½¿ç”¨æ¬¡æ•¸'}
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**æ¨™ç°½åˆ—è¡¨**")
            for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True):
                st.write(f"â€¢ {tag} ({count})")
    
    # æ‰¹é‡æ¨™ç°½æ“ä½œ
    st.markdown("---")
    st.write("**æ‰¹é‡æ¨™ç°½æ“ä½œ**")
    
    # é¸æ“‡è¦æ“ä½œçš„çµæœ
    if results:
        selected_results = st.multiselect(
            "é¸æ“‡åˆ†æçµæœ",
            options=range(len(results)),
            format_func=lambda i: f"{results[i].get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(results[i].get('timestamp', 0)).strftime('%m-%d %H:%M')}",
            max_selections=10
        )
        
        if selected_results:
            col1, col2 = st.columns(2)
            
            with col1:
                # æ·»åŠ æ¨™ç°½
                new_tag = st.text_input("æ–°æ¨™ç°½åç¨±", placeholder="è¼¸å…¥æ¨™ç°½åç¨±")
                if st.button("â• æ·»åŠ æ¨™ç°½") and new_tag:
                    for idx in selected_results:
                        analysis_id = results[idx].get('analysis_id', '')
                        if analysis_id:
                            add_tag_to_analysis(analysis_id, new_tag)
                    st.success(f"å·²ç‚º {len(selected_results)} å€‹çµæœæ·»åŠ æ¨™ç°½: {new_tag}")
                    st.rerun()
            
            with col2:
                # ç§»é™¤æ¨™ç°½
                if all_tags:
                    remove_tag = st.selectbox("é¸æ“‡è¦ç§»é™¤çš„æ¨™ç°½", sorted(all_tags))
                    if st.button("â– ç§»é™¤æ¨™ç°½") and remove_tag:
                        for idx in selected_results:
                            analysis_id = results[idx].get('analysis_id', '')
                            if analysis_id:
                                remove_tag_from_analysis(analysis_id, remove_tag)
                        st.success(f"å·²å¾ {len(selected_results)} å€‹çµæœç§»é™¤æ¨™ç°½: {remove_tag}")
                        st.rerun()

def render_results_export(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æçµæœå°å‡ºåŠŸèƒ½"""
    
    st.subheader("ğŸ“¤ å°å‡ºåˆ†æçµæœ")
    
    if not results:
        st.warning("æ²¡æœ‰å¯å°å‡ºçš„åˆ†æçµæœ")
        return
    
    # å°å‡ºé¸é …
    export_type = st.selectbox("é¸æ“‡å°å‡ºå…§å®¹", ["æ‘˜è¦ä¿¡æ¯", "å®Œæ•´æ•¸æ“š"])
    export_format = st.selectbox("é¸æ“‡å°å‡ºæ ¼å¼", ["CSV", "JSON", "Excel"])
    
    if st.button("ğŸ“¥ å°å‡ºçµæœ"):
        try:
            if export_type == "æ‘˜è¦ä¿¡æ¯":
                # å°å‡ºæ‘˜è¦ä¿¡æ¯
                summary_data = []
                for result in results:
                    summary_data.append({
                        'åˆ†ææ™‚é–“': safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M:%S'),
                        'è‚¡ç¥¨ä»£ç¢¼': result.get('stock_symbol', 'unknown'),
                        'åˆ†æå¸«': ', '.join(result.get('analysts', [])),
                        'ç ”ç©¶æ·±åº¦': result.get('research_depth', 'unknown'),
                        'ç‹€æ…‹': result.get('status', 'unknown'),
                        'æ‘˜è¦': result.get('summary', '')[:100] + '...' if len(result.get('summary', '')) > 100 else result.get('summary', '')
                    })
                
                if export_format == "CSV":
                    df = pd.DataFrame(summary_data)
                    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                    
                    st.download_button(
                        label="ä¸‹è¼‰ CSV æ–‡ä»¶",
                        data=csv_data,
                        file_name=f"analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                elif export_format == "JSON":
                    json_data = json.dumps(summary_data, ensure_ascii=False, indent=2)
                    
                    st.download_button(
                        label="ä¸‹è¼‰ JSON æ–‡ä»¶",
                        data=json_data,
                        file_name=f"analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                
                elif export_format == "Excel":
                    df = pd.DataFrame(summary_data)
                    
                    from io import BytesIO
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False, sheet_name='åˆ†ææ‘˜è¦')
                    
                    excel_data = output.getvalue()
                    
                    st.download_button(
                        label="ä¸‹è¼‰ Excel æ–‡ä»¶",
                        data=excel_data,
                        file_name=f"analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            
            else:  # å®Œæ•´æ•¸æ“š
                if export_format == "JSON":
                    json_data = json.dumps(results, ensure_ascii=False, indent=2)
                    
                    st.download_button(
                        label="ä¸‹è¼‰å®Œæ•´æ•¸æ“š JSON æ–‡ä»¶",
                        data=json_data,
                        file_name=f"analysis_full_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                else:
                    st.warning("å®Œæ•´æ•¸æ“šåªæ”¯æŒ JSON æ ¼å¼å°å‡º")
            
            st.success(f"âœ… {export_format} æ–‡ä»¶æº–å¤‡å®Œæˆï¼Œè«‹é»æ“Šä¸‹è¼‰æŒ‰é’®")
            
        except Exception as e:
            st.error(f"âŒ å°å‡ºå¤±è´¥: {e}")

def render_results_comparison(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æçµæœå°æ¯”"""
    
    st.subheader("ğŸ” åˆ†æçµæœå°æ¯”")
    
    if len(results) < 2:
        st.info("è‡³å°‘éœ€è¦2å€‹åˆ†æçµæœæ‰èƒ½é€²è¡Œå°æ¯”")
        return
    
    # é¸æ“‡è¦å°æ¯”çš„åˆ†æçµæœ
    st.write("**é¸æ“‡è¦å°æ¯”çš„åˆ†æçµæœï¼š**")
    
    col1, col2 = st.columns(2)
    
    # æº–å¤‡é¸é …
    result_options = []
    for i, result in enumerate(results[:20]):  # é™åˆ¶å‰20å€‹
        option = f"{result.get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M')}"
        result_options.append((option, i))
    
    with col1:
        st.write("**åˆ†æçµæœ A**")
        selected_a = st.selectbox(
            "é¸æ“‡ç¬¬ä¸€å€‹åˆ†æçµæœ", 
            result_options, 
            format_func=lambda x: x[0],
            key="compare_a"
        )
        result_a = results[selected_a[1]]
    
    with col2:
        st.write("**åˆ†æçµæœ B**")
        selected_b = st.selectbox(
            "é¸æ“‡ç¬¬äºŒå€‹åˆ†æçµæœ", 
            result_options, 
            format_func=lambda x: x[0],
            key="compare_b"
        )
        result_b = results[selected_b[1]]
    
    if selected_a[1] == selected_b[1]:
        st.warning("è«‹é¸æ“‡ä¸åŒçš„åˆ†æçµæœé€²è¡Œå°æ¯”")
        return
    
    # åŸºæœ¬ä¿¡æ¯å°æ¯”
    st.subheader("ğŸ“Š åŸºæœ¬ä¿¡æ¯å°æ¯”")
    
    comparison_data = {
        "é …ç›®": ["è‚¡ç¥¨ä»£ç¢¼", "åˆ†ææ™‚é–“", "åˆ†æå¸«æ•¸é‡", "ç ”ç©¶æ·±åº¦", "ç‹€æ…‹", "æ¨™ç°½æ•¸é‡"],
        "åˆ†æçµæœ A": [
            result_a.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_a.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            len(result_a.get('analysts', [])),
            result_a.get('research_depth', 'unknown'),
            "âœ… å®Œæˆ" if result_a.get('status') == 'completed' else "âŒ å¤±è´¥",
            len(result_a.get('tags', []))
        ],
        "åˆ†æçµæœ B": [
            result_b.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_b.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            len(result_b.get('analysts', [])),
            result_b.get('research_depth', 'unknown'),
            "âœ… å®Œæˆ" if result_b.get('status') == 'completed' else "âŒ å¤±è´¥",
            len(result_b.get('tags', []))
        ]
    }
    
    import pandas as pd
    df_comparison = pd.DataFrame(comparison_data)
    st.dataframe(df_comparison, use_container_width=True)
    
    # æ€§èƒ½æŒ‡æ¨™å°æ¯”
    perf_a = result_a.get('performance', {})
    perf_b = result_b.get('performance', {})
    
    if perf_a or perf_b:
        st.subheader("âš¡ æ€§èƒ½æŒ‡æ¨™å°æ¯”")
        
        # åˆä¸¦æ‰€æœ‰æ€§èƒ½æŒ‡æ¨™é”®
        all_perf_keys = set(perf_a.keys()) | set(perf_b.keys())
        
        if all_perf_keys:
            perf_comparison = {
                "æŒ‡æ¨™": list(all_perf_keys),
                "åˆ†æçµæœ A": [perf_a.get(key, "N/A") for key in all_perf_keys],
                "åˆ†æçµæœ B": [perf_b.get(key, "N/A") for key in all_perf_keys]
            }
            
            df_perf = pd.DataFrame(perf_comparison)
            st.dataframe(df_perf, use_container_width=True)
    
    # æ¨™ç°½å°æ¯”
    tags_a = set(result_a.get('tags', []))
    tags_b = set(result_b.get('tags', []))
    
    if tags_a or tags_b:
        st.subheader("ğŸ·ï¸ æ¨™ç°½å°æ¯”")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.write("**å…±åŒæ¨™ç°½**")
            common_tags = tags_a & tags_b
            if common_tags:
                for tag in common_tags:
                    st.markdown(f"âœ… `{tag}`")
            else:
                st.write("ç„¡å…±åŒæ¨™ç°½")
        
        with col2:
            st.write("**ä»…åœ¨çµæœAä¸­**")
            only_a = tags_a - tags_b
            if only_a:
                for tag in only_a:
                    st.markdown(f"ğŸ”µ `{tag}`")
            else:
                st.write("ç„¡ç¨æœ‰æ¨™ç°½")
        
        with col3:
            st.write("**ä»…åœ¨çµæœBä¸­**")
            only_b = tags_b - tags_a
            if only_b:
                for tag in only_b:
                    st.markdown(f"ğŸ”´ `{tag}`")
            else:
                st.write("ç„¡ç¨æœ‰æ¨™ç°½")
    
    # æ‘˜è¦å°æ¯”
    summary_a = result_a.get('summary', '')
    summary_b = result_b.get('summary', '')
    
    if summary_a or summary_b:
        st.subheader("ğŸ“ åˆ†ææ‘˜è¦å°æ¯”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**åˆ†æçµæœ A æ‘˜è¦**")
            if summary_a:
                st.markdown(summary_a)
            else:
                st.write("ç„¡æ‘˜è¦")
        
        with col2:
            st.write("**åˆ†æçµæœ B æ‘˜è¦**")
            if summary_b:
                st.markdown(summary_b)
            else:
                st.write("ç„¡æ‘˜è¦")
    
    # è©³ç´°å…§å®¹å°æ¯”
    st.subheader("ğŸ“Š è©³ç´°å…§å®¹å°æ¯”")
    
    # å®šç¾©è¦å°æ¯”çš„é—œé”®å­—æ®µ
    comparison_fields = [
        ('market_report', 'ğŸ“ˆ å¸‚å ´æŠ€è¡“åˆ†æ'),
        ('fundamentals_report', 'ğŸ’° åŸºæœ¬é¢åˆ†æ'),
        ('sentiment_report', 'ğŸ’­ å¸‚å ´æƒ…ç»ªåˆ†æ'),
        ('news_report', 'ğŸ“° æ–°èäº‹ä»¶åˆ†æ'),
        ('risk_assessment', 'âš ï¸ é¢¨éšªè©•ä¼°'),
        ('investment_plan', 'ğŸ“‹ æŠ•è³‡å»ºè­°'),
        ('final_trade_decision', 'ğŸ¯ æœ€çµ‚äº¤æ˜“æ±ºç­–')
    ]
    
    # å‰µå»ºå°æ¯”æ¨™ç°½é¡µ
    available_fields = []
    for field_key, field_name in comparison_fields:
        if (field_key in result_a and result_a[field_key]) or (field_key in result_b and result_b[field_key]):
            available_fields.append((field_key, field_name))
    
    if available_fields:
        tabs = st.tabs([field_name for _, field_name in available_fields])
        
        for i, (tab, (field_key, field_name)) in enumerate(zip(tabs, available_fields)):
            with tab:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**åˆ†æçµæœ A**")
                    content_a = result_a.get(field_key, '')
                    if content_a:
                        if isinstance(content_a, str):
                            st.markdown(content_a)
                        else:
                            st.write(content_a)
                    else:
                        st.write("ç„¡æ­¤é …åˆ†æ")
                
                with col2:
                    st.write("**åˆ†æçµæœ B**")
                    content_b = result_b.get(field_key, '')
                    if content_b:
                        if isinstance(content_b, str):
                            st.markdown(content_b)
                        else:
                            st.write(content_b)
                    else:
                        st.write("ç„¡æ­¤é …åˆ†æ")

def render_detailed_analysis(results: List[Dict[str, Any]]):
    """æ¸²æŸ“è©³ç´°åˆ†æ"""
    
    st.subheader("ğŸ“Š è©³ç´°åˆ†æ")
    
    if not results:
        st.info("æ²¡æœ‰å¯åˆ†æçš„æ•¸æ“š")
        return
    
    # é¸æ“‡è¦æŸ¥çœ‹çš„åˆ†æçµæœ
    result_options = []
    for i, result in enumerate(results[:50]):  # é¡¯ç¤ºå‰50å€‹
        option = f"{result.get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M')}"
        result_options.append((option, i))
    
    if result_options:
        selected_option = st.selectbox(
            "é¸æ“‡åˆ†æçµæœ", 
            result_options, 
            format_func=lambda x: x[0]
        )
        selected_result = results[selected_option[1]]
        
        # é¡¯ç¤ºåŸºæœ¬ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("è‚¡ç¥¨ä»£ç¢¼", selected_result.get('stock_symbol', 'unknown'))
            st.metric("åˆ†æå¸«æ•¸é‡", len(selected_result.get('analysts', [])))
        
        with col2:
            analysis_time = safe_timestamp_to_datetime(selected_result.get('timestamp', 0))
            st.metric("åˆ†ææ™‚é–“", analysis_time.strftime('%m-%d %H:%M'))
            status = "âœ… å®Œæˆ" if selected_result.get('status') == 'completed' else "âŒ å¤±è´¥"
            st.metric("ç‹€æ…‹", status)
        
        with col3:
            st.metric("ç ”ç©¶æ·±åº¦", selected_result.get('research_depth', 'unknown'))
            tags = selected_result.get('tags', [])
            st.metric("æ¨™ç°½æ•¸é‡", len(tags))
        
        # é¡¯ç¤ºæ¨™ç°½
        if tags:
            st.write("**æ¨™ç°½**:")
            tag_cols = st.columns(min(len(tags), 5))
            for i, tag in enumerate(tags):
                with tag_cols[i % 5]:
                    st.markdown(f"`{tag}`")
        
        # é¡¯ç¤ºåˆ†ææ‘˜è¦
        if selected_result.get('summary'):
            st.subheader("ğŸ“ åˆ†ææ‘˜è¦")
            st.markdown(selected_result['summary'])
        
        # é¡¯ç¤ºæ€§èƒ½æŒ‡æ¨™
        performance = selected_result.get('performance', {})
        if performance:
            st.subheader("âš¡ æ€§èƒ½æŒ‡æ¨™")
            perf_cols = st.columns(len(performance))
            for i, (key, value) in enumerate(performance.items()):
                with perf_cols[i]:
                    st.metric(key.replace('_', ' ').title(), f"{value:.2f}" if isinstance(value, (int, float)) else str(value))
        
        # é¡¯ç¤ºå®Œæ•´åˆ†æçµæœ
        if st.checkbox("é¡¯ç¤ºå®Œæ•´åˆ†æçµæœ"):
            render_detailed_analysis_content(selected_result)

def render_detailed_analysis_content(selected_result):
    """æ¸²æŸ“è©³ç´°åˆ†æçµæœå…§å®¹"""
    st.subheader("ğŸ“Š å®Œæ•´åˆ†ææ•¸æ“š")

    # æª¢æŸ¥æ˜¯å¦æœ‰å ±å‘Šæ•¸æ“šï¼ˆæ”¯æŒæ–‡ä»¶ç³»çµ±å’ŒMongoDBï¼‰
    if 'reports' in selected_result and selected_result['reports']:
        # é¡¯ç¤ºæ–‡ä»¶ç³»çµ±ä¸­çš„å ±å‘Š
        reports = selected_result['reports']
        
        if not reports:
            st.warning("è¯¥åˆ†æçµæœæ²¡æœ‰å¯ç”¨çš„å ±å‘Šå…§å®¹")
            return
        
        # èª¿è©¦ä¿¡æ¯ï¼šé¡¯ç¤ºæ‰€æœ‰å¯ç”¨çš„å ±å‘Š
        print(f"ğŸ” [å¼¹çª—èª¿è©¦] æ•¸æ“šä¾†æº: {selected_result.get('source', 'æœªçŸ¥')}")
        print(f"ğŸ” [å¼¹çª—èª¿è©¦] å¯ç”¨å ±å‘Šæ•¸é‡: {len(reports)}")
        print(f"ğŸ” [å¼¹çª—èª¿è©¦] å ±å‘Šé¡å‹: {list(reports.keys())}")

        # å‰µå»ºæ¨™ç°½é¡µé¡¯ç¤ºä¸åŒçš„å ±å‘Š
        report_tabs = list(reports.keys())

        # ç‚ºå ±å‘Šåç¨±æ·»åŠ ä¸­æ–‡æ¨™é¡Œå’Œåœ–æ¨™
        report_display_names = {
            'final_trade_decision': 'ğŸ¯ æœ€çµ‚äº¤æ˜“æ±ºç­–',
            'fundamentals_report': 'ğŸ’° åŸºæœ¬é¢åˆ†æ',
            'technical_report': 'ğŸ“ˆ æŠ€è¡“é¢åˆ†æ',
            'market_sentiment_report': 'ğŸ’­ å¸‚å ´æƒ…ç»ªåˆ†æ',
            'risk_assessment_report': 'âš ï¸ é¢¨éšªè©•ä¼°',
            'price_target_report': 'ğŸ¯ ç›®æ¨™åƒ¹æ ¼åˆ†æ',
            'summary_report': 'ğŸ“‹ åˆ†ææ‘˜è¦',
            'news_analysis_report': 'ğŸ“° æ–°èåˆ†æ',
            'social_media_report': 'ğŸ“± ç¤¾äº¤åª’é«”åˆ†æ'
        }
        
        # å‰µå»ºé¡¯ç¤ºåç¨±åˆ—è¡¨
        tab_names = []
        for report_key in report_tabs:
            display_name = report_display_names.get(report_key, f"ğŸ“„ {report_key.replace('_', ' ').title()}")
            tab_names.append(display_name)
            print(f"ğŸ” [å¼¹çª—èª¿è©¦] æ·»åŠ æ¨™ç°½: {display_name}")

        print(f"ğŸ” [å¼¹çª—èª¿è©¦] æ€»æ¨™ç°½æ•¸: {len(tab_names)}")
        
        if len(tab_names) == 1:
            # åªæœ‰ä¸€å€‹å ±å‘Šï¼Œç›´æ¥é¡¯ç¤º
            st.markdown(f"### {tab_names[0]}")
            st.markdown("---")
            st.markdown(reports[report_tabs[0]])
        else:
            # å¤šå€‹å ±å‘Šï¼Œä½¿ç”¨æ¨™ç°½é¡µ
            tabs = st.tabs(tab_names)
            
            for i, (tab, report_key) in enumerate(zip(tabs, report_tabs)):
                with tab:
                    st.markdown(reports[report_key])
        
        return
    
    # æ·»åŠ è‡ªå®šç¾©CSSæ¨£å¼ç¾åŒ–æ¨™ç°½é¡µ
    st.markdown("""
    <style>
    /* æ¨™ç°½é¡µå®¹å™¨æ¨£å¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #f8f9fa;
        padding: 8px;
        border-radius: 10px;
        margin-bottom: 20px;
    }

    /* å–®å€‹æ¨™ç°½é¡µæ¨£å¼ */
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding: 8px 16px;
        background-color: #ffffff;
        border-radius: 8px;
        border: 1px solid #e1e5e9;
        color: #495057;
        font-weight: 500;
        transition: all 0.3s ease;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    /* æ¨™ç°½é¡µæ‚¬åœæ•ˆæœ */
    .stTabs [data-baseweb="tab"]:hover {
        background-color: #e3f2fd;
        border-color: #2196f3;
        transform: translateY(-1px);
        box-shadow: 0 2px 8px rgba(33,150,243,0.2);
    }

    /* é¸ä¸­çš„æ¨™ç°½é¡µæ¨£å¼ */
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border-color: #667eea !important;
        box-shadow: 0 4px 12px rgba(102,126,234,0.3) !important;
        transform: translateY(-2px);
    }

    /* æ¨™ç°½é¡µå…§å®¹å€åŸŸ */
    .stTabs [data-baseweb="tab-panel"] {
        padding: 20px;
        background-color: #ffffff;
        border-radius: 10px;
        border: 1px solid #e1e5e9;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }

    /* æ¨™ç°½é¡µæ–‡å­—æ¨£å¼ */
    .stTabs [data-baseweb="tab"] p {
        margin: 0;
        font-size: 14px;
        font-weight: 600;
    }

    /* é¸ä¸­æ¨™ç°½é¡µçš„æ–‡å­—æ¨£å¼ */
    .stTabs [aria-selected="true"] p {
        color: white !important;
        text-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }
    </style>
    """, unsafe_allow_html=True)
    
    # å®šç¾©åˆ†ææ¨¡å¡Š
    analysis_modules = [
        {
            'key': 'market_report',
            'title': 'ğŸ“ˆ å¸‚å ´æŠ€è¡“åˆ†æ',
            'icon': 'ğŸ“ˆ',
            'description': 'æŠ€è¡“æŒ‡æ¨™ã€åƒ¹æ ¼è¶‹åŠ¿ã€æ”¯æ’‘é˜»åŠ›ä½åˆ†æ'
        },
        {
            'key': 'fundamentals_report',
            'title': 'ğŸ’° åŸºæœ¬é¢åˆ†æ',
            'icon': 'ğŸ’°',
            'description': 'è²¡å‹™æ•¸æ“šã€ä¼°å€¼æ°´å¹³ã€ç›ˆåˆ©èƒ½åŠ›åˆ†æ'
        },
        {
            'key': 'sentiment_report',
            'title': 'ğŸ’­ å¸‚å ´æƒ…ç»ªåˆ†æ',
            'icon': 'ğŸ’­',
            'description': 'æŠ•è³‡è€…æƒ…ç»ªã€ç¤¾äº¤åª’é«”æƒ…ç»ªæŒ‡æ¨™'
        },
        {
            'key': 'news_report',
            'title': 'ğŸ“° æ–°èäº‹ä»¶åˆ†æ',
            'icon': 'ğŸ“°',
            'description': 'ç›¸é—œæ–°èäº‹ä»¶ã€å¸‚å ´å‹•æ…‹å½±éŸ¿åˆ†æ'
        },
        {
            'key': 'risk_assessment',
            'title': 'âš ï¸ é¢¨éšªè©•ä¼°',
            'icon': 'âš ï¸',
            'description': 'é¢¨éšªå› ç´ è¯†åˆ¥ã€é¢¨éšªç­‰ç´šè©•ä¼°'
        },
        {
            'key': 'investment_plan',
            'title': 'ğŸ“‹ æŠ•è³‡å»ºè­°',
            'icon': 'ğŸ“‹',
            'description': 'å…·é«”æŠ•è³‡ç­–ç•¥ã€ä»“ä½ç®¡ç†å»ºè­°'
        },
        {
            'key': 'investment_debate_state',
            'title': 'ğŸ”¬ ç ”ç©¶å›¢éšŠæ±ºç­–',
            'icon': 'ğŸ”¬',
            'description': 'å¤šå¤´/ç©ºå¤´ç ”ç©¶å“¡è¾©è«–åˆ†æï¼Œç ”ç©¶ç¶“ç†ç¶œåˆæ±ºç­–'
        },
        {
            'key': 'trader_investment_plan',
            'title': 'ğŸ’¼ äº¤æ˜“å›¢éšŠè¨ˆåŠƒ',
            'icon': 'ğŸ’¼',
            'description': 'å°ˆæ¥­äº¤æ˜“å“¡åˆ¶å®šçš„å…·é«”äº¤æ˜“åŸ·è¡Œè¨ˆåŠƒ'
        },
        {
            'key': 'risk_debate_state',
            'title': 'âš–ï¸ é¢¨éšªç®¡ç†å›¢éšŠ',
            'icon': 'âš–ï¸',
            'description': 'æ¿€é€²/ä¿å®ˆ/ä¸­æ€§åˆ†æå¸«é¢¨éšªè©•ä¼°ï¼ŒæŠ•è³‡çµ„åˆç¶“ç†æœ€çµ‚æ±ºç­–'
        },
        {
            'key': 'final_trade_decision',
            'title': 'ğŸ¯ æœ€çµ‚äº¤æ˜“æ±ºç­–',
            'icon': 'ğŸ¯',
            'description': 'ç¶œåˆæ‰€æœ‰å›¢éšŠåˆ†æå¾Œçš„æœ€çµ‚æŠ•è³‡æ±ºç­–'
        }
    ]
    
    # éæ¿¾å‡ºæœ‰æ•¸æ“šçš„æ¨¡å¡Š
    available_modules = []
    for module in analysis_modules:
        if module['key'] in selected_result and selected_result[module['key']]:
            # æª¢æŸ¥å­—å…¸é¡å‹çš„æ•¸æ“šæ˜¯å¦æœ‰å¯¦é™…å…§å®¹
            if isinstance(selected_result[module['key']], dict):
                # å°æ–¼å­—å…¸ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰éç©ºçš„å€¼
                has_content = any(v for v in selected_result[module['key']].values() if v)
                if has_content:
                    available_modules.append(module)
            else:
                # å°æ–¼å­—ç¬¦ä¸²æˆ–å…¶ä»–é¡å‹ï¼Œç›´æ¥æ·»åŠ 
                available_modules.append(module)

    if not available_modules:
        # å¦‚æœæ²¡æœ‰é å®šç¾©æ¨¡å¡Šçš„æ•¸æ“šï¼Œé¡¯ç¤ºæ‰€æœ‰å¯ç”¨çš„åˆ†ææ•¸æ“š
        st.info("ğŸ“Š é¡¯ç¤ºå®Œæ•´åˆ†æå ±å‘Šæ•¸æ“š")
        
        # æ’é™¤ä¸€äº›åŸºç¡€å­—æ®µï¼Œåªé¡¯ç¤ºåˆ†æç›¸é—œçš„æ•¸æ“š
        excluded_keys = {'analysis_id', 'timestamp', 'stock_symbol', 'analysts', 
                        'research_depth', 'status', 'summary', 'performance', 
                        'is_favorite', 'tags', 'full_data'}
        
        # ç²å–æ‰€æœ‰åˆ†æç›¸é—œçš„æ•¸æ“š
        analysis_data = {}
        for key, value in selected_result.items():
            if key not in excluded_keys and value:
                analysis_data[key] = value
        
        # å¦‚æœæœ‰full_dataå­—æ®µï¼Œå„ªå…ˆä½¿ç”¨å®ƒ
        if 'full_data' in selected_result and selected_result['full_data']:
            full_data = selected_result['full_data']
            if isinstance(full_data, dict):
                for key, value in full_data.items():
                    if key not in excluded_keys and value:
                        analysis_data[key] = value
        
        if analysis_data:
            # å‰µå»ºå‹•æ…‹æ¨™ç°½é¡µé¡¯ç¤ºæ‰€æœ‰åˆ†ææ•¸æ“š
            tab_names = []
            tab_data = []
            
            for key, value in analysis_data.items():
                # æ ¼å¼åŒ–æ¨™ç°½é¡µåç¨±
                tab_name = key.replace('_', ' ').title()
                if 'report' in key.lower():
                    tab_name = f"ğŸ“Š {tab_name}"
                elif 'analysis' in key.lower():
                    tab_name = f"ğŸ” {tab_name}"
                elif 'decision' in key.lower():
                    tab_name = f"ğŸ¯ {tab_name}"
                elif 'plan' in key.lower():
                    tab_name = f"ğŸ“‹ {tab_name}"
                else:
                    tab_name = f"ğŸ“„ {tab_name}"
                
                tab_names.append(tab_name)
                tab_data.append((key, value))
            
            # å‰µå»ºæ¨™ç°½é¡µ
            tabs = st.tabs(tab_names)
            
            for i, (tab, (key, value)) in enumerate(zip(tabs, tab_data)):
                with tab:
                    st.markdown(f"## {tab_names[i]}")
                    st.markdown("---")
                    
                    # æ ¹æ“šæ•¸æ“šé¡å‹é¡¯ç¤ºå…§å®¹
                    if isinstance(value, str):
                        # å¦‚æœæ˜¯é•·æ–‡æœ¬ï¼Œä½¿ç”¨markdowné¡¯ç¤º
                        if len(value) > 100:
                            st.markdown(value)
                        else:
                            st.write(value)
                    elif isinstance(value, dict):
                        # å­—å…¸é¡å‹ï¼Œéæ­¸é¡¯ç¤º
                        for sub_key, sub_value in value.items():
                            if sub_value:
                                st.subheader(sub_key.replace('_', ' ').title())
                                if isinstance(sub_value, str):
                                    st.markdown(sub_value)
                                else:
                                    st.write(sub_value)
                    elif isinstance(value, list):
                        # åˆ—è¡¨é¡å‹
                        for idx, item in enumerate(value):
                            st.subheader(f"é …ç›® {idx + 1}")
                            if isinstance(item, str):
                                st.markdown(item)
                            else:
                                st.write(item)
                    else:
                        # å…¶ä»–é¡å‹ç›´æ¥é¡¯ç¤º
                        st.write(value)
        else:
            # å¦‚æœçœŸçš„æ²¡æœ‰ä»»ä½•åˆ†ææ•¸æ“šï¼Œé¡¯ç¤ºåŸå§‹JSON
            st.warning("ğŸ“Š è¯¥åˆ†æçµæœæš‚ç„¡è©³ç´°å ±å‘Šæ•¸æ“š")
            with st.expander("æŸ¥çœ‹åŸå§‹æ•¸æ“š"):
                st.json(selected_result)
        return

    # åªç‚ºæœ‰æ•¸æ“šçš„æ¨¡å¡Šå‰µå»ºæ¨™ç°½é¡µ
    tabs = st.tabs([module['title'] for module in available_modules])

    for i, (tab, module) in enumerate(zip(tabs, available_modules)):
        with tab:
            # åœ¨å…§å®¹å€åŸŸé¡¯ç¤ºåœ–æ¨™å’Œæè¿°
            st.markdown(f"## {module['icon']} {module['title']}")
            st.markdown(f"*{module['description']}*")
            st.markdown("---")

            # æ ¼å¼åŒ–é¡¯ç¤ºå…§å®¹
            content = selected_result[module['key']]
            if isinstance(content, str):
                st.markdown(content)
            elif isinstance(content, dict):
                # ç‰¹æ®Šè™•ç†å›¢éšŠæ±ºç­–å ±å‘Šçš„å­—å…¸çµæ§‹
                if module['key'] == 'investment_debate_state':
                    render_investment_debate_content(content)
                elif module['key'] == 'risk_debate_state':
                    render_risk_debate_content(content)
                else:
                    # æ™®é€šå­—å…¸æ ¼å¼åŒ–é¡¯ç¤º
                    for key, value in content.items():
                        if value:  # åªé¡¯ç¤ºéç©ºå€¼
                            st.subheader(key.replace('_', ' ').title())
                            if isinstance(value, str):
                                st.markdown(value)
                            else:
                                st.write(value)
            else:
                st.write(content)

def render_investment_debate_content(content):
    """æ¸²æŸ“æŠ•è³‡è¾©è«–å…§å®¹"""
    if 'bull_analyst_report' in content and content['bull_analyst_report']:
        st.subheader("ğŸ‚ å¤šå¤´åˆ†æå¸«è§€é»")
        st.markdown(content['bull_analyst_report'])
    
    if 'bear_analyst_report' in content and content['bear_analyst_report']:
        st.subheader("ğŸ» ç©ºå¤´åˆ†æå¸«è§€é»")
        st.markdown(content['bear_analyst_report'])
    
    if 'research_manager_decision' in content and content['research_manager_decision']:
        st.subheader("ğŸ‘¨â€ğŸ’¼ ç ”ç©¶ç¶“ç†æ±ºç­–")
        st.markdown(content['research_manager_decision'])

def render_risk_debate_content(content):
    """æ¸²æŸ“é¢¨éšªè¾©è«–å…§å®¹"""
    if 'aggressive_analyst_report' in content and content['aggressive_analyst_report']:
        st.subheader("ğŸ”¥ æ¿€é€²åˆ†æå¸«è§€é»")
        st.markdown(content['aggressive_analyst_report'])
    
    if 'conservative_analyst_report' in content and content['conservative_analyst_report']:
        st.subheader("ğŸ›¡ï¸ ä¿å®ˆåˆ†æå¸«è§€é»")
        st.markdown(content['conservative_analyst_report'])
    
    if 'neutral_analyst_report' in content and content['neutral_analyst_report']:
        st.subheader("âš–ï¸ ä¸­æ€§åˆ†æå¸«è§€é»")
        st.markdown(content['neutral_analyst_report'])
    
    if 'portfolio_manager_decision' in content and content['portfolio_manager_decision']:
        st.subheader("ğŸ‘¨â€ğŸ’¼ æŠ•è³‡çµ„åˆç¶“ç†æ±ºç­–")
        st.markdown(content['portfolio_manager_decision'])

def save_analysis_result(analysis_id: str, stock_symbol: str, analysts: List[str],
                        research_depth: int, result_data: Dict, status: str = "completed"):
    """ä¿å­˜åˆ†æçµæœ"""
    try:
        from web.utils.async_progress_tracker import safe_serialize

        # å‰µå»ºçµæœæ¢ç›®ï¼Œä½¿ç”¨å®‰å…¨åºåˆ—åŒ–
        result_entry = {
            'analysis_id': analysis_id,
            'timestamp': datetime.now().timestamp(),
            'stock_symbol': stock_symbol,
            'analysts': analysts,
            'research_depth': research_depth,
            'status': status,
            'summary': safe_serialize(result_data.get('summary', '')),
            'performance': safe_serialize(result_data.get('performance', {})),
            'full_data': safe_serialize(result_data)
        }

        # 1. ä¿å­˜åˆ°æ–‡ä»¶ç³»çµ±ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        results_dir = get_analysis_results_dir()
        result_file = results_dir / f"analysis_{analysis_id}.json"

        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_entry, f, ensure_ascii=False, indent=2)

        # 2. ä¿å­˜åˆ°MongoDBï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if MONGODB_AVAILABLE:
            try:
                print(f"ğŸ’¾ [MongoDBä¿å­˜] é–‹å§‹ä¿å­˜åˆ†æçµæœ: {analysis_id}")
                mongodb_manager = MongoDBReportManager()

                # ä½¿ç”¨æ¨™æº–çš„save_analysis_reportæ–¹æ³•ï¼Œç¢ºä¿æ•¸æ“šçµæ§‹ä¸€è‡´
                analysis_results = {
                    'stock_symbol': result_entry.get('stock_symbol', ''),
                    'analysts': result_entry.get('analysts', []),
                    'research_depth': result_entry.get('research_depth', 1),
                    'summary': result_entry.get('summary', '')
                }

                # å˜—è©¦å¾æ–‡ä»¶ç³»çµ±è®€å–å ±å‘Šå…§å®¹
                reports = {}
                try:
                    # æ§‹å»ºå ±å‘Šç›®éŒ„è·¯å¾‘
                    from pathlib import Path
                    import os

                    # ç²å–ç•¶å‰æ—¥æœŸ
                    current_date = datetime.now().strftime('%Y-%m-%d')

                    # æ§‹å»ºå ±å‘Šè·¯å¾‘
                    project_root = Path(__file__).parent.parent.parent
                    reports_dir = project_root / "data" / "analysis_results" / stock_symbol / current_date / "reports"

                    # ç¢ºä¿è·¯å¾‘åœ¨Windowsä¸Šæ­£ç¢ºé¡¯ç¤ºï¼ˆé¿å…é›™åæ–œæ ï¼‰
                    reports_dir_str = os.path.normpath(str(reports_dir))
                    print(f"ğŸ” [MongoDBä¿å­˜] æŸ¥æ‰¾å ±å‘Šç›®éŒ„: {reports_dir_str}")

                    if reports_dir.exists():
                        # è®€å–æ‰€æœ‰å ±å‘Šæ–‡ä»¶
                        for report_file in reports_dir.glob("*.md"):
                            try:
                                with open(report_file, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    report_name = report_file.stem
                                    reports[report_name] = content
                                    print(f"âœ… [MongoDBä¿å­˜] è®€å–å ±å‘Š: {report_name} ({len(content)} å­—ç¬¦)")
                            except Exception as e:
                                print(f"âš ï¸ [MongoDBä¿å­˜] è®€å–å ±å‘Šæ–‡ä»¶å¤±è´¥ {report_file}: {e}")

                        print(f"ğŸ“Š [MongoDBä¿å­˜] å…±è®€å– {len(reports)} å€‹å ±å‘Šæ–‡ä»¶")
                    else:
                        print(f"âš ï¸ [MongoDBä¿å­˜] å ±å‘Šç›®éŒ„ä¸å­˜åœ¨: {reports_dir_str}")

                except Exception as e:
                    print(f"âš ï¸ [MongoDBä¿å­˜] è®€å–å ±å‘Šæ–‡ä»¶ç•°å¸¸: {e}")
                    reports = {}

                # ä½¿ç”¨æ¨™æº–ä¿å­˜æ–¹æ³•ï¼Œç¢ºä¿å­—æ®µçµæ§‹ä¸€è‡´
                success = mongodb_manager.save_analysis_report(
                    stock_symbol=result_entry.get('stock_symbol', ''),
                    analysis_results=analysis_results,
                    reports=reports
                )

                if success:
                    print(f"âœ… [MongoDBä¿å­˜] åˆ†æçµæœå·²ä¿å­˜åˆ°MongoDB: {analysis_id} (åŒ…å« {len(reports)} å€‹å ±å‘Š)")
                else:
                    print(f"âŒ [MongoDBä¿å­˜] ä¿å­˜å¤±è´¥: {analysis_id}")

            except Exception as e:
                print(f"âŒ [MongoDBä¿å­˜] ä¿å­˜ç•°å¸¸: {e}")
                logger.error(f"MongoDBä¿å­˜ç•°å¸¸: {e}")

        return True

    except Exception as e:
        print(f"âŒ [ä¿å­˜åˆ†æçµæœ] ä¿å­˜å¤±è´¥: {e}")
        logger.error(f"ä¿å­˜åˆ†æçµæœç•°å¸¸: {e}")
        return False

def show_expanded_detail(result):
    """é¡¯ç¤ºå±•é–‹çš„è©³æƒ…å…§å®¹"""

    # å‰µå»ºè©³æƒ…å®¹å™¨
    with st.container():
        st.markdown("---")
        st.markdown("### ğŸ“Š è©³ç´°åˆ†æå ±å‘Š")

        # æª¢æŸ¥æ˜¯å¦æœ‰å ±å‘Šæ•¸æ“š
        if 'reports' not in result or not result['reports']:
            # å¦‚æœæ²¡æœ‰reportså­—æ®µï¼Œæª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–åˆ†ææ•¸æ“š
            if result.get('summary'):
                st.subheader("ğŸ“ åˆ†ææ‘˜è¦")
                st.markdown(result['summary'])

            # æª¢æŸ¥æ˜¯å¦æœ‰full_dataä¸­çš„å ±å‘Š
            if 'full_data' in result and result['full_data']:
                full_data = result['full_data']
                if isinstance(full_data, dict):
                    # é¡¯ç¤ºfull_dataä¸­çš„åˆ†æå…§å®¹
                    analysis_fields = [
                        ('market_report', 'ğŸ“ˆ å¸‚å ´åˆ†æ'),
                        ('fundamentals_report', 'ğŸ’° åŸºæœ¬é¢åˆ†æ'),
                        ('sentiment_report', 'ğŸ’­ æƒ…æ„Ÿåˆ†æ'),
                        ('news_report', 'ğŸ“° æ–°èåˆ†æ'),
                        ('risk_assessment', 'âš ï¸ é¢¨éšªè©•ä¼°'),
                        ('investment_plan', 'ğŸ“‹ æŠ•è³‡å»ºè­°'),
                        ('final_trade_decision', 'ğŸ¯ æœ€çµ‚æ±ºç­–')
                    ]

                    available_reports = []
                    for field_key, field_name in analysis_fields:
                        if field_key in full_data and full_data[field_key]:
                            available_reports.append((field_key, field_name, full_data[field_key]))

                    if available_reports:
                        # å‰µå»ºæ¨™ç°½é¡µé¡¯ç¤ºåˆ†æå…§å®¹
                        tab_names = [name for _, name, _ in available_reports]
                        tabs = st.tabs(tab_names)

                        for i, (tab, (field_key, field_name, content)) in enumerate(zip(tabs, available_reports)):
                            with tab:
                                if isinstance(content, str):
                                    st.markdown(content)
                                elif isinstance(content, dict):
                                    for key, value in content.items():
                                        if value:
                                            st.subheader(key.replace('_', ' ').title())
                                            st.markdown(str(value))
                                else:
                                    st.write(content)
                    else:
                        st.info("æš‚ç„¡è©³ç´°åˆ†æå ±å‘Š")
                else:
                    st.info("æš‚ç„¡è©³ç´°åˆ†æå ±å‘Š")
            else:
                st.info("æš‚ç„¡è©³ç´°åˆ†æå ±å‘Š")
            return

        # ç²å–å ±å‘Šæ•¸æ“š
        reports = result['reports']

        # ç‚ºå ±å‘Šåç¨±æ·»åŠ ä¸­æ–‡æ¨™é¡Œå’Œåœ–æ¨™
        report_display_names = {
            'final_trade_decision': 'ğŸ¯ æœ€çµ‚äº¤æ˜“æ±ºç­–',
            'fundamentals_report': 'ğŸ’° åŸºæœ¬é¢åˆ†æ',
            'technical_report': 'ğŸ“ˆ æŠ€è¡“é¢åˆ†æ',
            'market_sentiment_report': 'ğŸ’­ å¸‚å ´æƒ…ç»ªåˆ†æ',
            'risk_assessment_report': 'âš ï¸ é¢¨éšªè©•ä¼°',
            'price_target_report': 'ğŸ¯ ç›®æ¨™åƒ¹æ ¼åˆ†æ',
            'summary_report': 'ğŸ“‹ åˆ†ææ‘˜è¦',
            'news_analysis_report': 'ğŸ“° æ–°èåˆ†æ',
            'news_report': 'ğŸ“° æ–°èåˆ†æ',
            'market_report': 'ğŸ“ˆ å¸‚å ´åˆ†æ',
            'social_media_report': 'ğŸ“± ç¤¾äº¤åª’é«”åˆ†æ',
            'bull_state': 'ğŸ‚ å¤šå¤´è§€é»',
            'bear_state': 'ğŸ» ç©ºå¤´è§€é»',
            'trader_state': 'ğŸ’¼ äº¤æ˜“å“¡åˆ†æ',
            'invest_judge_state': 'âš–ï¸ æŠ•è³‡åˆ¤æ–·',
            'research_team_state': 'ğŸ”¬ ç ”ç©¶å›¢éšŠè§€é»',
            'risk_debate_state': 'âš ï¸ é¢¨éšªç®¡ç†è¨è«–',
            'research_team_decision': 'ğŸ”¬ ç ”ç©¶å›¢éšŠæ±ºç­–',
            'risk_management_decision': 'ğŸ›¡ï¸ é¢¨éšªç®¡ç†æ±ºç­–',
            'investment_plan': 'ğŸ“‹ æŠ•è³‡è¨ˆåŠƒ',
            'trader_investment_plan': 'ğŸ’¼ äº¤æ˜“å“¡æŠ•è³‡è¨ˆåŠƒ',
            'investment_debate_state': 'ğŸ’¬ æŠ•è³‡è¨è«–ç‹€æ…‹'
        }

        # å‰µå»ºæ¨™ç°½é¡µé¡¯ç¤ºä¸åŒçš„å ±å‘Š
        report_tabs = list(reports.keys())
        tab_names = []
        for report_key in report_tabs:
            display_name = report_display_names.get(report_key, f"ğŸ“„ {report_key.replace('_', ' ').title()}")
            tab_names.append(display_name)

        if len(tab_names) == 1:
            # åªæœ‰ä¸€å€‹å ±å‘Šï¼Œç›´æ¥é¡¯ç¤ºå…§å®¹ï¼ˆä¸æ·»åŠ é¡å¤–æ¨™é¡Œï¼Œé¿å…é‡è¤‡ï¼‰
            report_content = reports[report_tabs[0]]
            # å¦‚æœå ±å‘Šå…§å®¹å·²ç¶“åŒ…å«æ¨™é¡Œï¼Œç›´æ¥é¡¯ç¤ºï¼›å¦å‰‡æ·»åŠ æ¨™é¡Œ
            if not report_content.strip().startswith('#'):
                st.markdown(f"### {tab_names[0]}")
                st.markdown("---")
            st.markdown(report_content)
        else:
            # å¤šå€‹å ±å‘Šï¼Œä½¿ç”¨æ¨™ç°½é¡µ
            tabs = st.tabs(tab_names)

            for i, (tab, report_key) in enumerate(zip(tabs, report_tabs)):
                with tab:
                    st.markdown(reports[report_key])

        st.markdown("---")