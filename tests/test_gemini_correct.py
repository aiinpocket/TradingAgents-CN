#!/usr/bin/env python3
"""
ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹åç¨±æ¸¬è©¦Gemini
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è¼‰ç’°å¢ƒè®Šé‡
load_dotenv(project_root / ".env", override=True)

# æ¨è–¦çš„æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰
RECOMMENDED_MODELS = [
    "gemini-2.0-flash",      # æœ€æ–°çš„2.0ç‰ˆæœ¬
    "gemini-1.5-flash",      # ç©©å®šçš„1.5ç‰ˆæœ¬
    "gemini-1.5-pro",        # æ›´å¼·å¤§çš„1.5ç‰ˆæœ¬
    "gemini-2.5-flash",      # 2.5ç‰ˆæœ¬
]

def test_model(model_name):
    """æ¸¬è©¦ç‰¹å®šæ¨¡å‹"""
    try:
        print(f"\nğŸ§ª æ¸¬è©¦æ¨¡å‹: {model_name}")
        print("=" * 60)
        
        import google.generativeai as genai
        from langchain_google_genai import ChatGoogleGenerativeAI
        
        # é…ç½®APIå¯†é‘°
        google_api_key = os.getenv('GOOGLE_API_KEY')
        genai.configure(api_key=google_api_key)
        
        # æ¸¬è©¦1: ç›´æ¥API
        print("ğŸ“ æ¸¬è©¦ç›´æ¥API...")
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content("è«‹ç”¨ä¸­æ–‡ç°¡å–®ä»‹ç´¹ä¸€ä¸‹è˜‹æœå…¬å¸çš„ä¸»è¦æ¥­å‹™")
            
            if response and response.text:
                print("âœ… ç›´æ¥APIèª¿ç”¨æˆåŠŸ")
                print(f"   éŸ¿æ‡‰é•·åº¦: {len(response.text)} å­—ç¬¦")
                print(f"   éŸ¿æ‡‰é è¦½: {response.text[:150]}...")
                direct_success = True
            else:
                print("âŒ ç›´æ¥APIèª¿ç”¨å¤±æ•—ï¼šç„¡éŸ¿æ‡‰å…§å®¹")
                direct_success = False
        except Exception as e:
            print(f"âŒ ç›´æ¥APIèª¿ç”¨å¤±æ•—: {e}")
            direct_success = False
        
        # æ¸¬è©¦2: LangChainé›†æˆ
        print("\nğŸ“ æ¸¬è©¦LangChainé›†æˆ...")
        try:
            llm = ChatGoogleGenerativeAI(
                model=model_name,
                temperature=0.1,
                max_tokens=500,
                google_api_key=google_api_key
            )
            
            response = llm.invoke("è«‹ç”¨ä¸­æ–‡åˆ†æè˜‹æœå…¬å¸çš„æŠ•è³‡åƒ¹å€¼ï¼ŒåŒ…æ‹¬å„ªå‹¢å’Œé¢¨éšª")
            
            if response and response.content:
                print("âœ… LangChainèª¿ç”¨æˆåŠŸ")
                print(f"   éŸ¿æ‡‰é•·åº¦: {len(response.content)} å­—ç¬¦")
                print(f"   éŸ¿æ‡‰é è¦½: {response.content[:150]}...")
                langchain_success = True
            else:
                print("âŒ LangChainèª¿ç”¨å¤±æ•—ï¼šç„¡éŸ¿æ‡‰å…§å®¹")
                langchain_success = False
        except Exception as e:
            print(f"âŒ LangChainèª¿ç”¨å¤±æ•—: {e}")
            langchain_success = False
        
        return direct_success, langchain_success
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
        return False, False

def test_tradingagents_with_gemini(model_name):
    """æ¸¬è©¦TradingAgentsä¸­ä½¿ç”¨Gemini"""
    try:
        print(f"\nğŸ§ª æ¸¬è©¦TradingAgentsä¸­ä½¿ç”¨ {model_name}")
        print("=" * 60)
        
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        from tradingagents.default_config import DEFAULT_CONFIG
        
        # å‰µå»ºä½¿ç”¨Geminiçš„é…ç½®
        config = DEFAULT_CONFIG.copy()
        config["llm_provider"] = "google"
        config["deep_think_llm"] = model_name
        config["quick_think_llm"] = model_name
        config["online_tools"] = True
        config["memory_enabled"] = True
        
        # ä¿®è¤‡è·¯å¾‘
        config["data_dir"] = str(project_root / "data")
        config["results_dir"] = str(project_root / "results")
        config["data_cache_dir"] = str(project_root / "tradingagents" / "dataflows" / "data_cache")
        
        # å‰µå»ºç›®éŒ„
        os.makedirs(config["data_dir"], exist_ok=True)
        os.makedirs(config["results_dir"], exist_ok=True)
        os.makedirs(config["data_cache_dir"], exist_ok=True)
        
        print("âœ… é…ç½®å‰µå»ºæˆåŠŸ")
        print(f"   æ¨¡å‹: {model_name}")
        
        # å‰µå»ºTradingAgentsGraphå¯¦ä¾‹
        print("ğŸš€ åˆå§‹åŒ–TradingAgentsåœ–...")
        graph = TradingAgentsGraph(["market"], config=config, debug=False)
        
        print("âœ… TradingAgentsåœ–åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦ç°¡å–®åˆ†æ
        print("ğŸ“Š æ¸¬è©¦è‚¡ç¥¨åˆ†æ...")
        try:
            state, decision = graph.propagate("AAPL", "2025-06-27")
            
            if state and decision:
                print("âœ… Geminié©…å‹•çš„è‚¡ç¥¨åˆ†ææˆåŠŸ")
                print(f"   æ±ºç­–çµæœ: {decision}")
                
                # æª¢æŸ¥å¸‚å ´å ±å‘Š
                if "market_report" in state and state["market_report"]:
                    market_report = state["market_report"]
                    print(f"   å¸‚å ´å ±å‘Šé•·åº¦: {len(market_report)} å­—ç¬¦")
                    print(f"   å ±å‘Šé è¦½: {market_report[:150]}...")
                
                return True
            else:
                print("âŒ åˆ†æå®Œæˆä½†çµæœç‚ºç©º")
                return False
                
        except Exception as e:
            print(f"âŒ è‚¡ç¥¨åˆ†æå¤±æ•—: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ TradingAgentsé›†æˆæ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ§ª Geminiæ¨¡å‹å®Œæ•´æ¸¬è©¦")
    print("=" * 70)
    
    # æª¢æŸ¥APIå¯†é‘°
    google_api_key = os.getenv('GOOGLE_API_KEY')
    if not google_api_key:
        print("âŒ Google APIå¯†é‘°æœªé…ç½®")
        return
    
    print(f"âœ… Google APIå¯†é‘°å·²é…ç½®: {google_api_key[:20]}...")
    
    # æ¸¬è©¦æ¨è–¦çš„æ¨¡å‹
    best_model = None
    best_score = 0
    
    for model_name in RECOMMENDED_MODELS:
        print(f"\n{'='*70}")
        print(f"ğŸ¯ æ¸¬è©¦æ¨¡å‹: {model_name}")
        
        direct_success, langchain_success = test_model(model_name)
        
        # è¨ˆç®—å¾—åˆ†
        score = int(direct_success) + int(langchain_success)
        
        print(f"\nğŸ“Š {model_name} æ¸¬è©¦çµæœ:")
        print(f"   ç›´æ¥API: {'âœ… é€šé' if direct_success else 'âŒ å¤±æ•—'}")
        print(f"   LangChain: {'âœ… é€šé' if langchain_success else 'âŒ å¤±æ•—'}")
        print(f"   å¾—åˆ†: {score}/2")
        
        if score > best_score:
            best_score = score
            best_model = model_name
        
        # å¦‚æœæ‰¾åˆ°å®Œå…¨å¯ç”¨çš„æ¨¡å‹ï¼Œå°±ä½¿ç”¨å®ƒ
        if score == 2:
            print(f"\nğŸ‰ æ‰¾åˆ°å®Œå…¨å¯ç”¨çš„æ¨¡å‹: {model_name}")
            break
    
    # ä½¿ç”¨æœ€ä½³æ¨¡å‹æ¸¬è©¦TradingAgents
    if best_model and best_score > 0:
        print(f"\n{'='*70}")
        print(f"ğŸ† ä½¿ç”¨æœ€ä½³æ¨¡å‹æ¸¬è©¦TradingAgents: {best_model}")
        
        tradingagents_success = test_tradingagents_with_gemini(best_model)
        
        # æœ€çµ‚ç¸½çµ
        print(f"\nğŸ“Š æœ€çµ‚æ¸¬è©¦çµæœç¸½çµ:")
        print("=" * 50)
        print(f"  æœ€ä½³æ¨¡å‹: {best_model}")
        print(f"  åŸºç¤åŠŸèƒ½å¾—åˆ†: {best_score}/2")
        print(f"  TradingAgentsé›†æˆ: {'âœ… é€šé' if tradingagents_success else 'âŒ å¤±æ•—'}")
        
        if best_score == 2 and tradingagents_success:
            print(f"\nğŸ‰ Geminiæ¨¡å‹ {best_model} å®Œå…¨å¯ç”¨ï¼")
            print(f"\nğŸ’¡ ä½¿ç”¨å»ºè­°:")
            print(f"   1. åœ¨Webç•Œé¢é…ç½®ä¸­é¸æ“‡Googleä½œç‚ºLLMæä¾›å•†")
            print(f"   2. ä½¿ç”¨æ¨¡å‹åç¨±: {best_model}")
            print(f"   3. å¯ä»¥é€²è¡Œå®Œæ•´çš„è‚¡ç¥¨åˆ†æ")
            print(f"   4. æ”¯æŒä¸­æ–‡è¼¸å…¥å’Œè¼¸å‡º")
        else:
            print(f"\nâš ï¸ æ¨¡å‹éƒ¨åˆ†å¯ç”¨ï¼Œå»ºè­°æª¢æŸ¥ç¶²çµ¡é€£æ¥å’ŒAPIé…é¡")
    else:
        print(f"\nâŒ æ‰€æœ‰æ¨è–¦æ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥APIå¯†é‘°å’Œç¶²çµ¡é€£æ¥")

if __name__ == "__main__":
    main()
