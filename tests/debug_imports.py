#!/usr/bin/env python3
"""
èª¿è©¦å°å…¥å•é¡Œ
"""

import sys
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_google_news_import():
    """æ¸¬è©¦Google Newså·¥å…·å°å…¥"""
    print("ğŸ§ª æ¸¬è©¦Google Newså·¥å…·å°å…¥")
    print("=" * 50)
    
    try:
        # å˜—è©¦ä¸åŒçš„å°å…¥æ–¹å¼
        print("1. å˜—è©¦å°å…¥googlenews_utilsæ¨¡å¡Š...")
        from tradingagents.dataflows import googlenews_utils
        print("âœ… googlenews_utilsæ¨¡å¡Šå°å…¥æˆåŠŸ")
        
        # æª¢æŸ¥æ¨¡å¡Šä¸­çš„å‡½æ•¸
        print("2. æª¢æŸ¥æ¨¡å¡Šä¸­çš„å‡½æ•¸...")
        functions = [attr for attr in dir(googlenews_utils) if not attr.startswith('_')]
        print(f"   å¯ç”¨å‡½æ•¸: {functions}")
        
        # å˜—è©¦å°å…¥ç‰¹å®šå‡½æ•¸
        print("3. å˜—è©¦å°å…¥ç‰¹å®šå‡½æ•¸...")
        if hasattr(googlenews_utils, 'get_google_news'):
            print("âœ… get_google_newså‡½æ•¸å­˜åœ¨")
        else:
            print("âŒ get_google_newså‡½æ•¸ä¸å­˜åœ¨")
            
        if hasattr(googlenews_utils, 'getNewsData'):
            print("âœ… getNewsDataå‡½æ•¸å­˜åœ¨")
        else:
            print("âŒ getNewsDataå‡½æ•¸ä¸å­˜åœ¨")
            
        return True
        
    except ImportError as e:
        print(f"âŒ å°å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–éŒ¯èª¤: {e}")
        return False

def test_reddit_import():
    """æ¸¬è©¦Redditå·¥å…·å°å…¥"""
    print("\nğŸ§ª æ¸¬è©¦Redditå·¥å…·å°å…¥")
    print("=" * 50)
    
    try:
        # å˜—è©¦ä¸åŒçš„å°å…¥æ–¹å¼
        print("1. å˜—è©¦å°å…¥reddit_utilsæ¨¡å¡Š...")
        from tradingagents.dataflows import reddit_utils
        print("âœ… reddit_utilsæ¨¡å¡Šå°å…¥æˆåŠŸ")
        
        # æª¢æŸ¥æ¨¡å¡Šä¸­çš„å‡½æ•¸
        print("2. æª¢æŸ¥æ¨¡å¡Šä¸­çš„å‡½æ•¸...")
        functions = [attr for attr in dir(reddit_utils) if not attr.startswith('_')]
        print(f"   å¯ç”¨å‡½æ•¸: {functions}")
        
        # å˜—è©¦å°å…¥ç‰¹å®šå‡½æ•¸
        print("3. å˜—è©¦å°å…¥ç‰¹å®šå‡½æ•¸...")
        if hasattr(reddit_utils, 'get_reddit_sentiment'):
            print("âœ… get_reddit_sentimentå‡½æ•¸å­˜åœ¨")
        else:
            print("âŒ get_reddit_sentimentå‡½æ•¸ä¸å­˜åœ¨")
            
        # æª¢æŸ¥å…¶ä»–å¯èƒ½çš„å‡½æ•¸å
        possible_functions = ['get_reddit_data', 'fetch_reddit_posts', 'analyze_reddit_sentiment']
        for func_name in possible_functions:
            if hasattr(reddit_utils, func_name):
                print(f"âœ… {func_name}å‡½æ•¸å­˜åœ¨")
            
        return True
        
    except ImportError as e:
        print(f"âŒ å°å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–éŒ¯èª¤: {e}")
        return False

def check_dependencies():
    """æª¢æŸ¥ä¾è³´åº«"""
    print("\nğŸ§ª æª¢æŸ¥ä¾è³´åº«")
    print("=" * 50)
    
    dependencies = {
        'requests': 'HTTPè«‹æ±‚åº«',
        'beautifulsoup4': 'HTMLè§£æåº«',
        'praw': 'Reddit APIåº«',
        'tenacity': 'é‡è©¦æ©Ÿåˆ¶åº«'
    }
    
    for package, description in dependencies.items():
        try:
            if package == 'beautifulsoup4':
                import bs4
                print(f"âœ… {description}: å·²å®‰è£")
            else:
                __import__(package)
                print(f"âœ… {description}: å·²å®‰è£")
        except ImportError:
            print(f"âŒ {description}: æœªå®‰è£ (pip install {package})")

def check_actual_file_contents():
    """æª¢æŸ¥å¯¦é™…æ–‡ä»¶å…§å®¹"""
    print("\nğŸ§ª æª¢æŸ¥å¯¦é™…æ–‡ä»¶å…§å®¹")
    print("=" * 50)
    
    # æª¢æŸ¥Google Newsæ–‡ä»¶
    try:
        google_file = Path("tradingagents/dataflows/googlenews_utils.py")
        if google_file.exists():
            print(f"âœ… Google Newsæ–‡ä»¶å­˜åœ¨: {google_file}")
            with open(google_file, 'r', encoding='utf-8') as f:
                content = f.read()
                if 'def ' in content:
                    # æå–å‡½æ•¸å®šç¾©
                    import re
                    functions = re.findall(r'def (\w+)\(', content)
                    print(f"   æ–‡ä»¶ä¸­çš„å‡½æ•¸: {functions}")
                else:
                    print("   æ–‡ä»¶ä¸­æ²¡æœ‰å‡½æ•¸å®šç¾©")
        else:
            print(f"âŒ Google Newsæ–‡ä»¶ä¸å­˜åœ¨: {google_file}")
    except Exception as e:
        print(f"âŒ æª¢æŸ¥Google Newsæ–‡ä»¶å¤±è´¥: {e}")
    
    # æª¢æŸ¥Redditæ–‡ä»¶
    try:
        reddit_file = Path("tradingagents/dataflows/reddit_utils.py")
        if reddit_file.exists():
            print(f"âœ… Redditæ–‡ä»¶å­˜åœ¨: {reddit_file}")
            with open(reddit_file, 'r', encoding='utf-8') as f:
                content = f.read()
                if 'def ' in content:
                    # æå–å‡½æ•¸å®šç¾©
                    import re
                    functions = re.findall(r'def (\w+)\(', content)
                    print(f"   æ–‡ä»¶ä¸­çš„å‡½æ•¸: {functions}")
                else:
                    print("   æ–‡ä»¶ä¸­æ²¡æœ‰å‡½æ•¸å®šç¾©")
        else:
            print(f"âŒ Redditæ–‡ä»¶ä¸å­˜åœ¨: {reddit_file}")
    except Exception as e:
        print(f"âŒ æª¢æŸ¥Redditæ–‡ä»¶å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” è¨ºæ–·å·¥å…·å°å…¥å•é¡Œ")
    print("=" * 60)
    
    # æª¢æŸ¥ä¾è³´åº«
    check_dependencies()
    
    # æª¢æŸ¥æ–‡ä»¶å…§å®¹
    check_actual_file_contents()
    
    # æ¸¬è©¦å°å…¥
    google_success = test_google_news_import()
    reddit_success = test_reddit_import()
    
    print(f"\nğŸ“Š è¨ºæ–·çµæœ:")
    print(f"  Google Newså·¥å…·: {'âœ… å¯ç”¨' if google_success else 'âŒ ä¸å¯ç”¨'}")
    print(f"  Redditå·¥å…·: {'âœ… å¯ç”¨' if reddit_success else 'âŒ ä¸å¯ç”¨'}")

if __name__ == "__main__":
    main()
