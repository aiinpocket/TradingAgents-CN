#!/usr/bin/env python3
"""
æ¸¬è©¦Gemini 2.5 Flashå’ŒProæ¨¡å‹
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è¼‰ç’°å¢ƒè®Šé‡
load_dotenv(project_root / ".env", override=True)

# Gemini 2.5æ¨¡å‹åˆ—è¡¨
GEMINI_25_MODELS = [
    "gemini-2.5-flash",
    "gemini-2.5-pro", 
    "gemini-2.5-flash-002",
    "gemini-2.5-pro-002"
]

def test_gemini_25_availability():
    """æ¸¬è©¦Gemini 2.5æ¨¡å‹çš„å¯ç”¨æ€§"""
    print("ğŸ§ª æ¸¬è©¦Gemini 2.5æ¨¡å‹å¯ç”¨æ€§")
    print("=" * 60)
    
    try:
        import google.generativeai as genai
        
        # é…ç½®APIå¯†é‘°
        google_api_key = os.getenv('GOOGLE_API_KEY')
        if not google_api_key:
            print("âŒ Google APIå¯†é‘°æœªé…ç½®")
            return []
        
        genai.configure(api_key=google_api_key)
        
        # ç²å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
        print("ğŸ“‹ ç²å–æ‰€æœ‰å¯ç”¨æ¨¡å‹...")
        all_models = genai.list_models()
        
        available_25_models = []
        
        print("ğŸ” æª¢æŸ¥Gemini 2.5æ¨¡å‹:")
        for model_name in GEMINI_25_MODELS:
            found = False
            for model in all_models:
                if model_name in model.name:
                    print(f"âœ… {model_name}: å¯ç”¨")
                    print(f"   å®Œæ•´åç¨±: {model.name}")
                    print(f"   é¡¯ç¤ºåç¨±: {model.display_name}")
                    print(f"   æ”¯æŒæ–¹æ³•: {model.supported_generation_methods}")
                    available_25_models.append(model.name)
                    found = True
                    break
            
            if not found:
                print(f"âŒ {model_name}: ä¸å¯ç”¨")
        
        return available_25_models
        
    except Exception as e:
        print(f"âŒ æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§å¤±æ•—: {e}")
        return []

def test_specific_gemini_25_model(model_name):
    """æ¸¬è©¦ç‰¹å®šçš„Gemini 2.5æ¨¡å‹"""
    try:
        print(f"\nğŸ§ª æ¸¬è©¦æ¨¡å‹: {model_name}")
        print("=" * 60)
        
        import google.generativeai as genai
        from langchain_google_genai import ChatGoogleGenerativeAI
        
        # é…ç½®APIå¯†é‘°
        google_api_key = os.getenv('GOOGLE_API_KEY')
        genai.configure(api_key=google_api_key)
        
        # æ¸¬è©¦1: ç›´æ¥API
        print("ğŸ“ æ¸¬è©¦ç›´æ¥API...")
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(
                "è«‹ç”¨ä¸­æ–‡åˆ†æè˜‹æœå…¬å¸(AAPL)çš„æŠ•è³‡åƒ¹å€¼ï¼ŒåŒ…æ‹¬æŠ€è¡“å‰µæ–°ã€å¸‚å ´åœ°ä½å’Œè²¡å‹™ç‹€æ³"
            )
            
            if response and response.text:
                print("âœ… ç›´æ¥APIèª¿ç”¨æˆåŠŸ")
                print(f"   éŸ¿æ‡‰é•·åº¦: {len(response.text)} å­—ç¬¦")
                print(f"   éŸ¿æ‡‰é è¦½: {response.text[:200]}...")
                direct_success = True
            else:
                print("âŒ ç›´æ¥APIèª¿ç”¨å¤±æ•—ï¼šç„¡éŸ¿æ‡‰å…§å®¹")
                direct_success = False
        except Exception as e:
            print(f"âŒ ç›´æ¥APIèª¿ç”¨å¤±æ•—: {e}")
            direct_success = False
        
        # æ¸¬è©¦2: LangChainé›†æˆ
        print("\nğŸ“ æ¸¬è©¦LangChainé›†æˆ...")
        try:
            llm = ChatGoogleGenerativeAI(
                model=model_name,
                temperature=0.1,
                max_tokens=1000,
                google_api_key=google_api_key
            )
            
            response = llm.invoke(
                "è«‹ç”¨ä¸­æ–‡åˆ†æç•¶å‰äººå·¥æ™ºèƒ½è¡Œæ¥­çš„æŠ•è³‡æ©Ÿæœƒï¼Œé‡é»é—œè¨»å¤§å‹ç§‘æŠ€å…¬å¸çš„AIæˆ°ç•¥"
            )
            
            if response and response.content:
                print("âœ… LangChainèª¿ç”¨æˆåŠŸ")
                print(f"   éŸ¿æ‡‰é•·åº¦: {len(response.content)} å­—ç¬¦")
                print(f"   éŸ¿æ‡‰é è¦½: {response.content[:200]}...")
                langchain_success = True
            else:
                print("âŒ LangChainèª¿ç”¨å¤±æ•—ï¼šç„¡éŸ¿æ‡‰å…§å®¹")
                langchain_success = False
        except Exception as e:
            print(f"âŒ LangChainèª¿ç”¨å¤±æ•—: {e}")
            langchain_success = False
        
        # æ¸¬è©¦3: è¤‡é›œæ¨ç†èƒ½åŠ›
        print("\nğŸ“ æ¸¬è©¦è¤‡é›œæ¨ç†èƒ½åŠ›...")
        try:
            complex_prompt = """
            è«‹ç”¨ä¸­æ–‡é€²è¡Œè¤‡é›œçš„è‚¡ç¥¨åˆ†ææ¨ç†ï¼š
            
            å‡è¨­å ´æ™¯ï¼š
            - ç•¶å‰æ™‚é–“ï¼š2025å¹´6æœˆ
            - ç¾è¯å„²å‰›å‰›é™æ¯0.25%
            - ä¸­ç¾è²¿æ˜“é—œç³»æœ‰æ‰€ç·©è§£
            - AIæŠ€è¡“å¿«é€Ÿç™¼å±•
            - é€šè„¹ç‡é™è‡³2.5%
            
            è«‹åˆ†æåœ¨é€™ç¨®å®è§€ç’°å¢ƒä¸‹ï¼Œè˜‹æœå…¬å¸(AAPL)çš„æŠ•è³‡åƒ¹å€¼ï¼ŒåŒ…æ‹¬ï¼š
            1. å®è§€ç¶“æ¿Ÿå› ç´ çš„å½±éŸ¿
            2. è¡Œæ¥­ç«¶çˆ­æ…‹å‹¢
            3. å…¬å¸ç‰¹æœ‰å„ªå‹¢
            4. é¢¨éšªå› ç´ 
            5. æŠ•è³‡å»ºè­°å’Œç›®æ¨™åƒ¹ä½
            
            è«‹æä¾›è©³ç´°çš„é‚è¼¯æ¨ç†éç¨‹ã€‚
            """
            
            response = llm.invoke(complex_prompt)
            
            if response and response.content and len(response.content) > 500:
                print("âœ… è¤‡é›œæ¨ç†æ¸¬è©¦æˆåŠŸ")
                print(f"   éŸ¿æ‡‰é•·åº¦: {len(response.content)} å­—ç¬¦")
                print(f"   éŸ¿æ‡‰é è¦½: {response.content[:300]}...")
                complex_success = True
            else:
                print("âŒ è¤‡é›œæ¨ç†æ¸¬è©¦å¤±æ•—ï¼šéŸ¿æ‡‰éçŸ­æˆ–ç„¡å…§å®¹")
                complex_success = False
        except Exception as e:
            print(f"âŒ è¤‡é›œæ¨ç†æ¸¬è©¦å¤±æ•—: {e}")
            complex_success = False
        
        return direct_success, langchain_success, complex_success
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
        return False, False, False

def test_gemini_25_in_tradingagents(model_name):
    """æ¸¬è©¦Gemini 2.5åœ¨TradingAgentsä¸­çš„ä½¿ç”¨"""
    try:
        print(f"\nğŸ§ª æ¸¬è©¦{model_name}åœ¨TradingAgentsä¸­çš„ä½¿ç”¨")
        print("=" * 60)
        
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        from tradingagents.default_config import DEFAULT_CONFIG
        
        # å‰µå»ºé…ç½®
        config = DEFAULT_CONFIG.copy()
        config["llm_provider"] = "google"
        config["deep_think_llm"] = model_name
        config["quick_think_llm"] = model_name
        config["online_tools"] = False  # é¿å…APIé™åˆ¶
        config["memory_enabled"] = True  # å•Ÿç”¨å…§å­˜åŠŸèƒ½
        config["max_debate_rounds"] = 1
        config["max_risk_discuss_rounds"] = 1
        
        # ä¿®è¤‡è·¯å¾‘
        config["data_dir"] = str(project_root / "data")
        config["results_dir"] = str(project_root / "results")
        config["data_cache_dir"] = str(project_root / "tradingagents" / "dataflows" / "data_cache")
        
        # å‰µå»ºç›®éŒ„
        os.makedirs(config["data_dir"], exist_ok=True)
        os.makedirs(config["results_dir"], exist_ok=True)
        os.makedirs(config["data_cache_dir"], exist_ok=True)
        
        print("âœ… é…ç½®å‰µå»ºæˆåŠŸ")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   å…§å­˜åŠŸèƒ½: {config['memory_enabled']}")
        
        # å‰µå»ºTradingAgentsGraphå¯¦ä¾‹
        print("ğŸš€ åˆå§‹åŒ–TradingAgentsåœ–...")
        graph = TradingAgentsGraph(["market"], config=config, debug=False)
        
        print("âœ… TradingAgentsåœ–åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦åˆ†æ
        print("ğŸ“Š é–‹å§‹è‚¡ç¥¨åˆ†æ...")
        
        try:
            state, decision = graph.propagate("AAPL", "2025-06-27")
            
            if state and decision:
                print(f"âœ… {model_name}é©…å‹•çš„è‚¡ç¥¨åˆ†ææˆåŠŸï¼")
                print(f"   æœ€çµ‚æ±ºç­–: {decision}")
                
                # æª¢æŸ¥å¸‚å ´å ±å‘Š
                if "market_report" in state and state["market_report"]:
                    market_report = state["market_report"]
                    print(f"   å¸‚å ´å ±å‘Šé•·åº¦: {len(market_report)} å­—ç¬¦")
                    print(f"   å ±å‘Šé è¦½: {market_report[:200]}...")
                
                return True
            else:
                print("âŒ åˆ†æå®Œæˆä½†çµæœç‚ºç©º")
                return False
                
        except Exception as e:
            print(f"âŒ è‚¡ç¥¨åˆ†æå¤±æ•—: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ TradingAgentsæ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª Gemini 2.5æ¨¡å‹æ¸¬è©¦")
    print("=" * 70)
    
    # æª¢æŸ¥APIå¯†é‘°
    google_api_key = os.getenv('GOOGLE_API_KEY')
    if not google_api_key:
        print("âŒ Google APIå¯†é‘°æœªé…ç½®")
        return
    
    print(f"âœ… Google APIå¯†é‘°å·²é…ç½®: {google_api_key[:20]}...")
    
    # æª¢æŸ¥å¯ç”¨çš„Gemini 2.5æ¨¡å‹
    available_models = test_gemini_25_availability()
    
    if not available_models:
        print("\nâŒ æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„Gemini 2.5æ¨¡å‹")
        return
    
    print(f"\nğŸ¯ æ‰¾åˆ° {len(available_models)} å€‹å¯ç”¨çš„Gemini 2.5æ¨¡å‹")
    
    # æ¸¬è©¦æ¯å€‹å¯ç”¨æ¨¡å‹
    best_model = None
    best_score = 0
    
    for model_name in available_models:
        print(f"\n{'='*70}")
        
        # åŸºç¤åŠŸèƒ½æ¸¬è©¦
        direct, langchain, complex = test_specific_gemini_25_model(model_name)
        score = sum([direct, langchain, complex])
        
        print(f"\nğŸ“Š {model_name} åŸºç¤æ¸¬è©¦çµæœ:")
        print(f"   ç›´æ¥API: {'âœ…' if direct else 'âŒ'}")
        print(f"   LangChain: {'âœ…' if langchain else 'âŒ'}")
        print(f"   è¤‡é›œæ¨ç†: {'âœ…' if complex else 'âŒ'}")
        print(f"   å¾—åˆ†: {score}/3")
        
        if score > best_score:
            best_score = score
            best_model = model_name
        
        # å¦‚æœåŸºç¤åŠŸèƒ½å…¨éƒ¨é€šéï¼Œæ¸¬è©¦TradingAgentsé›†æˆ
        if score == 3:
            tradingagents_success = test_gemini_25_in_tradingagents(model_name)
            if tradingagents_success:
                print(f"   TradingAgents: âœ…")
                total_score = score + 1
            else:
                print(f"   TradingAgents: âŒ")
                total_score = score
            
            print(f"   ç¸½å¾—åˆ†: {total_score}/4")
    
    # æœ€çµ‚æ¨è–¦
    print(f"\nğŸ“Š æœ€çµ‚æ¸¬è©¦çµæœ:")
    print("=" * 50)
    print(f"  æœ€ä½³æ¨¡å‹: {best_model}")
    print(f"  æœ€é«˜å¾—åˆ†: {best_score}/3")
    
    if best_score >= 2:
        print(f"\nğŸ‰ æ¨è–¦ä½¿ç”¨: {best_model}")
        print(f"\nğŸ’¡ é…ç½®å»ºè­°:")
        print(f"   1. åœ¨Webç•Œé¢ä¸­é¸æ“‡'Google'ä½œç‚ºLLMæä¾›å•†")
        print(f"   2. ä½¿ç”¨æ¨¡å‹åç¨±: {best_model}")
        print(f"   3. Gemini 2.5å…·æœ‰æ›´å¼·çš„æ¨ç†å’Œåˆ†æèƒ½åŠ›")
        print(f"   4. æ”¯æŒæ›´è¤‡é›œçš„é‡‘èåˆ†æä»»å‹™")
    else:
        print(f"\nâš ï¸ æ‰€æœ‰Gemini 2.5æ¨¡å‹æ¸¬è©¦ä¸ç†æƒ³")
        print(f"   å»ºè­°æª¢æŸ¥APIå¯†é‘°æ¬Šé™å’Œç¶²çµ¡é€£æ¥")

if __name__ == "__main__":
    main()
