#!/usr/bin/env python3
"""
æ¸…ç†ä¸å¿…è¦çš„ç›®éŒ„å’Œæ–‡ä»¶
ç§»é™¤è‡ªå‹•ç”Ÿæˆçš„æ–‡ä»¶å’Œè‡¨æ™‚è¼¸å‡º
"""

import os
import shutil
from pathlib import Path

# å°å…¥æ—¥èªŒæ¨¡å¡Š
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('default')


def cleanup_directories():
    """æ¸…ç†ä¸å¿…è¦çš„ç›®éŒ„"""
    logger.info(f"ğŸ§¹ æ¸…ç†ä¸å¿…è¦çš„ç›®éŒ„å’Œæ–‡ä»¶")
    logger.info(f"=")
    
    # é …ç›®æ ¹ç›®éŒ„
    project_root = Path(".")
    
    # éœ€è¦æ¸…ç†çš„ç›®éŒ„
    cleanup_dirs = [
        "tradingagents.egg-info",
        "enhanced_analysis_reports",
        "__pycache__",
        ".pytest_cache",
    ]
    
    # éœ€è¦æ¸…ç†çš„æ–‡ä»¶æ¨¡å¼
    cleanup_patterns = [
        "*.pyc",
        "*.pyo", 
        "*.pyd",
        ".DS_Store",
        "Thumbs.db"
    ]
    
    cleaned_count = 0
    
    # æ¸…ç†ç›®éŒ„
    for dir_name in cleanup_dirs:
        dir_path = project_root / dir_name
        if dir_path.exists():
            try:
                shutil.rmtree(dir_path)
                logger.info(f"âœ… åˆªé™¤ç›®éŒ„: {dir_name}")
                cleaned_count += 1
            except Exception as e:
                logger.error(f"âŒ åˆªé™¤å¤±æ•— {dir_name}: {e}")
    
    # éæ­¸æ¸…ç†æ–‡ä»¶
    for pattern in cleanup_patterns:
        for file_path in project_root.rglob(pattern):
            try:
                file_path.unlink()
                logger.info(f"âœ… åˆªé™¤æ–‡ä»¶: {file_path}")
                cleaned_count += 1
            except Exception as e:
                logger.error(f"âŒ åˆªé™¤å¤±æ•— {file_path}: {e}")
    
    return cleaned_count

def update_gitignore():
    """æ›´æ–°.gitignoreæ–‡ä»¶"""
    logger.info(f"\nğŸ“ æ›´æ–°.gitignoreæ–‡ä»¶")
    logger.info(f"=")
    
    gitignore_path = Path(".gitignore")
    
    # éœ€è¦æ·»åŠ çš„å¿½ç•¥è¦å‰‡
    ignore_rules = [
        "# PythonåŒ…å…ƒæ•¸æ“š",
        "*.egg-info/",
        "tradingagents.egg-info/",
        "",
        "# è‡¨æ™‚è¼¸å‡ºæ–‡ä»¶", 
        "enhanced_analysis_reports/",
        "analysis_reports/",
        "",
        "# Pythonç·©å­˜",
        "__pycache__/",
        "*.py[cod]",
        "*$py.class",
        ".pytest_cache/",
        "",
        "# ç³»çµ±æ–‡ä»¶",
        ".DS_Store",
        "Thumbs.db",
        "",
        "# IDEæ–‡ä»¶",
        ".vscode/settings.json",
        ".idea/",
        "",
        "# æ—¥èªŒæ–‡ä»¶",
        "*.log",
        "logs/",
    ]
    
    try:
        # è®€å–ç¾æœ‰å…§å®¹
        existing_content = ""
        if gitignore_path.exists():
            with open(gitignore_path, 'r', encoding='utf-8') as f:
                existing_content = f.read()
        
        # æª¢æŸ¥å“ªäº›è¦å‰‡éœ€è¦æ·»åŠ 
        new_rules = []
        for rule in ignore_rules:
            if rule.strip() and rule not in existing_content:
                new_rules.append(rule)
        
        if new_rules:
            # æ·»åŠ æ–°è¦å‰‡
            with open(gitignore_path, 'a', encoding='utf-8') as f:
                f.write("\n# è‡ªå‹•æ¸…ç†è…³æœ¬æ·»åŠ çš„è¦å‰‡\n")
                for rule in new_rules:
                    f.write(f"{rule}\n")
            
            logger.info(f"âœ… æ·»åŠ äº† {len(new_rules)} æ¢æ–°çš„å¿½ç•¥è¦å‰‡")
        else:
            logger.info(f"âœ… .gitignoreå·²ç¶“æ˜¯æœ€æ–°çš„")
            
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°.gitignoreå¤±æ•—: {e}")

def analyze_upstream_contribution():
    """åˆ†æupstream_contributionç›®éŒ„"""
    logger.debug(f"\nğŸ” åˆ†æupstream_contributionç›®éŒ„")
    logger.info(f"=")
    
    upstream_dir = Path("upstream_contribution")
    
    if not upstream_dir.exists():
        logger.info(f"âœ… upstream_contributionç›®éŒ„ä¸å­˜åœ¨")
        return
    
    # çµ±è¨ˆå…§å®¹
    batch_dirs = list(upstream_dir.glob("batch*"))
    json_files = list(upstream_dir.glob("*.json"))
    
    logger.info(f"ğŸ“Š ç™¼ç¾å…§å®¹:")
    logger.info(f"   - Batchç›®éŒ„: {len(batch_dirs)}å€‹")
    logger.info(f"   - JSONæ–‡ä»¶: {len(json_files)}å€‹")
    
    for batch_dir in batch_dirs:
        logger.info(f"   - {batch_dir.name}: {len(list(batch_dir.rglob('*')))}å€‹æ–‡ä»¶")
    
    # è©¢å•æ˜¯å¦åˆªé™¤
    logger.info(f"\nğŸ’¡ upstream_contributionç›®éŒ„ç”¨é€”:")
    logger.info(f"   - æº–å‚™å‘ä¸Šæ¸¸é …ç›®(TauricResearch/TradingAgents)è²¢ç»ä»£ç¢¼")
    logger.info(f"   - åŒ…å«ç§»é™¤ä¸­æ–‡å…§å®¹çš„ç‰ˆæœ¬")
    logger.info(f"   - å¦‚æœä¸è¨ˆåŠƒå‘ä¸Šæ¸¸è²¢ç»ï¼Œå¯ä»¥åˆªé™¤")
    
    return len(batch_dirs) + len(json_files)

def main():
    """ä¸»å‡½æ•¸"""
    logger.info(f"ğŸ§¹ TradingAgents ç›®éŒ„æ¸…ç†å·¥å…·")
    logger.info(f"=")
    logger.info(f"ğŸ’¡ ç›®æ¨™: æ¸…ç†è‡ªå‹•ç”Ÿæˆçš„æ–‡ä»¶å’Œä¸å¿…è¦çš„ç›®éŒ„")
    logger.info(f"=")
    
    # æ¸…ç†ç›®éŒ„å’Œæ–‡ä»¶
    cleaned_count = cleanup_directories()
    
    # æ›´æ–°gitignore
    update_gitignore()
    
    # åˆ†æupstream_contribution
    upstream_count = analyze_upstream_contribution()
    
    # ç¸½çµ
    logger.info(f"\nğŸ“Š æ¸…ç†ç¸½çµ")
    logger.info(f"=")
    logger.info(f"âœ… æ¸…ç†äº† {cleaned_count} å€‹æ–‡ä»¶/ç›®éŒ„")
    logger.info(f"ğŸ“ æ›´æ–°äº† .gitignore æ–‡ä»¶")
    
    if upstream_count > 0:
        logger.warning(f"âš ï¸ upstream_contributionç›®éŒ„åŒ…å« {upstream_count} å€‹é …ç›®")
        logger.info(f"   å¦‚æœä¸éœ€è¦å‘ä¸Šæ¸¸è²¢ç»ï¼Œå¯ä»¥æ‰‹å‹•åˆªé™¤:")
        logger.info(f"   rm -rf upstream_contribution/")
    
    logger.info(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼é …ç›®ç›®éŒ„æ›´åŠ æ•´æ½”")
    logger.info(f"\nğŸ’¡ å»ºè­°:")
    logger.info(f"   1. æª¢æŸ¥gitç‹€æ…‹: git status")
    logger.info(f"   2. æäº¤æ¸…ç†æ›´æ”¹: git add . && git commit -m 'æ¸…ç†ä¸å¿…è¦çš„ç›®éŒ„å’Œæ–‡ä»¶'")
    logger.info(f"   3. å¦‚æœä¸éœ€è¦upstream_contributionï¼Œå¯ä»¥æ‰‹å‹•åˆªé™¤")

if __name__ == "__main__":
    main()
