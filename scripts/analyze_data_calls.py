#!/usr/bin/env python3
"""
æ•¸æ“šç²å–èª¿ç”¨åˆ†æå·¥å…·
å°ˆé–€åˆ†ææ•¸æ“šç²å–ç›¸é—œçš„æ—¥èªŒï¼Œæä¾›è©³ç´°çš„èª¿ç”¨çµ±è¨ˆå’Œæ€§èƒ½åˆ†æ
"""

import json
import re
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import defaultdict, Counter
import argparse

# å°å…¥æ—¥èªŒæ¨¡å¡Š
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('scripts')



class DataCallAnalyzer:
    """æ•¸æ“šç²å–èª¿ç”¨åˆ†æå™¨"""
    
    def __init__(self, log_file: Path):
        self.log_file = log_file
        self.data_calls = []
        self.tool_calls = []
        self.data_source_calls = []
        
    def parse_logs(self):
        """è§£ææ—¥èªŒæ–‡ä»¶"""
        if not self.log_file.exists():
            logger.error(f"âŒ æ—¥èªŒæ–‡ä»¶ä¸å­˜åœ¨: {self.log_file}")
            return
            
        logger.info(f"ğŸ“– è§£ææ•¸æ“šç²å–æ—¥èªŒ: {self.log_file}")
        
        with open(self.log_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                    
                # å˜—è©¦è§£æçµæ§‹åŒ–æ—¥èªŒï¼ˆJSONï¼‰
                if line.startswith('{'):
                    try:
                        entry = json.loads(line)
                        self._process_structured_entry(entry, line_num)
                        continue
                    except json.JSONDecodeError:
                        pass
                
                # è§£ææ™®é€šæ—¥èªŒ
                self._process_regular_log(line, line_num)
        
        logger.info(f"âœ… è§£æå®Œæˆ: {len(self.data_calls)} æ¢æ•¸æ“šèª¿ç”¨, {len(self.tool_calls)} æ¢å·¥å…·èª¿ç”¨, {len(self.data_source_calls)} æ¢æ•¸æ“šæºèª¿ç”¨")
    
    def _process_structured_entry(self, entry: Dict[str, Any], line_num: int):
        """è™•ç†çµæ§‹åŒ–æ—¥èªŒæ¢ç›®"""
        event_type = entry.get('event_type', '')
        
        if 'data_fetch' in event_type:
            self.data_calls.append({
                'type': 'structured',
                'line_num': line_num,
                'timestamp': entry.get('timestamp'),
                'event_type': event_type,
                'symbol': entry.get('symbol'),
                'start_date': entry.get('start_date'),
                'end_date': entry.get('end_date'),
                'data_source': entry.get('data_source'),
                'duration': entry.get('duration'),
                'result_length': entry.get('result_length'),
                'result_preview': entry.get('result_preview'),
                'error': entry.get('error'),
                'entry': entry
            })
        
        elif 'tool_call' in event_type:
            self.tool_calls.append({
                'type': 'structured',
                'line_num': line_num,
                'timestamp': entry.get('timestamp'),
                'event_type': event_type,
                'tool_name': entry.get('tool_name'),
                'duration': entry.get('duration'),
                'args_info': entry.get('args_info'),
                'result_info': entry.get('result_info'),
                'error': entry.get('error'),
                'entry': entry
            })
        
        elif 'unified_data_call' in event_type:
            self.data_source_calls.append({
                'type': 'structured',
                'line_num': line_num,
                'timestamp': entry.get('timestamp'),
                'event_type': event_type,
                'function': entry.get('function'),
                'ticker': entry.get('ticker'),
                'start_date': entry.get('start_date'),
                'end_date': entry.get('end_date'),
                'duration': entry.get('duration'),
                'result_length': entry.get('result_length'),
                'result_preview': entry.get('result_preview'),
                'error': entry.get('error'),
                'entry': entry
            })
    
    def _process_regular_log(self, line: str, line_num: int):
        """è™•ç†æ™®é€šæ—¥èªŒè¡Œ"""
        # åŒ¹é…æ•¸æ“šç²å–ç›¸é—œçš„æ—¥èªŒ
        patterns = [
            (r'ğŸ“Š.*\[æ•¸æ“šç²å–\].*symbol=(\w+).*start_date=([^,]+).*end_date=([^,]+)', 'data_fetch'),
            (r'ğŸ”§.*\[å·¥å…·èª¿ç”¨\].*(\w+)', 'tool_call'),
            (r'ğŸ“Š.*\[çµ±ä¸€æ¥å£\].*ç²å–(\w+)è‚¡ç¥¨æ•¸æ“š', 'unified_call'),
            (r'ğŸ“Š.*\[(Tushare|AKShare|BaoStock|TDX)\].*èª¿ç”¨åƒæ•¸.*symbol=(\w+)', 'data_source_call')
        ]
        
        for pattern, call_type in patterns:
            match = re.search(pattern, line)
            if match:
                # æå–æ™‚é–“æˆ³
                timestamp_match = re.match(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3})', line)
                timestamp = timestamp_match.group(1) if timestamp_match else None
                
                if call_type == 'data_fetch':
                    self.data_calls.append({
                        'type': 'regular',
                        'line_num': line_num,
                        'timestamp': timestamp,
                        'symbol': match.group(1),
                        'start_date': match.group(2),
                        'end_date': match.group(3),
                        'raw_line': line
                    })
                elif call_type == 'tool_call':
                    self.tool_calls.append({
                        'type': 'regular',
                        'line_num': line_num,
                        'timestamp': timestamp,
                        'tool_name': match.group(1),
                        'raw_line': line
                    })
                elif call_type == 'data_source_call':
                    self.data_source_calls.append({
                        'type': 'regular',
                        'line_num': line_num,
                        'timestamp': timestamp,
                        'data_source': match.group(1),
                        'symbol': match.group(2),
                        'raw_line': line
                    })
                break
    
    def analyze_data_calls(self) -> Dict[str, Any]:
        """åˆ†ææ•¸æ“šç²å–èª¿ç”¨"""
        logger.info(f"\nğŸ“Š æ•¸æ“šç²å–èª¿ç”¨åˆ†æ")
        logger.info(f"=")
        
        analysis = {
            'total_calls': len(self.data_calls),
            'by_symbol': defaultdict(int),
            'by_data_source': defaultdict(int),
            'by_date_range': defaultdict(int),
            'performance': {
                'total_duration': 0,
                'avg_duration': 0,
                'slow_calls': [],
                'fast_calls': []
            },
            'success_rate': {
                'total': 0,
                'success': 0,
                'warning': 0,
                'error': 0
            }
        }
        
        durations = []
        
        for call in self.data_calls:
            # çµ±è¨ˆè‚¡ç¥¨ä»£ç¢¼
            symbol = call.get('symbol')
            if symbol:
                analysis['by_symbol'][symbol] += 1
            
            # çµ±è¨ˆæ•¸æ“šæº
            data_source = call.get('data_source')
            if data_source:
                analysis['by_data_source'][data_source] += 1
            
            # çµ±è¨ˆæ—¥æœŸç¯„å›´
            start_date = call.get('start_date')
            end_date = call.get('end_date')
            if start_date and end_date:
                date_range = f"{start_date} to {end_date}"
                analysis['by_date_range'][date_range] += 1
            
            # æ€§èƒ½åˆ†æ
            duration = call.get('duration')
            if duration:
                durations.append(duration)
                analysis['performance']['total_duration'] += duration
                
                if duration > 5.0:  # è¶…é5ç§’çš„æ…¢èª¿ç”¨
                    analysis['performance']['slow_calls'].append({
                        'symbol': symbol,
                        'duration': duration,
                        'data_source': data_source,
                        'line_num': call.get('line_num')
                    })
                elif duration < 1.0:  # å°æ–¼1ç§’çš„å¿«èª¿ç”¨
                    analysis['performance']['fast_calls'].append({
                        'symbol': symbol,
                        'duration': duration,
                        'data_source': data_source,
                        'line_num': call.get('line_num')
                    })
            
            # æˆåŠŸç‡åˆ†æ
            event_type = call.get('event_type', '')
            if 'success' in event_type:
                analysis['success_rate']['success'] += 1
            elif 'warning' in event_type:
                analysis['success_rate']['warning'] += 1
            elif 'error' in event_type or 'exception' in event_type:
                analysis['success_rate']['error'] += 1
            
            analysis['success_rate']['total'] += 1
        
        # è¨ˆç®—å¹³å‡æ™‚é–“
        if durations:
            analysis['performance']['avg_duration'] = sum(durations) / len(durations)
        
        # è¼¸å‡ºåˆ†æçµæœ
        logger.info(f"ğŸ“ˆ æ€»èª¿ç”¨æ¬¡æ•¸: {analysis['total_calls']}")
        
        if analysis['by_symbol']:
            logger.info(f"\nğŸ“Š æŒ‰è‚¡ç¥¨ä»£ç¢¼çµ±è¨ˆ (å‰10):")
            for symbol, count in Counter(analysis['by_symbol']).most_common(10):
                logger.info(f"  - {symbol}: {count} æ¬¡")
        
        if analysis['by_data_source']:
            logger.info(f"\nğŸ”§ æŒ‰æ•¸æ“šæºçµ±è¨ˆ:")
            for source, count in Counter(analysis['by_data_source']).most_common():
                logger.info(f"  - {source}: {count} æ¬¡")
        
        if durations:
            logger.info(f"\nâ±ï¸  æ€§èƒ½çµ±è¨ˆ:")
            logger.info(f"  - æ€»è€—æ™‚: {analysis['performance']['total_duration']:.2f}s")
            logger.info(f"  - å¹³å‡è€—æ™‚: {analysis['performance']['avg_duration']:.2f}s")
            logger.info(f"  - æ…¢èª¿ç”¨ (>5s): {len(analysis['performance']['slow_calls'])} æ¬¡")
            logger.info(f"  - å¿«èª¿ç”¨ (<1s): {len(analysis['performance']['fast_calls'])} æ¬¡")
        
        if analysis['success_rate']['total'] > 0:
            success_pct = (analysis['success_rate']['success'] / analysis['success_rate']['total']) * 100
            logger.info(f"\nâœ… æˆåŠŸç‡çµ±è¨ˆ:")
            logger.info(f"  - æˆåŠŸ: {analysis['success_rate']['success']} ({success_pct:.1f}%)")
            logger.warning(f"  - è­¦å‘Š: {analysis['success_rate']['warning']}")
            logger.error(f"  - éŒ¯èª¤: {analysis['success_rate']['error']}")
        
        return analysis
    
    def analyze_tool_calls(self) -> Dict[str, Any]:
        """åˆ†æå·¥å…·èª¿ç”¨"""
        logger.info(f"\nğŸ”§ å·¥å…·èª¿ç”¨åˆ†æ")
        logger.info(f"=")
        
        analysis = {
            'total_calls': len(self.tool_calls),
            'by_tool': defaultdict(int),
            'performance': defaultdict(list),
            'success_rate': defaultdict(int)
        }
        
        for call in self.tool_calls:
            tool_name = call.get('tool_name', 'unknown')
            analysis['by_tool'][tool_name] += 1
            
            duration = call.get('duration')
            if duration:
                analysis['performance'][tool_name].append(duration)
            
            event_type = call.get('event_type', '')
            if 'success' in event_type:
                analysis['success_rate'][f"{tool_name}_success"] += 1
            elif 'error' in event_type:
                analysis['success_rate'][f"{tool_name}_error"] += 1
        
        # è¼¸å‡ºçµæœ
        logger.info(f"ğŸ”§ æ€»å·¥å…·èª¿ç”¨: {analysis['total_calls']}")
        
        if analysis['by_tool']:
            logger.info(f"\nğŸ“Š æŒ‰å·¥å…·çµ±è¨ˆ:")
            for tool, count in Counter(analysis['by_tool']).most_common():
                logger.info(f"  - {tool}: {count} æ¬¡")
                
                # æ€§èƒ½çµ±è¨ˆ
                if tool in analysis['performance']:
                    durations = analysis['performance'][tool]
                    avg_duration = sum(durations) / len(durations)
                    logger.info(f"    å¹³å‡è€—æ™‚: {avg_duration:.2f}s")
        
        return analysis
    
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        logger.info(f"\nğŸ“‹ ç”Ÿæˆæ•¸æ“šç²å–åˆ†æå ±å‘Š")
        logger.info(f"=")
        
        data_analysis = self.analyze_data_calls()
        tool_analysis = self.analyze_tool_calls()
        
        report = f"""
# æ•¸æ“šç²å–èª¿ç”¨åˆ†æå ±å‘Š

ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ—¥èªŒæ–‡ä»¶: {self.log_file}

## æ¦‚è¦½
- æ•¸æ“šç²å–èª¿ç”¨: {data_analysis['total_calls']}
- å·¥å…·èª¿ç”¨: {tool_analysis['total_calls']}
- æ•¸æ“šæºèª¿ç”¨: {len(self.data_source_calls)}

## æ•¸æ“šç²å–æ€§èƒ½
- æ€»è€—æ™‚: {data_analysis['performance']['total_duration']:.2f}s
- å¹³å‡è€—æ™‚: {data_analysis['performance']['avg_duration']:.2f}s
- æ…¢èª¿ç”¨æ•¸é‡: {len(data_analysis['performance']['slow_calls'])}

## æˆåŠŸç‡
- æˆåŠŸèª¿ç”¨: {data_analysis['success_rate']['success']}
- è­¦å‘Šèª¿ç”¨: {data_analysis['success_rate']['warning']}
- éŒ¯èª¤èª¿ç”¨: {data_analysis['success_rate']['error']}

## å»ºè®®
"""
        
        # æ·»åŠ å»ºè®®
        if data_analysis['performance']['avg_duration'] > 3.0:
            report += "- âš ï¸ å¹³å‡æ•¸æ“šç²å–æ™‚é–“è¼ƒé•·ï¼Œå»ºè®®å„ªåŒ–ç·©å­˜ç­–ç•¥\n"
        
        if data_analysis['success_rate']['error'] > 0:
            report += f"- âŒ ç™¼ç¾ {data_analysis['success_rate']['error']} å€‹æ•¸æ“šç²å–éŒ¯èª¤ï¼Œå»ºè®®æª¢æŸ¥æ•¸æ“šæºé…ç½®\n"
        
        if len(data_analysis['performance']['slow_calls']) > 5:
            report += "- ğŸŒ æ…¢èª¿ç”¨è¼ƒå¤šï¼Œå»ºè®®åˆ†æç¶²çµ¡é€£æ¥å’ŒAPIé™åˆ¶\n"
        
        return report


def main():
    parser = argparse.ArgumentParser(description='æ•¸æ“šç²å–èª¿ç”¨åˆ†æå·¥å…·')
    parser.add_argument('log_file', help='æ—¥èªŒæ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--output', '-o', help='è¼¸å‡ºå ±å‘Šæ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--format', choices=['text', 'json'], default='text', help='è¼¸å‡ºæ ¼å¼')
    
    args = parser.parse_args()
    
    log_file = Path(args.log_file)
    analyzer = DataCallAnalyzer(log_file)
    
    try:
        analyzer.parse_logs()
        report = analyzer.generate_report()
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"ğŸ“„ å ±å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(report)
            
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
