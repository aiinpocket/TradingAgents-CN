#!/usr/bin/env python3
"""
ä¿®è¤‡é‡è¤‡loggerå®šç¾©å•é¡Œçš„è…³æœ¬

é€™å€‹è…³æœ¬æœƒ:
1. æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
2. æª¢æ¸¬é‡è¤‡çš„logger = get_logger()å®šç¾©
3. ç§»é™¤é‡è¤‡å®šç¾©ï¼Œåªä¿ç•™æ–‡ä»¶å¤´éƒ¨çš„ç¬¬ä¸€å€‹å®šç¾©
4. ç”Ÿæˆè©³ç´°çš„ä¿®è¤‡å ±å‘Š
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Tuple

def find_python_files(root_dir: str, exclude_dirs: List[str] = None) -> List[str]:
    """æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶"""
    if exclude_dirs is None:
        exclude_dirs = ['env', '.env', '__pycache__', '.git', 'node_modules', '.venv']
    
    python_files = []
    for root, dirs, files in os.walk(root_dir):
        # æ’é™¤æŒ‡å®šç›®éŒ„
        dirs[:] = [d for d in dirs if d not in exclude_dirs]
        
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    
    return python_files

def analyze_logger_definitions(file_path: str) -> Dict:
    """åˆ†ææ–‡ä»¶ä¸­çš„loggerå®šç¾©"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        return {'error': str(e), 'logger_lines': []}
    
    logger_lines = []
    logger_pattern = re.compile(r'^\s*logger\s*=\s*get_logger\s*\(')
    
    for i, line in enumerate(lines, 1):
        if logger_pattern.match(line):
            logger_lines.append({
                'line_number': i,
                'content': line.strip(),
                'indentation': len(line) - len(line.lstrip())
            })
    
    return {
        'total_lines': len(lines),
        'logger_lines': logger_lines,
        'has_duplicates': len(logger_lines) > 1
    }

def find_import_section_end(lines: List[str]) -> int:
    """æ‰¾åˆ°importèªå¥çµæŸçš„ä½ç½®"""
    import_end = 0
    in_docstring = False
    docstring_char = None
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # è™•ç†æ–‡æ¡£å­—ç¬¦ä¸²
        if not in_docstring:
            if stripped.startswith('"""') or stripped.startswith("'''"):
                docstring_char = stripped[:3]
                if stripped.count(docstring_char) == 1:  # é–‹å§‹æ–‡æ¡£å­—ç¬¦ä¸²
                    in_docstring = True
                # å¦‚æœåŒä¸€è¡ŒåŒ…å«é–‹å§‹å’ŒçµæŸï¼Œå‰‡ä¸é€²å…¥æ–‡æ¡£å­—ç¬¦ä¸²ç‹€æ…‹
        else:
            if docstring_char in stripped:
                in_docstring = False
                continue
        
        if in_docstring:
            continue
            
        # è·³éè¨»é‡‹å’Œç©ºè¡Œ
        if not stripped or stripped.startswith('#'):
            continue
            
        # æª¢æŸ¥æ˜¯å¦æ˜¯importèªå¥
        if (stripped.startswith('import ') or 
            stripped.startswith('from ') or
            stripped.startswith('sys.path.') or
            stripped.startswith('load_dotenv(')):
            import_end = i + 1
        elif stripped and not stripped.startswith('#'):
            # é‡åˆ°éimportèªå¥ï¼Œåœæ­¢
            break
    
    return import_end

def fix_duplicate_loggers(file_path: str) -> Dict:
    """ä¿®è¤‡æ–‡ä»¶ä¸­çš„é‡è¤‡loggerå®šç¾©"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        return {'success': False, 'error': f'è®€å–æ–‡ä»¶å¤±è´¥: {str(e)}'}
    
    analysis = analyze_logger_definitions(file_path)
    
    if not analysis['has_duplicates']:
        return {'success': True, 'message': 'ç„¡éœ€ä¿®è¤‡', 'changes': 0}
    
    logger_lines = analysis['logger_lines']
    if len(logger_lines) <= 1:
        return {'success': True, 'message': 'ç„¡éœ€ä¿®è¤‡', 'changes': 0}
    
    # æ‰¾åˆ°importèªå¥çµæŸä½ç½®
    import_end = find_import_section_end(lines)
    
    # ç¢ºå®šè¦ä¿ç•™çš„loggerå®šç¾©
    keep_logger = None
    remove_lines = []
    
    # å„ªå…ˆä¿ç•™åœ¨importåŒºåŸŸé™„è¿‘çš„loggerå®šç¾©
    for logger_info in logger_lines:
        line_num = logger_info['line_number'] - 1  # è½‰æ›ç‚º0ç´¢å¼•
        if line_num <= import_end + 5:  # åœ¨importåŒºåŸŸé™„è¿‘
            if keep_logger is None:
                keep_logger = logger_info
            else:
                remove_lines.append(line_num)
        else:
            remove_lines.append(line_num)
    
    # å¦‚æœæ²¡æœ‰åœ¨importåŒºåŸŸæ‰¾åˆ°ï¼Œä¿ç•™ç¬¬ä¸€å€‹
    if keep_logger is None:
        keep_logger = logger_lines[0]
        remove_lines = [info['line_number'] - 1 for info in logger_lines[1:]]
    
    # ç§»é™¤é‡è¤‡çš„loggerå®šç¾©ï¼ˆå¾å¾Œå¾€å‰åˆªé™¤ä»¥ä¿æŒè¡Œè™Ÿæ­£ç¢ºï¼‰
    remove_lines.sort(reverse=True)
    changes_made = 0
    
    for line_num in remove_lines:
        if 0 <= line_num < len(lines):
            # æª¢æŸ¥æ˜¯å¦ç¢ºå¯¦æ˜¯loggerå®šç¾©
            if 'logger = get_logger(' in lines[line_num]:
                lines.pop(line_num)
                changes_made += 1
    
    if changes_made > 0:
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.writelines(lines)
            return {
                'success': True, 
                'message': f'ç§»é™¤äº†{changes_made}å€‹é‡è¤‡çš„loggerå®šç¾©',
                'changes': changes_made,
                'kept_logger': keep_logger['content'],
                'removed_count': changes_made
            }
        except Exception as e:
            return {'success': False, 'error': f'å¯«å…¥æ–‡ä»¶å¤±è´¥: {str(e)}'}
    
    return {'success': True, 'message': 'ç„¡éœ€ä¿®è¤‡', 'changes': 0}

def main():
    """ä¸»å‡½æ•¸"""
    root_dir = "c:\\code\\TradingAgentsCN"
    
    print("ğŸ” é–‹å§‹æ‰«æPythonæ–‡ä»¶...")
    python_files = find_python_files(root_dir)
    print(f"ğŸ“ æ‰¾åˆ° {len(python_files)} å€‹Pythonæ–‡ä»¶")
    
    # åˆ†ææ‰€æœ‰æ–‡ä»¶
    print("\nğŸ“Š åˆ†æloggerå®šç¾©...")
    files_with_duplicates = []
    total_duplicates = 0
    
    for file_path in python_files:
        analysis = analyze_logger_definitions(file_path)
        if analysis.get('has_duplicates', False):
            files_with_duplicates.append((file_path, analysis))
            total_duplicates += len(analysis['logger_lines']) - 1
    
    print(f"âš ï¸  ç™¼ç¾ {len(files_with_duplicates)} å€‹æ–‡ä»¶æœ‰é‡è¤‡loggerå®šç¾©")
    print(f"ğŸ“ˆ æ€»å…±æœ‰ {total_duplicates} å€‹é‡è¤‡å®šç¾©éœ€è¦ä¿®è¤‡")
    
    if not files_with_duplicates:
        print("âœ… æ²¡æœ‰ç™¼ç¾é‡è¤‡çš„loggerå®šç¾©ï¼")
        return
    
    # ä¿®è¤‡é‡è¤‡å®šç¾©
    print("\nğŸ”§ é–‹å§‹ä¿®è¤‡é‡è¤‡loggerå®šç¾©...")
    fixed_files = 0
    total_changes = 0
    errors = []
    
    for file_path, analysis in files_with_duplicates:
        rel_path = os.path.relpath(file_path, root_dir)
        print(f"\nğŸ“ è™•ç†: {rel_path}")
        print(f"   ç™¼ç¾ {len(analysis['logger_lines'])} å€‹loggerå®šç¾©")
        
        result = fix_duplicate_loggers(file_path)
        
        if result['success']:
            if result['changes'] > 0:
                fixed_files += 1
                total_changes += result['changes']
                print(f"   âœ… {result['message']}")
                if 'kept_logger' in result:
                    print(f"   ğŸ“Œ ä¿ç•™: {result['kept_logger']}")
            else:
                print(f"   â„¹ï¸  {result['message']}")
        else:
            errors.append((rel_path, result['error']))
            print(f"   âŒ {result['error']}")
    
    # ç”Ÿæˆå ±å‘Š
    print("\n" + "="*60)
    print("ğŸ“‹ ä¿®è¤‡å ±å‘Š")
    print("="*60)
    print(f"âœ… æˆåŠŸä¿®è¤‡æ–‡ä»¶æ•¸: {fixed_files}")
    print(f"ğŸ”§ æ€»å…±ç§»é™¤é‡è¤‡å®šç¾©: {total_changes}")
    print(f"âŒ ä¿®è¤‡å¤±è´¥æ–‡ä»¶æ•¸: {len(errors)}")
    
    if errors:
        print("\nâŒ ä¿®è¤‡å¤±è´¥çš„æ–‡ä»¶:")
        for file_path, error in errors:
            print(f"   - {file_path}: {error}")
    
    # ä¿å­˜è©³ç´°å ±å‘Š
    report_file = "duplicate_logger_fix_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# é‡è¤‡Loggerå®šç¾©ä¿®è¤‡å ±å‘Š\n\n")
        f.write(f"## æ¦‚è¦\n\n")
        f.write(f"- æ‰«ææ–‡ä»¶æ€»æ•¸: {len(python_files)}\n")
        f.write(f"- ç™¼ç¾é‡è¤‡å®šç¾©æ–‡ä»¶æ•¸: {len(files_with_duplicates)}\n")
        f.write(f"- æˆåŠŸä¿®è¤‡æ–‡ä»¶æ•¸: {fixed_files}\n")
        f.write(f"- æ€»å…±ç§»é™¤é‡è¤‡å®šç¾©: {total_changes}\n")
        f.write(f"- ä¿®è¤‡å¤±è´¥æ–‡ä»¶æ•¸: {len(errors)}\n\n")
        
        if errors:
            f.write("## ä¿®è¤‡å¤±è´¥çš„æ–‡ä»¶\n\n")
            for file_path, error in errors:
                f.write(f"- `{file_path}`: {error}\n")
            f.write("\n")
        
        f.write("## ä¿®è¤‡è©³æƒ…\n\n")
        for file_path, analysis in files_with_duplicates:
            rel_path = os.path.relpath(file_path, root_dir)
            f.write(f"### {rel_path}\n\n")
            f.write(f"- åŸæœ‰loggerå®šç¾©æ•¸: {len(analysis['logger_lines'])}\n")
            for i, logger_info in enumerate(analysis['logger_lines']):
                f.write(f"  - ç¬¬{logger_info['line_number']}è¡Œ: `{logger_info['content']}`\n")
            f.write("\n")
    
    print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("\nğŸ‰ ä¿®è¤‡å®Œæˆï¼")

if __name__ == "__main__":
    main()