#!/usr/bin/env python3
"""
ç³»çµ±ç‹€æ…‹æª¢æŸ¥è…³æœ¬
æª¢æŸ¥æ•¸æ“šåº«é…ç½®å’Œç·©å­˜ç³»çµ±ç‹€æ…‹
"""

import sys
import os
from pathlib import Path

# å°å…¥æ—¥èªŒæ¨¡å¡Š
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('scripts')

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def check_system_status():
    """æª¢æŸ¥ç³»çµ±ç‹€æ…‹"""
    logger.debug(f"ğŸ” TradingAgents ç³»çµ±ç‹€æ…‹æª¢æŸ¥")
    logger.info(f"=")
    
    # æª¢æŸ¥ç’°å¢ƒé…ç½®æ–‡ä»¶
    logger.info(f"\nğŸ“ æª¢æŸ¥ç’°å¢ƒé…ç½®...")
    env_file = project_root / ".env"
    env_example_file = project_root / ".env.example"

    if env_file.exists():
        logger.info(f"âœ… ç’°å¢ƒé…ç½®æ–‡ä»¶å­˜åœ¨: {env_file}")

        try:
            import os
            from dotenv import load_dotenv

            # åŠ è¼‰ç’°å¢ƒè®Šé‡
            load_dotenv(env_file)

            logger.info(f"ğŸ“Š æ•¸æ“šåº«é…ç½®ç‹€æ…‹:")
            mongodb_enabled = os.getenv('MONGODB_ENABLED', 'false').lower() == 'true'
            redis_enabled = os.getenv('REDIS_ENABLED', 'false').lower() == 'true'
            mongodb_host = os.getenv('MONGODB_HOST', 'localhost')
            mongodb_port = os.getenv('MONGODB_PORT', '27017')
            redis_host = os.getenv('REDIS_HOST', 'localhost')
            redis_port = os.getenv('REDIS_PORT', '6379')

            logger.error(f"  MongoDBå•Ÿç”¨: {'âœ… æ˜¯' if mongodb_enabled else 'âŒ å¦'}")
            logger.info(f"  MongoDBåœ°å€: {mongodb_host}:{mongodb_port}")
            logger.error(f"  Rediså•Ÿç”¨: {'âœ… æ˜¯' if redis_enabled else 'âŒ å¦'}")
            logger.info(f"  Redisåœ°å€: {redis_host}:{redis_port}")

            logger.info(f"\nğŸ“Š APIå¯†é‘°é…ç½®ç‹€æ…‹:")
            api_keys = {
                'FINNHUB_API_KEY': 'FinnHub',
                'OPENAI_API_KEY': 'OpenAI',
                'GOOGLE_API_KEY': 'Google AI',
                'ANTHROPIC_API_KEY': 'Anthropic',
                'OPENROUTER_API_KEY': 'OpenRouter'
            }

            for key, name in api_keys.items():
                value = os.getenv(key, '')
                if value and value != f'your_{key.lower()}_here':
                    logger.info(f"  {name}: âœ… å·²é…ç½®")
                else:
                    logger.error(f"  {name}: âŒ æœªé…ç½®")

        except ImportError:
            logger.warning(f"âš ï¸ python-dotenvæœªå®‰è£ï¼Œç„¡æ³•è§£æ.envæ–‡ä»¶")
        except Exception as e:
            logger.error(f"âŒ ç’°å¢ƒé…ç½®è§£æå¤±æ•—: {e}")
    else:
        logger.error(f"âŒ ç’°å¢ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {env_file}")
        if env_example_file.exists():
            logger.info(f"ğŸ’¡ è«‹è¤‡åˆ¶ {env_example_file} ç‚º {env_file} ä¸¦é…ç½®APIå¯†é‘°")
    
    # æª¢æŸ¥æ•¸æ“šåº«ç®¡ç†å™¨
    logger.info(f"\nğŸ”§ æª¢æŸ¥æ•¸æ“šåº«ç®¡ç†å™¨...")
    try:
        from tradingagents.config.database_manager import get_database_manager
        
        db_manager = get_database_manager()
        status = db_manager.get_status_report()
        
        logger.info(f"ğŸ“Š æ•¸æ“šåº«ç‹€æ…‹:")
        logger.error(f"  æ•¸æ“šåº«å¯ç”¨: {'âœ… æ˜¯' if status['database_available'] else 'âŒ å¦'}")
        logger.error(f"  MongoDB: {'âœ… å¯ç”¨' if status['mongodb']['available'] else 'âŒ ä¸å¯ç”¨'}")
        logger.error(f"  Redis: {'âœ… å¯ç”¨' if status['redis']['available'] else 'âŒ ä¸å¯ç”¨'}")
        logger.info(f"  ç·©å­˜å¾Œç«¯: {status['cache_backend']}")
        logger.error(f"  é™ç´šæ”¯æŒ: {'âœ… å•Ÿç”¨' if status['fallback_enabled'] else 'âŒ ç¦ç”¨'}")
        
    except Exception as e:
        logger.error(f"âŒ æ•¸æ“šåº«ç®¡ç†å™¨æª¢æŸ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    # æª¢æŸ¥ç·©å­˜ç³»çµ±
    logger.info(f"\nğŸ’¾ æª¢æŸ¥ç·©å­˜ç³»çµ±...")
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        backend_info = cache.get_cache_backend_info()
        
        logger.info(f"ğŸ“Š ç·©å­˜ç³»çµ±ç‹€æ…‹:")
        logger.info(f"  ç·©å­˜ç³»çµ±: {backend_info['system']}")
        logger.info(f"  ä¸»è¦å¾Œç«¯: {backend_info['primary_backend']}")
        logger.error(f"  é™ç´šæ”¯æŒ: {'âœ… å•Ÿç”¨' if backend_info['fallback_enabled'] else 'âŒ ç¦ç”¨'}")
        logger.info(f"  æ€§èƒ½æ¨¡å¼: {cache.get_performance_mode()}")
        
        # ç²å–è©³ç´°çµ±è¨ˆ
        stats = cache.get_cache_stats()
        if 'adaptive_cache' in stats:
            adaptive_stats = stats['adaptive_cache']
            logger.info(f"  æ–‡ä»¶ç·©å­˜æ•¸é‡: {adaptive_stats.get('file_cache_count', 0)}")
            if 'redis_keys' in adaptive_stats:
                logger.info(f"  Rediséµæ•¸é‡: {adaptive_stats['redis_keys']}")
            if 'mongodb_cache_count' in adaptive_stats:
                logger.info(f"  MongoDBç·©å­˜æ•¸é‡: {adaptive_stats['mongodb_cache_count']}")
        
    except Exception as e:
        logger.error(f"âŒ ç·©å­˜ç³»çµ±æª¢æŸ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    # æ¸¬è©¦ç·©å­˜åŠŸèƒ½
    logger.info(f"\nğŸ§ª æ¸¬è©¦ç·©å­˜åŠŸèƒ½...")
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        from datetime import datetime
        
        cache = get_cache()
        
        # æ¸¬è©¦æ•¸æ“šä¿å­˜
        test_data = f"æ¸¬è©¦æ•¸æ“š - {datetime.now()}"
        cache_key = cache.save_stock_data(
            symbol="TEST",
            data=test_data,
            start_date="2024-01-01",
            end_date="2024-12-31",
            data_source="system_test"
        )
        logger.info(f"âœ… æ•¸æ“šä¿å­˜æˆåŠŸ: {cache_key}")
        
        # æ¸¬è©¦æ•¸æ“šåŠ è¼‰
        loaded_data = cache.load_stock_data(cache_key)
        if loaded_data == test_data:
            logger.info(f"âœ… æ•¸æ“šåŠ è¼‰æˆåŠŸï¼Œå…§å®¹åŒ¹é…")
        else:
            logger.error(f"âŒ æ•¸æ“šåŠ è¼‰å¤±æ•—æˆ–å…§å®¹ä¸åŒ¹é…")
        
        # æ¸¬è©¦æ•¸æ“šæŸ¥æ‰¾
        found_key = cache.find_cached_stock_data(
            symbol="TEST",
            start_date="2024-01-01",
            end_date="2024-12-31",
            data_source="system_test"
        )
        
        if found_key:
            logger.info(f"âœ… ç·©å­˜æŸ¥æ‰¾æˆåŠŸ: {found_key}")
        else:
            logger.error(f"âŒ ç·©å­˜æŸ¥æ‰¾å¤±æ•—")
        
    except Exception as e:
        logger.error(f"âŒ ç·©å­˜åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    # æ€§èƒ½æ¸¬è©¦
    logger.info(f"\nâš¡ ç°¡å–®æ€§èƒ½æ¸¬è©¦...")
    try:
        import time
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        # ä¿å­˜æ€§èƒ½æ¸¬è©¦
        start_time = time.time()
        cache_key = cache.save_stock_data(
            symbol="PERF",
            data="æ€§èƒ½æ¸¬è©¦æ•¸æ“š",
            start_date="2024-01-01",
            end_date="2024-12-31",
            data_source="perf_test"
        )
        save_time = time.time() - start_time
        
        # åŠ è¼‰æ€§èƒ½æ¸¬è©¦
        start_time = time.time()
        data = cache.load_stock_data(cache_key)
        load_time = time.time() - start_time
        
        logger.info(f"ğŸ“Š æ€§èƒ½æ¸¬è©¦çµæœ:")
        logger.info(f"  ä¿å­˜æ™‚é–“: {save_time:.4f}ç§’")
        logger.info(f"  åŠ è¼‰æ™‚é–“: {load_time:.4f}ç§’")
        
        if load_time < 0.1:
            logger.info(f"âœ… ç·©å­˜æ€§èƒ½è‰¯å¥½ (<0.1ç§’)")
        else:
            logger.warning(f"âš ï¸ ç·©å­˜æ€§èƒ½éœ€è¦å„ªåŒ–")
        
        # è¨ˆç®—æ€§èƒ½æ”¹é€²
        api_simulation_time = 2.0  # å‡è¨­APIèª¿ç”¨éœ€è¦2ç§’
        if load_time < api_simulation_time:
            improvement = ((api_simulation_time - load_time) / api_simulation_time) * 100
            logger.info(f"ğŸš€ ç›¸æ¯”APIèª¿ç”¨æ€§èƒ½æå‡: {improvement:.1f}%")
        
    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½æ¸¬è©¦å¤±æ•—: {e}")
    
    # ç³»çµ±å»ºè­°
    logger.info(f"\nğŸ’¡ ç³»çµ±å»ºè­°:")
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        if cache.is_database_available():
            logger.info(f"âœ… æ•¸æ“šåº«å¯ç”¨ï¼Œç³»çµ±é‹è¡Œåœ¨æœ€ä½³æ€§èƒ½æ¨¡å¼")
        else:
            logger.info(f"â„¹ï¸ æ•¸æ“šåº«ä¸å¯ç”¨ï¼Œç³»çµ±ä½¿ç”¨æ–‡ä»¶ç·©å­˜æ¨¡å¼")
            logger.info(f"ğŸ’¡ æå‡æ€§èƒ½å»ºè­°:")
            logger.info(f"  1. é…ç½®ç’°å¢ƒè®Šé‡å•Ÿç”¨æ•¸æ“šåº«:")
            logger.info(f"     MONGODB_ENABLED=true")
            logger.info(f"     REDIS_ENABLED=true")
            logger.info(f"  2. å•Ÿå‹•æ•¸æ“šåº«æœå‹™:")
            logger.info(f"     docker-compose up -d  # æ¨è–¦æ–¹å¼")
            logger.info(f"     æˆ–æ‰‹å‹•å•Ÿå‹•:")
            logger.info(f"     - MongoDB: docker run -d -p 27017:27017 mongo:4.4")
            logger.info(f"     - Redis: docker run -d -p 6379:6379 redis:alpine")
        
        performance_mode = cache.get_performance_mode()
        logger.info(f"ğŸ¯ ç•¶å‰æ€§èƒ½æ¨¡å¼: {performance_mode}")
        
    except Exception as e:
        logger.warning(f"âš ï¸ ç„¡æ³•ç”Ÿæˆç³»çµ±å»ºè­°: {e}")
    
    logger.info(f"\n")
    logger.info(f"ğŸ‰ ç³»çµ±ç‹€æ…‹æª¢æŸ¥å®Œæˆ!")

def main():
    """ä¸»å‡½æ•¸"""
    try:
        check_system_status()
        return True
    except Exception as e:
        logger.error(f"âŒ ç³»çµ±æª¢æŸ¥å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
