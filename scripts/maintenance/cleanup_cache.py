#!/usr/bin/env python3
"""
ç·©å­˜æ¸…ç†å·¥å…·
æ¸…ç†éæœŸçš„ç·©å­˜æ–‡ä»¶å’Œæ•¸æ“šåº«è¨˜éŒ„
"""

import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

# å°å…¥æ—¥èªŒæ¨¡å¡Š
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('scripts')

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def cleanup_file_cache(max_age_days: int = 7):
    """æ¸…ç†æ–‡ä»¶ç·©å­˜"""
    logger.info(f"ğŸ§¹ æ¸…ç† {max_age_days} å¤©å‰çš„æ–‡ä»¶ç·©å­˜...")
    
    cache_dirs = [
        project_root / "cache",
        project_root / "data" / "cache", 
        project_root / "tradingagents" / "dataflows" / "data_cache"
    ]
    
    total_cleaned = 0
    cutoff_time = datetime.now() - timedelta(days=max_age_days)
    
    for cache_dir in cache_dirs:
        if not cache_dir.exists():
            continue
            
        logger.info(f"ğŸ“ æª¢æŸ¥ç·©å­˜ç›®éŒ„: {cache_dir}")
        
        for cache_file in cache_dir.rglob("*"):
            if cache_file.is_file():
                try:
                    file_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
                    if file_time < cutoff_time:
                        cache_file.unlink()
                        total_cleaned += 1
                        logger.info(f"  âœ… åˆªé™¤: {cache_file.name}")
                except Exception as e:
                    logger.error(f"  âŒ åˆªé™¤å¤±è´¥: {cache_file.name} - {e}")
    
    logger.info(f"âœ… æ–‡ä»¶ç·©å­˜æ¸…ç†å®Œæˆï¼Œåˆªé™¤äº† {total_cleaned} å€‹æ–‡ä»¶")
    return total_cleaned

def cleanup_database_cache(max_age_days: int = 7):
    """æ¸…ç†æ•¸æ“šåº«ç·©å­˜"""
    logger.info(f"ğŸ—„ï¸ æ¸…ç† {max_age_days} å¤©å‰çš„æ•¸æ“šåº«ç·©å­˜...")
    
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        if hasattr(cache, 'clear_old_cache'):
            cleared_count = cache.clear_old_cache(max_age_days)
            logger.info(f"âœ… æ•¸æ“šåº«ç·©å­˜æ¸…ç†å®Œæˆï¼Œåˆªé™¤äº† {cleared_count} æ¢è¨˜éŒ„")
            return cleared_count
        else:
            logger.info(f"â„¹ï¸ ç•¶å‰ç·©å­˜ç³»çµ±ä¸æ”¯æŒè‡ªå‹•æ¸…ç†")
            return 0
            
    except Exception as e:
        logger.error(f"âŒ æ•¸æ“šåº«ç·©å­˜æ¸…ç†å¤±è´¥: {e}")
        return 0

def cleanup_python_cache():
    """æ¸…ç†Pythonç·©å­˜æ–‡ä»¶"""
    logger.info(f"ğŸ æ¸…ç†Pythonç·©å­˜æ–‡ä»¶...")
    
    cache_patterns = ["__pycache__", "*.pyc", "*.pyo"]
    total_cleaned = 0
    
    for pattern in cache_patterns:
        if pattern == "__pycache__":
            cache_dirs = list(project_root.rglob(pattern))
            for cache_dir in cache_dirs:
                try:
                    import shutil
                    shutil.rmtree(cache_dir)
                    total_cleaned += 1
                    logger.info(f"  âœ… åˆªé™¤ç›®éŒ„: {cache_dir.relative_to(project_root)}")
                except Exception as e:
                    logger.error(f"  âŒ åˆªé™¤å¤±è´¥: {cache_dir.relative_to(project_root)} - {e}")
        else:
            cache_files = list(project_root.rglob(pattern))
            for cache_file in cache_files:
                try:
                    cache_file.unlink()
                    total_cleaned += 1
                    logger.info(f"  âœ… åˆªé™¤æ–‡ä»¶: {cache_file.relative_to(project_root)}")
                except Exception as e:
                    logger.error(f"  âŒ åˆªé™¤å¤±è´¥: {cache_file.relative_to(project_root)} - {e}")
    
    logger.info(f"âœ… Pythonç·©å­˜æ¸…ç†å®Œæˆï¼Œåˆªé™¤äº† {total_cleaned} å€‹é …ç›®")
    return total_cleaned

def get_cache_statistics():
    """ç²å–ç·©å­˜çµ±è¨ˆä¿¡æ¯"""
    logger.info(f"ğŸ“Š ç²å–ç·©å­˜çµ±è¨ˆä¿¡æ¯...")
    
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        logger.info(f"ğŸ¯ ç·©å­˜æ¨¡å¼: {cache.get_performance_mode()}")
        logger.info(f"ğŸ—„ï¸ æ•¸æ“šåº«å¯ç”¨: {'æ˜¯' if cache.is_database_available() else 'å¦'}")
        
        # çµ±è¨ˆæ–‡ä»¶ç·©å­˜
        cache_dirs = [
            project_root / "cache",
            project_root / "data" / "cache",
            project_root / "tradingagents" / "dataflows" / "data_cache"
        ]
        
        total_files = 0
        total_size = 0
        
        for cache_dir in cache_dirs:
            if cache_dir.exists():
                for cache_file in cache_dir.rglob("*"):
                    if cache_file.is_file():
                        total_files += 1
                        total_size += cache_file.stat().st_size
        
        logger.info(f"ğŸ“ æ–‡ä»¶ç·©å­˜: {total_files} å€‹æ–‡ä»¶ï¼Œ{total_size / 1024 / 1024:.2f} MB")
        
    except Exception as e:
        logger.error(f"âŒ ç²å–ç·©å­˜çµ±è¨ˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    logger.info(f"ğŸ§¹ TradingAgents ç·©å­˜æ¸…ç†å·¥å…·")
    logger.info(f"=")
    
    import argparse

    parser = argparse.ArgumentParser(description="æ¸…ç†TradingAgentsç·©å­˜")
    parser.add_argument("--days", type=int, default=7, help="æ¸…ç†å¤šå°‘å¤©å‰çš„ç·©å­˜ (é»˜èª: 7)")
    parser.add_argument("--type", choices=["all", "file", "database", "python"], 
                       default="all", help="æ¸…ç†é¡å‹ (é»˜èª: all)")
    parser.add_argument("--stats", action="store_true", help="åªé¡¯ç¤ºçµ±è¨ˆä¿¡æ¯ï¼Œä¸æ¸…ç†")
    
    args = parser.parse_args()
    
    if args.stats:
        get_cache_statistics()
        return
    
    total_cleaned = 0
    
    if args.type in ["all", "file"]:
        total_cleaned += cleanup_file_cache(args.days)
    
    if args.type in ["all", "database"]:
        total_cleaned += cleanup_database_cache(args.days)
    
    if args.type in ["all", "python"]:
        total_cleaned += cleanup_python_cache()
    
    logger.info(f"\n")
    logger.info(f"ğŸ‰ ç·©å­˜æ¸…ç†å®Œæˆï¼æ€»å…±æ¸…ç†äº† {total_cleaned} å€‹é …ç›®")
    logger.info(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
    logger.info(f"  --stats     æŸ¥çœ‹ç·©å­˜çµ±è¨ˆ")
    logger.info(f"  --days 3    æ¸…ç†3å¤©å‰çš„ç·©å­˜")
    logger.info(f"  --type file åªæ¸…ç†æ–‡ä»¶ç·©å­˜")

if __name__ == "__main__":
    main()
